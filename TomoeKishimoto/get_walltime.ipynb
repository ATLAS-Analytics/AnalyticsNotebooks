{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_host      = 'atlas-kibana.mwt2.org'\n",
    "db_port      = 9200\n",
    "db_index     = 'jobs_archive_2018-*'\n",
    "\n",
    "query_source = [\n",
    "    'taskid',\n",
    "    'pandaid',\n",
    "    'jobstatus',\n",
    "    'computingsite',\n",
    "    'exeerrorcode',\n",
    "    'exeerrordiag',\n",
    "    'piloterrorcode',\n",
    "    'piloterrordiag',\n",
    "    'jobdispatchererrorcode',\n",
    "    'jobdispatchererrordiag',\n",
    "    'ddmerrorcode',\n",
    "    'ddmerrordiag',\n",
    "    'taskbuffererrorcode',\n",
    "    'taskbuffererrordiag',\n",
    "    'transexitcode',\n",
    "    'transformation',\n",
    "    'wall_time',\n",
    "    'corecount',\n",
    "]\n",
    "\n",
    "query_should = [              \n",
    "    {'term':{'jobstatus': 'failed'}},\n",
    "]\n",
    "\n",
    "query_must_not = [\n",
    "    {'term':{'gShare': 'Analysis'}},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf> index:  jobs_archive_2018-*\n",
      "inf> processed 100000 events\n",
      "inf> processed 200000 events\n",
      "inf> processed 300000 events\n",
      "inf> processed 400000 events\n",
      "inf> processed 500000 events\n",
      "inf> processed 600000 events\n",
      "inf> processed 700000 events\n",
      "inf> processed 800000 events\n",
      "inf> processed 900000 events\n",
      "inf> processed 1000000 events\n",
      "inf> processed 1100000 events\n",
      "inf> processed 1200000 events\n",
      "inf> processed 1300000 events\n",
      "inf> processed 1400000 events\n",
      "inf> processed 1500000 events\n",
      "inf> processed 1600000 events\n",
      "inf> processed 1700000 events\n",
      "inf> processed 1800000 events\n",
      "inf> processed 1900000 events\n",
      "inf> processed 2000000 events\n",
      "inf> processed 2100000 events\n",
      "inf> processed 2200000 events\n",
      "inf> processed 2300000 events\n",
      "inf> processed 2400000 events\n",
      "inf> processed 2500000 events\n",
      "inf> processed 2600000 events\n",
      "inf> processed 2700000 events\n",
      "inf> processed 2800000 events\n",
      "inf> processed 2900000 events\n",
      "inf> processed 3000000 events\n",
      "inf> processed 3100000 events\n",
      "inf> processed 3200000 events\n",
      "inf> processed 3300000 events\n",
      "inf> processed 3400000 events\n",
      "inf> processed 3500000 events\n",
      "inf> processed 3600000 events\n",
      "inf> processed 3700000 events\n",
      "inf> processed 3800000 events\n",
      "inf> processed 3900000 events\n",
      "inf> processed 4000000 events\n",
      "inf> processed 4100000 events\n",
      "inf> processed 4200000 events\n",
      "inf> processed 4300000 events\n",
      "inf> processed 4400000 events\n",
      "inf> processed 4500000 events\n",
      "inf> processed 4600000 events\n",
      "inf> processed 4700000 events\n",
      "inf> processed 4800000 events\n",
      "inf> processed 4900000 events\n",
      "inf> processed 5000000 events\n",
      "inf> processed 5100000 events\n",
      "inf> processed 5200000 events\n",
      "inf> processed 5300000 events\n",
      "inf> processed 5400000 events\n",
      "inf> processed 5500000 events\n",
      "inf> processed 5600000 events\n",
      "inf> processed 5700000 events\n",
      "inf> processed 5800000 events\n",
      "inf> total 5887867 tasks queried\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers \n",
    "from elasticsearch.helpers import scan\n",
    "\n",
    "es = Elasticsearch([{'host':db_host, 'port':db_port}], timeout=60)\n",
    "\n",
    "indices = es.cat.indices(index=db_index, h='index', \n",
    "                         request_timeout=600).split('\\n')\n",
    "indices = sorted(indices)\n",
    "indices = [ii for ii in indices if ii != '']\n",
    "indices = ','.join(indices)\n",
    "\n",
    "job_query = {\n",
    "    'size'   : 0, \n",
    "    '_source': query_source, \n",
    "    'query':   {'bool': {'should': query_should, \n",
    "                         'minimum_should_match':1, \n",
    "                         'must_not': query_must_not}}\n",
    "}\n",
    "\n",
    "scroll = scan(client=es, index=indices, query=job_query)\n",
    "\n",
    "results = []\n",
    "count = 1\n",
    "\n",
    "print ('inf> index: ', db_index)\n",
    "\n",
    "for res in scroll:\n",
    "    r = res['_source']\n",
    "    job_info = []\n",
    "    \n",
    "    for source in query_source:\n",
    "        job_info.append(r[source])\n",
    "            \n",
    "    if job_info[0] == None:\n",
    "        continue\n",
    "        \n",
    "    results.append(job_info)\n",
    "    \n",
    "    if (count % 100000) == 0:\n",
    "        print ('inf> processed', count, 'events')\n",
    "    count += 1\n",
    "    \n",
    "print ('inf> total', len(results), 'tasks queried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf> writing transformation\n",
      "inf> writing computingsite\n",
      "inf> writing execution error codes\n",
      "inf> writing pilot error codes\n",
      "inf> writing dispatcher error codes\n",
      "inf> writing ddm error codes\n",
      "inf> writing execution error messages\n",
      "inf> writing pilot error messages\n",
      "inf> writing dispatcher error messages\n",
      "inf> writing ddm error messages\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "\n",
    "wall_trans = {}\n",
    "wall_site  = {}\n",
    "\n",
    "wall_exe   = {}\n",
    "wall_pilot = {}\n",
    "wall_jobds = {}\n",
    "wall_ddm   = {}\n",
    "\n",
    "wall_exe_total  = {}\n",
    "wall_pilot_total = {}\n",
    "wall_jobds_total = {}\n",
    "wall_ddm_total   = {}\n",
    "\n",
    "def get_filter(words):\n",
    "    filtered = ''\n",
    "    \n",
    "    words_list = words.split()\n",
    "    for word in words_list:\n",
    "        tmp_word = word.replace(';', '')\n",
    "        tmp_word = tmp_word.replace(':', '')\n",
    "        \n",
    "        if len(tmp_word) > 30:\n",
    "            tmp_word = 'xxxx'\n",
    "        if tmp_word.isdigit():\n",
    "            tmp_word = 'xxxx'\n",
    "        if '0x' in tmp_word:\n",
    "            tmp_word = 'xxxx'\n",
    "            \n",
    "        match = re.match(r'\\d{4}-\\d{2}-\\d{2}.*', tmp_word)\n",
    "        if match:\n",
    "            tmp_word = 'xxxx-xx-xx'\n",
    "    \n",
    "        filtered = filtered + \" \" + tmp_word\n",
    "    \n",
    "    return filtered\n",
    "    \n",
    "    \n",
    "def fill_err(code, err, loss, wall_dict, wall_dict_total):\n",
    "    if code in wall_dict_total.keys():            \n",
    "        wall_dict_total[code] += loss\n",
    "    else:\n",
    "        wall_dict_total[code] = loss\n",
    "\n",
    "    if err in wall_dict.keys():            \n",
    "        wall_dict[err] += loss\n",
    "    else:\n",
    "        wall_dict[err] = loss\n",
    "    \n",
    "    \n",
    "for result in results:\n",
    "    exeerr  = result[5]\n",
    "    execode = result[4]\n",
    "    pilerr  = result[7]\n",
    "    pilcode = result[6]\n",
    "    diserr  = result[9]\n",
    "    discode = result[8]\n",
    "    ddmerr  = result[11]\n",
    "    ddmcode = result[10]\n",
    "    \n",
    "    site    = result[3]\n",
    "    process = result[15]\n",
    "    core    = result[17]\n",
    "    \n",
    "    if core == None:\n",
    "        core = 1\n",
    "    loss    = (result[16]/3600)*core\n",
    "    \n",
    "    if process in wall_trans.keys():\n",
    "        wall_trans[process] += loss\n",
    "    else:\n",
    "        wall_trans[process] = loss\n",
    "        \n",
    "    if site in wall_site.keys():\n",
    "        wall_site[site] += loss\n",
    "    else:\n",
    "        wall_site[site] = loss\n",
    "        \n",
    "    if exeerr != None:\n",
    "        exeerr = get_filter(exeerr)\n",
    "        fill_err(execode, exeerr, loss, wall_exe, wall_exe_total)\n",
    "    if pilerr != None:\n",
    "        pilerr = get_filter(pilerr)\n",
    "        fill_err(pilcode, pilerr, loss, wall_pilot, wall_pilot_total)\n",
    "    if diserr != None:\n",
    "        diserr = get_filter(diserr)\n",
    "        fill_err(discode, diserr, loss, wall_jobds, wall_jobds_total)\n",
    "    if ddmerr != None:\n",
    "        ddmerr = get_filter(ddmerr)\n",
    "        fill_err(ddmcode, ddmerr, loss, wall_ddm, wall_ddm_total)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "data_trans = sorted(wall_trans.items(), key=lambda x: -x[1])  \n",
    "data_site  = sorted(wall_site.items(), key=lambda x: -x[1])\n",
    "data_exe   = sorted(wall_exe_total.items(), key=lambda x: -x[1])\n",
    "data_pil   = sorted(wall_pilot_total.items(), key=lambda x: -x[1])\n",
    "data_dis   = sorted(wall_jobds_total.items(), key=lambda x: -x[1])\n",
    "data_ddm   = sorted(wall_ddm_total.items(), key=lambda x: -x[1])\n",
    "\n",
    "data_exe_err   = sorted(wall_exe.items(), key=lambda x: -x[1])\n",
    "data_pil_err   = sorted(wall_pilot.items(), key=lambda x: -x[1])\n",
    "data_dis_err   = sorted(wall_jobds.items(), key=lambda x: -x[1])\n",
    "data_ddm_err   = sorted(wall_ddm.items(), key=lambda x: -x[1])\n",
    "\n",
    "#data_pilot = sorted(wall_pilot.items(), key=lambda x: -x[1])\n",
    "\n",
    "print ('inf> writing transformation')\n",
    "output = open('transformation.txt', 'w')\n",
    "for ii in data_trans:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing computingsite')\n",
    "output = open('computingsite.txt', 'w')\n",
    "for ii in data_site:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing execution error codes')\n",
    "output = open('exeerrorcode.txt', 'w')\n",
    "for ii in data_exe:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing pilot error codes')\n",
    "output = open('piloterrorcode.txt', 'w')\n",
    "for ii in data_pil:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing dispatcher error codes')\n",
    "output = open('dipatcherrorcode.txt', 'w')\n",
    "for ii in data_dis:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing ddm error codes')\n",
    "output = open('ddmerrorcode.txt', 'w')\n",
    "for ii in data_ddm:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "\n",
    "print ('inf> writing execution error messages')\n",
    "output = open('exeerror.txt', 'w')\n",
    "for ii in data_exe_err:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing pilot error messages')\n",
    "output = open('piloterror.txt', 'w')\n",
    "for ii in data_pil_err:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing dispatcher error messages')\n",
    "output = open('dipatcherror.txt', 'w')\n",
    "for ii in data_dis_err:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n",
    "\n",
    "print ('inf> writing ddm error messages')\n",
    "output = open('ddmerror.txt', 'w')\n",
    "for ii in data_ddm_err:\n",
    "    output.write('%s %s\\n' % (ii[0], ii[1]))\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
