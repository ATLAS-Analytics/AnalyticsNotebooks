{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots delays, throughputs, packet loss and path for a selected link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-96e37ca7fb8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib import gridspec\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "es = Elasticsearch(['atlas-kibana.mwt2.org:9200'],timeout=60)\n",
    "indices = \"network_weather-2017.5.*\"\n",
    "\n",
    "my_query = {}\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "from pandas.tseries.offsets import *\n",
    "\n",
    "#from graphviz import Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Select your link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sS='UC'\n",
    "# srcSiteOWDServer = \"192.170.227.160\"\n",
    "# srcSiteThroughputServer = \"192.170.227.162\"\n",
    "\n",
    "sS1= 'pic'\n",
    "srcSiteOWDServer1 = \"193.109.172.188\"\n",
    "#srcSiteThroughputServer = \"128.142.223.246\"\n",
    "\n",
    "sS2= 'pic'\n",
    "srcSiteOWDServer2 = \"193.109.172.188\"\n",
    "\n",
    "sS3= 'pic'\n",
    "srcSiteOWDServer3 = \"193.109.172.188\"\n",
    "\n",
    "sS4= 'pic'\n",
    "srcSiteOWDServer4 = \"193.109.172.188\"\n",
    "\n",
    "sS5= 'pic'\n",
    "srcSiteOWDServer5 = \"193.109.172.188\"\n",
    "\n",
    "# dS='IU'\n",
    "# destSiteOWDServer = \"149.165.225.223\"\n",
    "# destSiteThroughputServer = \"149.165.225.224\"\n",
    "\n",
    "# dS='UIUC'\n",
    "# destSiteOWDServer = \"72.36.96.4\"\n",
    "# destSiteThroughputServer = \"72.36.96.9\"\n",
    "\n",
    "# dS='ICCN'\n",
    "# destSiteOWDServer = \"72.36.96.4\"\n",
    "# destSiteThroughputServer = \"72.36.126.132\"\n",
    "\n",
    "dS1 = 'CERN-PROD'\n",
    "destSiteOWDServer1 = \"128.142.223.247\"\n",
    "#destSiteThroughputServer = \"193.109.172.187\"\n",
    "\n",
    "dS2 = 'RO-16-UAIC'\n",
    "destSiteOWDServer2 = \"85.122.31.74\"\n",
    "\n",
    "dS3 = 'praguelcg2'\n",
    "destSiteOWDServer3 = \"147.231.25.192\"\n",
    "\n",
    "dS4 = 'MWT2'\n",
    "destSiteOWDServer4 = \"149.165.225.223\"\n",
    "\n",
    "dS5 = 'UFlorida-HPC'\n",
    "destSiteOWDServer5 = \"128.227.221.44\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from Elasticsearch, and store the record based on its type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_query1 = {\n",
    "    'query': { \n",
    "       'bool':{\n",
    "            'must':[\n",
    "                    {'range': {'timestamp': {'gte': '20170510T000000Z', 'lt': '20170517T000000Z'}}},\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'src': srcSiteOWDServer1}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'dest': destSiteOWDServer1}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'_type': 'packet_loss_rate'}},\n",
    "                            ]}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "scroll1 = list(scan(client=es, index=indices, query=my_query1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_query2 = {\n",
    "    'query': { \n",
    "       'bool':{\n",
    "            'must':[\n",
    "                    {'range': {'timestamp': {'gte': '20170510T000000Z', 'lt': '20170517T000000Z'}}},\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'src': srcSiteOWDServer2}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'dest': destSiteOWDServer2}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'_type': 'packet_loss_rate'}},\n",
    "                            ]}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "scroll2 = list(scan(client=es, index=indices, query=my_query2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_query3 = {\n",
    "    'query': { \n",
    "       'bool':{\n",
    "            'must':[\n",
    "                    {'range': {'timestamp': {'gte': '20170510T000000Z', 'lt': '20170517T000000Z'}}},\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'src': srcSiteOWDServer3}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'dest': destSiteOWDServer3}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'_type': 'packet_loss_rate'}},\n",
    "                            ]}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "scroll3 = list(scan(client=es, index=indices, query=my_query3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_query4 = {\n",
    "    'query': { \n",
    "       'bool':{\n",
    "            'must':[\n",
    "                    {'range': {'timestamp': {'gte': '20170510T000000Z', 'lt': '20170517T000000Z'}}},\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'src': srcSiteOWDServer4}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'dest': destSiteOWDServer4}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'_type': 'packet_loss_rate'}},\n",
    "                            ]}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "scroll4 = list(scan(client=es, index=indices, query=my_query4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_query5 = {\n",
    "    'query': { \n",
    "       'bool':{\n",
    "            'must':[\n",
    "                    {'range': {'timestamp': {'gte': '20170510T000000Z', 'lt': '20170517T000000Z'}}},\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'src': srcSiteOWDServer5}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'dest': destSiteOWDServer5}},\n",
    "                            ]}\n",
    "                        },\n",
    "                        {'bool':\n",
    "                            {'should':[\n",
    "                                {'term': {'_type': 'packet_loss_rate'}},\n",
    "                            ]}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "scroll5 = list(scan(client=es, index=indices, query=my_query5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site1 = {srcSiteOWDServer1: sS1, destSiteOWDServer1:dS1}\n",
    "data1 = {sS1:pd.DataFrame(),dS1:pd.DataFrame()}\n",
    "epoch = datetime.utcfromtimestamp(0)\n",
    "count = 0\n",
    "print(epoch)\n",
    "\n",
    "for res in scroll1:\n",
    "    if count<10: print(res)\n",
    "    count += 1\n",
    "#     dt=datetime.strptime(res['_source']['timestamp'], '%Y-%m-%dT%H:%M:%S') # for data before Oct. 15 2016\n",
    "    dt=datetime.utcfromtimestamp(res['_source']['timestamp']/1000.0)\n",
    "    ts = (dt - epoch).total_seconds() * 1000.0\n",
    "    s=site1[res['_source']['src']]\n",
    "    data1[s].set_value(ts, 'timestamp', dt)\n",
    "    column_type = res['_type']\n",
    "    if column_type == 'packet_loss_rate':\n",
    "        data1[s].set_value( ts, 'packet_loss', res['_source']['packet_loss'])\n",
    "    #if count<2: print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site2 = {srcSiteOWDServer2: sS2, destSiteOWDServer2:dS2}\n",
    "data2 = {sS2:pd.DataFrame(),dS2:pd.DataFrame()}\n",
    "epoch = datetime.utcfromtimestamp(0)\n",
    "count = 0\n",
    "print(epoch)\n",
    "\n",
    "for res in scroll2:\n",
    "    if count<10: print(res)\n",
    "    count += 1\n",
    "#     dt=datetime.strptime(res['_source']['timestamp'], '%Y-%m-%dT%H:%M:%S') # for data before Oct. 15 2016\n",
    "    dt=datetime.utcfromtimestamp(res['_source']['timestamp']/1000.0)\n",
    "    ts = (dt - epoch).total_seconds() * 1000.0\n",
    "    s=site2[res['_source']['src']]\n",
    "    data2[s].set_value(ts, 'timestamp', dt)\n",
    "    column_type = res['_type']\n",
    "    if column_type == 'packet_loss_rate':\n",
    "        data2[s].set_value( ts, 'packet_loss', res['_source']['packet_loss'])\n",
    "    #if count<2: print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site3 = {srcSiteOWDServer3: sS3, destSiteOWDServer3:dS3}\n",
    "data3 = {sS3:pd.DataFrame(),dS3:pd.DataFrame()}\n",
    "epoch = datetime.utcfromtimestamp(0)\n",
    "count = 0\n",
    "print(epoch)\n",
    "\n",
    "for res in scroll3:\n",
    "    if count<10: print(res)\n",
    "    count += 1\n",
    "#     dt=datetime.strptime(res['_source']['timestamp'], '%Y-%m-%dT%H:%M:%S') # for data before Oct. 15 2016\n",
    "    dt=datetime.utcfromtimestamp(res['_source']['timestamp']/1000.0)\n",
    "    ts = (dt - epoch).total_seconds() * 1000.0\n",
    "    s=site3[res['_source']['src']]\n",
    "    data3[s].set_value(ts, 'timestamp', dt)\n",
    "    column_type = res['_type']\n",
    "    if column_type == 'packet_loss_rate':\n",
    "        data3[s].set_value( ts, 'packet_loss', res['_source']['packet_loss'])\n",
    "    #if count<2: print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site4 = {srcSiteOWDServer4: sS4, destSiteOWDServer4:dS4}\n",
    "data4 = {sS4:pd.DataFrame(),dS4:pd.DataFrame()}\n",
    "epoch = datetime.utcfromtimestamp(0)\n",
    "count = 0\n",
    "print(epoch)\n",
    "\n",
    "for res in scroll4:\n",
    "    if count<10: print(res)\n",
    "    count += 1\n",
    "#     dt=datetime.strptime(res['_source']['timestamp'], '%Y-%m-%dT%H:%M:%S') # for data before Oct. 15 2016\n",
    "    dt=datetime.utcfromtimestamp(res['_source']['timestamp']/1000.0)\n",
    "    ts = (dt - epoch).total_seconds() * 1000.0\n",
    "    s=site4[res['_source']['src']]\n",
    "    data4[s].set_value(ts, 'timestamp', dt)\n",
    "    column_type = res['_type']\n",
    "    if column_type == 'packet_loss_rate':\n",
    "        data4[s].set_value( ts, 'packet_loss', res['_source']['packet_loss'])\n",
    "    #if count<2: print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site5 = {srcSiteOWDServer5: sS5, destSiteOWDServer5:dS5}\n",
    "data5 = {sS5:pd.DataFrame(),dS5:pd.DataFrame()}\n",
    "epoch = datetime.utcfromtimestamp(0)\n",
    "count = 0\n",
    "print(epoch)\n",
    "\n",
    "for res in scroll5:\n",
    "    if count<10: print(res)\n",
    "    count += 1\n",
    "#     dt=datetime.strptime(res['_source']['timestamp'], '%Y-%m-%dT%H:%M:%S') # for data before Oct. 15 2016\n",
    "    dt=datetime.utcfromtimestamp(res['_source']['timestamp']/1000.0)\n",
    "    ts = (dt - epoch).total_seconds() * 1000.0\n",
    "    s=site5[res['_source']['src']]\n",
    "    data5[s].set_value(ts, 'timestamp', dt)\n",
    "    column_type = res['_type']\n",
    "    if column_type == 'packet_loss_rate':\n",
    "        data5[s].set_value( ts, 'packet_loss', res['_source']['packet_loss'])\n",
    "    #if count<2: print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(\"hi\")\n",
    "# exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1[sS1].sort_index(inplace=True) \n",
    "data1[sS1].describe()\n",
    "\n",
    "print(data1[sS1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2[sS2].sort_index(inplace=True) \n",
    "data2[sS2].describe()\n",
    "\n",
    "print(data2[sS2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3[sS3].sort_index(inplace=True) \n",
    "data3[sS3].describe()\n",
    "\n",
    "print(data3[sS3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data4[sS4].sort_index(inplace=True) \n",
    "data4[sS4].describe()\n",
    "\n",
    "print(data4[sS4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data5[sS5].sort_index(inplace=True) \n",
    "data5[sS5].describe()\n",
    "\n",
    "print(data5[sS5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F1 = data1[sS1]\n",
    "Fpl1 = F1[F1.packet_loss.notnull()]\n",
    "\n",
    "#print(Fpl)\n",
    "print(Fpl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F2 = data2[sS2]\n",
    "Fpl2 = F2[F2.packet_loss.notnull()]\n",
    "\n",
    "#print(Fpl)\n",
    "print(Fpl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F3 = data3[sS3]\n",
    "Fpl3 = F3[F3.packet_loss.notnull()]\n",
    "\n",
    "#print(Fpl)\n",
    "print(Fpl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F4 = data4[sS4]\n",
    "Fpl4 = F4[F4.packet_loss.notnull()]\n",
    "\n",
    "#print(Fpl)\n",
    "print(Fpl4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F5 = data5[sS5]\n",
    "Fpl5 = F5[F5.packet_loss.notnull()]\n",
    "\n",
    "#print(Fpl)\n",
    "print(Fpl5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#### interpolate all the values and leave only onese where all 4 measurements are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NF=F.interpolate(method='index',limit=1,limit_direction='both')\n",
    "# NFall = NF[NF.packet_loss.notnull()]\n",
    "\n",
    "# print(NFall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(NF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( 'packet loss forward: ', Fpl1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( 'packet loss forward: ', Fpl2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( 'packet loss forward: ', Fpl3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( 'packet loss forward: ', Fpl4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( 'packet loss forward: ', Fpl5.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16, 17])\n",
    "gs = gridspec.GridSpec(4, 1)\n",
    "\n",
    "ax0 = plt.subplot(gs[1])\n",
    "ax0.plot(Fpl1.timestamp.tolist(), np.sqrt(Fpl1.packet_loss).tolist(), ls='', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax0.set_xlabel('time')\n",
    "ax0.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax0.legend()\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.plot(Fpl2.timestamp.tolist(), np.sqrt(Fpl2.packet_loss).tolist(), ls='', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax2.set_xlabel('time')\n",
    "ax2.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax2.legend()\n",
    "\n",
    "ax4 = plt.subplot(gs[1])\n",
    "ax4.plot(Fpl4.timestamp.tolist(), np.sqrt(Fpl4.packet_loss).tolist(), ls='', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax4.set_xlabel('time')\n",
    "ax4.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax4.legend()\n",
    "\n",
    "ax6 = plt.subplot(gs[1])\n",
    "ax6.plot(Fpl6.timestamp.tolist(), np.sqrt(Fpl6.packet_loss).tolist(), ls='', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax6.set_xlabel('time')\n",
    "ax6.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax6.legend()\n",
    "\n",
    "ax8 = plt.subplot(gs[1])\n",
    "ax8.plot(Fpl8.timestamp.tolist(), np.sqrt(Fpl8.packet_loss).tolist(), ls='', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax8.set_xlabel('time')\n",
    "ax8.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax8.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fpl1.set_index('timestamp').join(Fpl2.set_index('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Fpl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Hi\")\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "# predicted_flag_array = np.zeros((24*3600), dtype=np.int)\n",
    "# auc_score_array = np.zeros((24*3600), dtype=np.float)\n",
    "# score_holder_array = np.zeros(3600, dtype=np.float)\n",
    "# anomaly_array = np.ones(3600, dtype=np.int)\n",
    "# not_anomaly_array = np.zeros(3600, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_series = 1\n",
    "start_date = '2017-08-14 00:00:00'\n",
    "end_date = '2017-08-21 23:59:59'\n",
    "\n",
    "window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_anomaly(ref, sub):\n",
    "    \n",
    "    y_ref = pd.Series([0] * ref.shape[0])\n",
    "    X_ref = ref\n",
    "    del X_ref['auc_score']\n",
    "    \n",
    "    y_sub = pd.Series([1] * sub.shape[0])\n",
    "    X_sub=sub\n",
    "    del X_sub['auc_score']\n",
    "    \n",
    "    # separate Reference and Subject into Train and Test\n",
    "    X_ref_train, X_ref_test, y_ref_train, y_ref_test = train_test_split(X_ref, y_ref, test_size=0.3, random_state=50)\n",
    "    X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_sub, y_sub, test_size=0.3, random_state=50)\n",
    "    \n",
    "    # combine training ref and sub samples\n",
    "    X_train = pd.concat([X_ref_train, X_sub_train])\n",
    "    y_train = pd.concat([y_ref_train, y_sub_train])\n",
    "\n",
    "    # combine testing ref and sub samples\n",
    "    X_test = pd.concat([X_ref_test, X_sub_test])\n",
    "    y_test = pd.concat([y_ref_test, y_sub_test])\n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators=50)\n",
    "    \n",
    "    #train an AdaBoost model to be able to tell the difference between the reference and subject data\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Predict using the combined test data\n",
    "    y_predict = clf.predict(X_test)\n",
    "    \n",
    "    # scores = cross_val_score(clf, X, y)\n",
    "    # print(scores)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict) # calculate the false positive rate and true positive rate\n",
    "    auc_score = auc(fpr, tpr) #calculate the AUC score\n",
    "    print ( \"auc_score = \", auc_score, \"\\tfeature importances:\", clf.feature_importances_)\n",
    "    \n",
    "    if auc_score > 0.55: \n",
    "        plot_roc(fpr, tpr, auc_score)\n",
    "        #filename='tree_'+sub.index.min().strftime(\"%Y-%m-%d_%H\")\n",
    "        #tree.export_graphviz(clf.estimators_[0] , out_file=filename +'_1.dot') \n",
    "        #tree.export_graphviz(clf.estimators_[1] , out_file=filename +'_2.dot') \n",
    "        \n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr,tpr, roc_auc):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='r',label='Luck', alpha=.8)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = Fpl['timestamp'].min()\n",
    "print(start_date)\n",
    "end_date = Fpl['timestamp'].max()\n",
    "print(end_date)\n",
    "\n",
    "#print(Fpl.index/1000 - 1502668800.0)\n",
    "\n",
    "Fpl2 = Fpl.set_index('timestamp')\n",
    "Fpl2['auc_score']=0.5\n",
    "print(Fpl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Fpl2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find min and max timestamps\n",
    "\n",
    "start = Fpl2.index.min()\n",
    "end = Fpl2.index.max()\n",
    "\n",
    "#round start \n",
    "start.seconds=0\n",
    "start.minutes=0\n",
    "\n",
    "ref = window * Hour()\n",
    "sub = 1 * Hour()\n",
    "\n",
    "# loop over them\n",
    "ti=start+ref+sub\n",
    "count=0\n",
    "while ti < end + 1 * Minute():\n",
    "    ref_start = ti-ref-sub\n",
    "    ref_end = ti-sub\n",
    "    ref_df = Fpl2[(Fpl2.index >= ref_start) & (Fpl2.index < ref_end)]\n",
    "    #print('ref_df = ', ref_df)\n",
    "    #print(\"In while loop: ref_df: \", ref_df)\n",
    "    sub_df = Fpl2[(Fpl2.index >= ref_end) & (Fpl2.index < ti)]\n",
    "    #print('sub_df = ', sub_df)\n",
    "    #print(\"In while loop: sub_df: \", sub_df)\n",
    "    \n",
    "    ref_count = ref_df.shape[0]\n",
    "    sub_count = sub_df.shape[0] \n",
    "    if ref_count < 10 or sub_count < 3:\n",
    "        auc_score == 0.5\n",
    "        ti = ti + sub\n",
    "        count=count+1\n",
    "        continue\n",
    "    \n",
    "    print(\"timestamp = \", ref_end)\n",
    "    auc_score = check_for_anomaly(ref_df, sub_df)\n",
    "    Fpl2.loc[(Fpl2.index>=ref_end) & (Fpl2.index<=ti),['auc_score']] = auc_score\n",
    "    #print(ti,\"\\trefes:\" , ref_df.shape[0], \"\\tsubjects:\", sub_df.shape[0], '\\tauc:', auc_score)\n",
    "    ti = ti + sub\n",
    "    count=count+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fpl2.plot(figsize=(20,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "Fpl2.loc[:,'Detected'] = 0\n",
    "Fpl2.loc[Fpl2.auc_score>0.55,'Detected']=1\n",
    "Fpl2.head()\n",
    "#ax.plot(Fpl2.Flag, 'r')\n",
    "ax.plot(Fpl2.auc_score,'g')\n",
    "ax.fill( Fpl2.Detected, 'b', alpha=0.3)\n",
    "ax.plot(Fpl.timestamp.tolist(), np.sqrt(Fpl.packet_loss).tolist(), ls='', linestyle='-', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Fpl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fpl2_avg_auc_holder = Fpl2.auc_score\n",
    "#Fpl2_avg_auc = Fpl2_avg_auc_holder[:'2017-08-15 00:00:00']\n",
    "#Fpl2_avg_auc.mean()\n",
    "#ref_start_df = pd.DataFrame(columns=['timestamp'])\n",
    "\n",
    "#columns1 = ['timestamp', 'auc_score']\n",
    "#ref_start_df = pd.DataFrame(columns=columns1) \n",
    "#ref_start_df.set_index('timestamp')\n",
    "\n",
    "#print(ref_start_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fpl2_avg_pkt_holder = Fpl2.packet_loss\n",
    "#holds all the auc scores\n",
    "\n",
    "timestamp_np = np.array([])\n",
    "pkt_score_np = np.array([])\n",
    "\n",
    "start = Fpl2.index.min()\n",
    "end = Fpl2.index.max()\n",
    "\n",
    "#round start \n",
    "start.seconds=0\n",
    "start.minutes=0\n",
    "\n",
    "ref = window * Hour()\n",
    "sub = 1 * Hour()\n",
    "\n",
    "# loop over them\n",
    "ti=start\n",
    "count=0\n",
    "while ti < end + 1 * Minute():\n",
    "#while start < end:\n",
    "    ref_start = ti\n",
    "    ref_end = ti+sub\n",
    "    \n",
    "    \n",
    "    timestamp_np = np.append(timestamp_np, ref_start)\n",
    "    #create a dataframe that stores the starting time of the each hour\n",
    "    \n",
    "    Fpl2_avg_pkt = math.sqrt(Fpl2_avg_pkt_holder[ref_start:ref_end].mean())\n",
    "    #average packet loss score for every hour    \n",
    "    \n",
    "    pkt_score_np = np.append(pkt_score_np, Fpl2_avg_pkt)\n",
    "    \n",
    "    #start = start + sub\n",
    "    \n",
    "    ti = ti + sub\n",
    "    #count=count+1\n",
    "    #if count>2: break\n",
    "\n",
    "timestamp1_df = pd.DataFrame(timestamp_np[:], columns=['timestamp'])\n",
    "pkt_score1_df = pd.DataFrame(pkt_score_np[:], columns=['avg_packet_loss'])\n",
    "\n",
    "pkt_avg_df1 = pd.concat([timestamp1_df, pkt_score1_df], axis=1)\n",
    "\n",
    "pkt_avg_df2 = pkt_avg_df1.set_index('timestamp')\n",
    "\n",
    "print(pkt_avg_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkt_avg_df2.plot(figsize=(20,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ax = pkt_avg_df2.plot()\n",
    "# Fpl2.loc[:,'Detected'] = 0\n",
    "# Fpl2.loc[Fpl2.auc_score>0.51,'Detected']=1\n",
    "# Fpl2.plot(ax=ax, figsize=(20,7))\n",
    "# ax.fill( Fpl2.Detected, 'b', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "Fpl2.loc[:,'Detected'] = 0\n",
    "Fpl2.loc[Fpl2.auc_score>0.55,'Detected']=1\n",
    "Fpl2.head()\n",
    "#ax.plot(Fpl2.Flag, 'r')\n",
    "ax.plot(Fpl2.auc_score,'g')\n",
    "ax.fill( Fpl2.Detected, 'b', alpha=0.3)\n",
    "ax.plot(timestamp1_df, pkt_avg_df2, ls='', linestyle='-', marker='.', c='r', label=sS+'->'+dS)\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('sqrt(packet loss) [%]')\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.4 GPU ML",
   "language": "python",
   "name": "sys_kernel_py3.4_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
