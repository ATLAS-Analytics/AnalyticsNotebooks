{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **{'size': 12})\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import datetime\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch.helpers import scan\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "es = Elasticsearch([{'host':'atlas-kibana.mwt2.org', 'port':9200}],timeout=60)\n",
    "\n",
    "benchmark_indices = ['fts_*']\n",
    "daysOfData=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497.832622051239\n",
      "27734735\n"
     ]
    }
   ],
   "source": [
    "#Get data from elasticsearch - all done transfers for 9 days\n",
    "transfer_query = {\n",
    "    \"size\": 0,\n",
    "    \"_source\": [\"src_rse\", \"dst_rse\", \"activity\",\"bytes\",\"submitted_at\",\"started_at\",\"transferred_at\"],\n",
    "    'query':{\n",
    "            'bool':{\n",
    "                   'should':[\n",
    "                       { \"term\": {\"_type\": \"transfer-done\" } }\n",
    "                   ]\n",
    "            }\n",
    "    }\n",
    "                \n",
    "}\n",
    "data=[]\n",
    "scroll = scan(client=es, index='fts_2017-01-31,fts_2017-02-01,fts_2017-02-02,fts_2017-02-03,fts_2017-02-04,fts_2017-02-05,fts_2017-02-06,fts_2017-02-07,fts_2017-02-08,', query=transfer_query, scroll='5m', timeout=\"5m\", size=10000)\n",
    "st = time.time()\n",
    "for res in scroll:\n",
    "    r = res['_source']\n",
    "    r['submitted_at'] = (dt.datetime.strptime(r['submitted_at'].strip('Z').split('.')[0], '%Y-%m-%dT%H:%M:%S') - dt.datetime(1970,1,1)).total_seconds()\n",
    "    r['started_at'] = (dt.datetime.strptime(r['started_at'].strip('Z').split('.')[0], '%Y-%m-%dT%H:%M:%S') - dt.datetime(1970,1,1)).total_seconds()\n",
    "    r['transferred_at'] = (dt.datetime.strptime(r['transferred_at'].strip('Z').split('.')[0], '%Y-%m-%dT%H:%M:%S') - dt.datetime(1970,1,1)).total_seconds()\n",
    "    data.append([r['src_rse'],r['dst_rse'],r['activity'],r['bytes'],r['submitted_at'],r['started_at'],r['transferred_at']])\n",
    "print(time.time() - st)\n",
    "data = pd.DataFrame(data, columns=['SRC', 'DST', 'ACT', 'SIZE', 'SUBMITTED', 'STARTED', 'ENDED'])\n",
    "data['QUEUE_T'] = data.STARTED - data.SUBMITTED\n",
    "data['NET_T'] = data.ENDED - data.STARTED\n",
    "print(len(data))\n",
    "data.to_csv('transfers_2017-02-01_07.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(data.STARTED.values[:1500000], (data.ENDED - data.STARTED).values[:1500000], '.')\n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(17, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the model - Return the average queue time and network time for each link\n",
    "# filter outliers (queue_t > 170 hours and net_t > 200 minutes)\n",
    "data = data.where(data.QUEUE_T/60/60 < 170).dropna()\n",
    "data = data.where(data.NET_T/60 < 200).dropna()\n",
    "links = {}\n",
    "for index,row in data.iterrows():\n",
    "    link = row.SRC + ' ' + row.DST + ' ' + row.ACT\n",
    "    if link not in links.keys():\n",
    "        links[link] = 0\n",
    "        cut = data.where(data.SRC == row.SRC).dropna()\n",
    "        cut = cut.where(cut.DST == row.DST).dropna()\n",
    "        cut = cut.where(cut.ACT == row.ACT).dropna()\n",
    "        links[link] = (cut.QUEUE_T.mean(), cut.NET_T.mean(), len(cut))\n",
    "        #print (link,cut.QUEUE_T.mean(), cut.NET_T.mean(), len(cut), sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20867050"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = data.where(data.STARTED >= 1485907200).dropna()\n",
    "d = d.where(d.STARTED <= 1486512000).dropna()\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9492"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(links, open('dumb_model2.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
