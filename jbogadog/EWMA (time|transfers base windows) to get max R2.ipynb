{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#matplotlib stuff\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **{'size': 12})\n",
    "\n",
    "# other imports\n",
    "import datetime\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch.helpers import scan\n",
    "import datetime as dt\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from scipy.optimize import minimize,differential_evolution\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get AGIS endpoints (RSEs) and site names\n",
    "r = requests.get('http://atlas-agis-api.cern.ch/request/site/query/list/ddmendpoints?json')\n",
    "j = r.json()\n",
    "#Create RSE to site name dictionary\n",
    "rse2site = {}\n",
    "for i in j:\n",
    "    for ep in i['ddmendpoints']:\n",
    "        rse2site[ep]=i['name']\n",
    "\n",
    "def get_link_data(src, dst, act, date='2017-08-01', span=1):\n",
    "    es = Elasticsearch([{'host':'atlas-kibana.mwt2.org', 'port':9200}],timeout=60)\n",
    "    DATE = date  # yyyy-mm-dd\n",
    "    DELTA = span\n",
    "    # Generate the indexes to scan\n",
    "    dt.datetime.strptime(DATE,'%Y-%m-%d')\n",
    "    index_list = []\n",
    "    for i in range(-1, DELTA+1):\n",
    "        index_list.append('fts_'+(dt.datetime.strptime(DATE,'%Y-%m-%d')\n",
    "                          + dt.timedelta(days=i)).strftime('%Y-%m-%d'))\n",
    "    #indexes = ','.join(index_list)\n",
    "    indexes = 'fts_*'\n",
    "    #print (index_list)\n",
    "    period_start = dt.datetime.strptime(DATE,'%Y-%m-%d')\n",
    "    period_end = dt.datetime.strptime(DATE,'%Y-%m-%d') + dt.timedelta(days=span)\n",
    "    transfer_query = {\n",
    "        \"size\": 0,\n",
    "        \"_source\": [\"src_rse\", \"dst_rse\", \"activity\",\"bytes\",\"submitted_at\",\"started_at\",\"transferred_at\"],\n",
    "        'query':{\n",
    "            \"bool\" : {\n",
    "                \"must\" : [\n",
    "                    {\"term\" : { \"dst\" : src }},\n",
    "                    {\"term\" : { \"src\" : dst }},\n",
    "                    {\"term\" : { \"activity\" : act }},\n",
    "                    {\"range\" : {\"transferred_at\" : {  \"gte\": period_start } }},\n",
    "                    {\"range\" : {\"submitted_at\" :   {  \"lt\" : period_end } }}\n",
    "                    ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "    scroll = scan(client=es, index=indexes, query=transfer_query, scroll='5m', timeout=\"5m\", size=10000)\n",
    "    epoch = dt.datetime(1970,1,1)\n",
    "    st = time.time()\n",
    "    count = 0\n",
    "    data = []\n",
    "    for res in scroll:\n",
    "        r = res['_source']\n",
    "        #if not count%1000000 : print (count)\n",
    "        r['submitted_at'] = (dt.datetime.strptime(r['submitted_at'].strip('Z').split('.')[0], '%Y-%m-%dT%H:%M:%S') - epoch).total_seconds()\n",
    "        r['started_at'] = (dt.datetime.strptime(r['started_at'].strip('Z').split('.')[0], '%Y-%m-%dT%H:%M:%S') - epoch).total_seconds()\n",
    "        r['transferred_at'] = (dt.datetime.strptime(r['transferred_at'].strip('Z').split('.')[0], '%Y-%m-%dT%H:%M:%S') - epoch).total_seconds()\n",
    "        data.append([rse2site[r['src_rse']]+'__'+rse2site[r['dst_rse']]+'__'+r['activity'],r['bytes'],r['submitted_at'],r['started_at'],r['transferred_at']])\n",
    "        count += 1\n",
    "    #print('Reading took',time.time() - st,'seconds.')\n",
    "    data = pd.DataFrame(data, columns=['LINK', 'SIZE', 'SUBMITTED', 'STARTED', 'ENDED'])\n",
    "    data['Q_TIME'] = data['STARTED'] - data['SUBMITTED']\n",
    "    data['N_RATE'] = data.SIZE/(data['ENDED'] - data['STARTED'])\n",
    "    data['T_TIME'] = data['ENDED'] - data['SUBMITTED']\n",
    "    print('%d records retrieved for link %s --> %s (%s).' % (len(data), src, dst, act))\n",
    "    return data\n",
    "def holt_winters_second_order_ewma( x, span, beta ):\n",
    "    N = x.size\n",
    "    alpha = 2.0 / ( 1 + span )\n",
    "    s = np.zeros(( N, ))\n",
    "    b = np.zeros(( N, ))\n",
    "    s[0] = x[0]\n",
    "    for i in range( 1, N ):\n",
    "        s[i] = alpha * x[i] + ( 1 - alpha )*( s[i-1] + b[i-1] )\n",
    "        b[i] = beta * ( s[i] - s[i-1] ) + ( 1 - beta ) * b[i-1]\n",
    "    return s[-1],b[-1]\n",
    "def hwsoewma_forcast(s0, b0, beta, span):\n",
    "    '''Forcast span values after s0'''\n",
    "    s = [s0]\n",
    "    b = [b0]\n",
    "    queue_limit_time = 7*24*60*60  # 7 days in sec.\n",
    "    for i in range(1,span):\n",
    "        s.append(min((s[i-1] + i*b[i-1]),queue_limit_time))\n",
    "        b.append(beta*(s[i] - s[i-1])+(1-beta)*b[i-1])\n",
    "    return (s,b)\n",
    "\n",
    "def calculate_ewma(window=12, beta=0.1):\n",
    "    preds = []\n",
    "    for t in data.index:\n",
    "        history = cut[cut.index < t]\n",
    "        history = history[history.index > history.index.max() - dt.timedelta(hours=windows)]\n",
    "        if len(history) > 3:\n",
    "            s0,b0 = holt_winters_second_order_ewma(history.Q_TIME.values, len(history.Q_TIME.values), beta)\n",
    "            s,b = hwsoewma_forcast(s0, b0, beta, 1)\n",
    "            preds.append(max(s[0],-1))\n",
    "        else:\n",
    "            preds.append(-1)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def make_prediction_time(data, window, every, beta):\n",
    "    cut1 = data.set_index(pd.to_datetime(data.SUBMITTED, unit='s'))\n",
    "    cut1 = cut1.sort_index()\n",
    "    cut2 = data.set_index(pd.to_datetime(data.ENDED, unit='s'))\n",
    "    cut2 = cut2.sort_index()\n",
    "    current = cut1.index.min()\n",
    "    preds = []\n",
    "    while current < cut1.index.max():\n",
    "        subcut = cut1[cut1.index < current + dt.timedelta(minutes=every)]\n",
    "        subcut = subcut[subcut.index > current]\n",
    "        fspan = len(subcut)\n",
    "        if fspan == 0:\n",
    "            current = current + dt.timedelta(minutes=every)\n",
    "            continue\n",
    "        history = cut2[cut2.index < current]\n",
    "        history = history[history.index > history.index.max() - dt.timedelta(minutes=window)]\n",
    "        if len(history) > 0:\n",
    "            s0,b0 = holt_winters_second_order_ewma(history.Q_TIME.values, len(history.Q_TIME.values), beta)\n",
    "            s1,b = hwsoewma_forcast(s0, b0, beta, len(subcut))\n",
    "            preds.extend(s1)\n",
    "        else:\n",
    "            preds.extend([-1]*len(subcut))\n",
    "        current = current + dt.timedelta(minutes=every)\n",
    "    return cut1.SUBMITTED.values[:len(preds)],np.array(preds), cut1.Q_TIME.values[:len(preds)]\n",
    "\n",
    "\n",
    "def make_prediction_transfer(data, window, every, beta):\n",
    "    cut1 = data.set_index(pd.to_datetime(data.SUBMITTED, unit='s'))\n",
    "    cut1 = cut1.sort_index()\n",
    "    cut2 = data.set_index(pd.to_datetime(data.ENDED, unit='s'))\n",
    "    cut2 = cut2.sort_index()\n",
    "    current = cut1.index.min()\n",
    "    preds = []\n",
    "    while current < cut1.index.max():\n",
    "        s = cut1[cut1.index < current + dt.timedelta(minutes=every)]\n",
    "        s = s[s.index > current]\n",
    "        fspan = len(s)\n",
    "        if fspan == 0:\n",
    "            current = current + dt.timedelta(minutes=every)\n",
    "            continue\n",
    "        history = cut2[cut2.index < current]\n",
    "        #history = history.set_index(pd.to_datetime(history.ENDED.values,unit='s'))\n",
    "        #history = history.sort_index()\n",
    "        history = history.loc[history.index[-window:]]\n",
    "        if len(history) > 3:\n",
    "            s0,b0 = holt_winters_second_order_ewma(history.Q_TIME.values, len(history.Q_TIME.values), beta)\n",
    "            s1,b = hwsoewma_forcast(s0, b0, beta, len(s))\n",
    "            preds.extend(s1)\n",
    "        else:\n",
    "            preds.extend([-1]*len(s))\n",
    "        current = current + dt.timedelta(minutes=every)\n",
    "    return cut1.SUBMITTED.values[:len(preds)],np.array(preds), cut1.Q_TIME.values[:len(preds)]\n",
    "\n",
    "def opt_transfer(x, *args):\n",
    "    window = int(round(x[0]))\n",
    "    every = 5\n",
    "    beta = 0.0000\n",
    "    x,y,y_real = make_prediction_transfer(data, window, every, beta)\n",
    "    y = np.array([np.nan_to_num(i) for i in y])\n",
    "    R = abs(r2(y_real,y) - 1)\n",
    "    MAE = np.log10(mae(y_real,y))\n",
    "    return R + MAE\n",
    "\n",
    "def opt_time(x, *args):\n",
    "    window = int(round(x[0]))\n",
    "    every = 5\n",
    "    beta = 0.0000\n",
    "    x,y,y_real = make_prediction_time(data, window, every, beta)\n",
    "    y = np.array([np.nan_to_num(i) for i in y])\n",
    "    R = abs(r2(y_real,y) - 1)\n",
    "    MAE = np.log10(mae(y_real,y))\n",
    "    return R + MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39466 records retrieved for link BNL-ATLAS --> CERN-PROD (Data Consolidation).\n",
      "Estimated time to calculate: 89 minutes\n",
      "Time to calculate: 62.09 minutes\n"
     ]
    }
   ],
   "source": [
    "# link to test\n",
    "st = time.time()\n",
    "src = 'BNL-ATLAS'\n",
    "dst = 'CERN-PROD'\n",
    "act = 'Data Consolidation'\n",
    "data = get_link_data(src,dst,act,'2017-08-01', 7)\n",
    "print('Estimated time to calculate: %d minutes'% (len(data)/441.7))\n",
    "res_transf = differential_evolution(opt_transfer,[(1,1000)], args=(data))\n",
    "res_time = differential_evolution(opt_time,[(1,10000)], args=(data))\n",
    "print('Time to calculate: %0.2f minutes'%((time.time()-st)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 4.8500704366606042\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 62\n",
       "     nit: 3\n",
       " success: True\n",
       "       x: array([ 575.27161605])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#res for window transfers based on transfers...\n",
    "res_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 4.7424710604175715\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 107\n",
       "     nit: 6\n",
       " success: True\n",
       "       x: array([ 1529.85655847])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#res for window transfers based on time...\n",
    "res_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
