{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400000 samples, validate on 160000 samples\n",
      "Epoch 1/100\n",
      "400000/400000 [==============================] - 6s - loss: 0.6446 - acc: 0.8214 - val_loss: 0.3069 - val_acc: 0.9354\n",
      "Epoch 2/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.2543 - acc: 0.9438 - val_loss: 0.2178 - val_acc: 0.9491\n",
      "Epoch 3/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.1940 - acc: 0.9537 - val_loss: 0.1744 - val_acc: 0.9579\n",
      "Epoch 4/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.1605 - acc: 0.9598 - val_loss: 0.1458 - val_acc: 0.9641\n",
      "Epoch 5/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.1354 - acc: 0.9658 - val_loss: 0.1262 - val_acc: 0.9667\n",
      "Epoch 6/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.1131 - acc: 0.9728 - val_loss: 0.0997 - val_acc: 0.9788\n",
      "Epoch 7/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0941 - acc: 0.9801 - val_loss: 0.0859 - val_acc: 0.9815\n",
      "Epoch 8/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0781 - acc: 0.9867 - val_loss: 0.0655 - val_acc: 0.9918\n",
      "Epoch 9/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0623 - acc: 0.9931 - val_loss: 0.0550 - val_acc: 0.9950\n",
      "Epoch 10/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0522 - acc: 0.9959 - val_loss: 0.0460 - val_acc: 0.9979\n",
      "Epoch 11/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0433 - acc: 0.9982 - val_loss: 0.0389 - val_acc: 0.9989\n",
      "Epoch 12/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0391 - acc: 0.9983 - val_loss: 0.0335 - val_acc: 0.9994\n",
      "Epoch 13/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0326 - acc: 0.9994 - val_loss: 0.0306 - val_acc: 0.9997\n",
      "Epoch 14/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0311 - acc: 0.9989 - val_loss: 0.0297 - val_acc: 0.9998\n",
      "Epoch 15/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0263 - acc: 0.9997 - val_loss: 0.0243 - val_acc: 0.9999\n",
      "Epoch 16/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0241 - acc: 0.9997 - val_loss: 0.0231 - val_acc: 0.9997\n",
      "Epoch 17/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0327 - acc: 0.9972 - val_loss: 0.1487 - val_acc: 0.9633\n",
      "Epoch 18/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0233 - acc: 0.9992 - val_loss: 0.0198 - val_acc: 0.9999\n",
      "Epoch 19/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0193 - acc: 0.9999 - val_loss: 0.0188 - val_acc: 0.9999\n",
      "Epoch 20/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0183 - acc: 0.9999 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0173 - acc: 0.9999 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0162 - acc: 0.9999 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0149 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0655 - acc: 0.9900 - val_loss: 0.0205 - val_acc: 0.9996\n",
      "Epoch 25/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0174 - acc: 0.9999 - val_loss: 0.0159 - val_acc: 0.9999\n",
      "Epoch 26/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0153 - acc: 0.9999 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0134 - acc: 0.9999 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9999\n",
      "Epoch 29/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0285 - acc: 0.9955 - val_loss: 0.0226 - val_acc: 0.9970\n",
      "Epoch 32/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0119 - acc: 0.9998 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0214 - acc: 0.9968 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0227 - acc: 0.9966 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "400000/400000 [==============================] - 6s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0146 - acc: 0.9981 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000/400000 [==============================] - 5s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0196 - acc: 0.9973 - val_loss: 0.0087 - val_acc: 0.9995\n",
      "Epoch 67/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0071 - acc: 0.9999 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0210 - acc: 0.9970 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0178 - acc: 0.9970 - val_loss: 0.0075 - val_acc: 0.9997\n",
      "Epoch 85/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0067 - acc: 0.9999 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "400000/400000 [==============================] - 4s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "400000/400000 [==============================] - 4s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "400000/400000 [==============================] - 4s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "400000/400000 [==============================] - 4s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "400000/400000 [==============================] - 4s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0675 - acc: 0.9894 - val_loss: 0.0108 - val_acc: 0.9999\n",
      "Epoch 95/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "400000/400000 [==============================] - 5s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "159680/160000 [============================>.] - ETA: 0s\n",
      "acc: 100.00%\n",
      "159008/160000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f785cba3048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from sklearn import metrics\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(1)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"train_dim24.txt\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:55]\n",
    "Y = dataset[:,55]\n",
    "# create model\n",
    "\n",
    "dataset_test = numpy.loadtxt(\"val_dim24.txt\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X_test = dataset_test[:,0:55]\n",
    "Y_test = dataset_test[:,55]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=55, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y,validation_data=(X_test,Y_test), epochs=100, batch_size=512)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "probs = model.predict_proba(X_test)\n",
    "#np.savetxt('testout.txt',probs,delimiter=',')\n",
    "preds = probs[:,0]\n",
    "fpr, tpr, threshold = metrics.roc_curve(Y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('ROC py1')\n",
    "plt.plot(tpr, 1-fpr, 'b')\n",
    "#plt.plot(tpr, fpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "#plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('signal efficiency')\n",
    "plt.ylabel('background rejection')\n",
    "plt.show()\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_test_0506.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_test_0506.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.4 GPU ML",
   "language": "python",
   "name": "sys_kernel_py3.4_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
