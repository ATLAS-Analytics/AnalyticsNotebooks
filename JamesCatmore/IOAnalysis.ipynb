{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These lines set up inline plotting, and apply a standard size\n",
    "# Standard includes\n",
    "from datetime import date,timedelta\n",
    "import re\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Little method to append items to the dictionary\n",
    "def addTo(theDict,jobType,variableName,variable):\n",
    "    if (jobType,variableName) in theDict.keys():\n",
    "        theDict[(jobType,variableName)].append(variable)\n",
    "    else:\n",
    "        theDict[(jobType,variableName)] = [variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time (for setting range)\n",
    "nDays = 300\n",
    "now = date.today()\n",
    "then = now - timedelta(days=nDays)\n",
    "# Set upper limit for number of jobs to process\n",
    "maxHits = 5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define ElasticSearch and the relevant index\n",
    "es = Elasticsearch(['atlas-kibana-dev.mwt2.org'],timeout=120)\n",
    "jobIndex = \"jobs_archive_2018*,jobs_archive_2017*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the trains and the quantities for collection\n",
    "quantities = [\n",
    "    'nevents',\n",
    "    'actualcorecount',\n",
    "    'wall_time',\n",
    "    'inputfilebytes',\n",
    "    'outputfilebytes',\n",
    "    'IObytesReadRate',\n",
    "    'IObytesWriteRate',\n",
    "    'actualcorecount'\n",
    "]\n",
    "\n",
    "to_read = quantities\n",
    "#to_read.append('homepackage')\n",
    "#to_read.append('jobstatus')\n",
    "#to_read.append('transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up query: TOPQ1\n",
    "jobQueryAOD = {\n",
    "    \"_source\": to_read,\n",
    "    \"query\": {\n",
    "        \"bool\":{\n",
    "            \"must\": [\n",
    "                {'range': {'endtime': {'gte': then, 'lt': now}}},\n",
    "                {'range': {'nevents': {'gt': 0.0}}},\n",
    "                {'range': {'wall_time': {'gt': 0.0}}},\n",
    "                {'range': {'IObytesReadRate': {'gt': 0.0}}},\n",
    "                {'range': {'IObytesWriteRate': {'gt': 0.0}}},\n",
    "                {'range': {'inputfilebytes': {'gt': 0.0}}},\n",
    "                {'range': {'outputfilebytes': {'gt': 0.0}}},\n",
    "                {'range': {'actualcorecount': {'gt': 0.0}}},\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\"term\":{\"processingtype\": \"panda-client-0.5.96-jedi-run\"}},\n",
    "                            {\"term\":{\"inputfiletype\": \"AOD\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up query: SUSY2\n",
    "jobQuerySUSY5 = {\n",
    "    \"_source\": to_read,\n",
    "    \"query\": {\n",
    "        \"bool\":{\n",
    "            \"must\": [\n",
    "                {'range': {'endtime': {'gte': then, 'lt': now}}},\n",
    "                {'range': {'nevents': {'gt': 0.0}}},\n",
    "                {'range': {'wall_time': {'gt': 0.0}}},\n",
    "                {'range': {'IObytesReadRate': {'gt': 0.0}}},\n",
    "                {'range': {'IObytesWriteRate': {'gt': 0.0}}},\n",
    "                {'range': {'inputfilebytes': {'gt': 0.0}}},\n",
    "                {'range': {'outputfilebytes': {'gt': 0.0}}},\n",
    "                {'range': {'actualcorecount': {'gt': 0.0}}},\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\"term\":{\"processingtype\": \"panda-client-0.5.96-jedi-run\"}},\n",
    "                            {\"term\":{\"inputfiletype\": \"DAOD_SUSY5\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan the DB\n",
    "jobsAOD = scan(es, query=jobQueryAOD, index=jobIndex, scroll='5m', timeout=\"5m\", size=10000) \n",
    "jobsSUSY5 = scan(es, query=jobQuerySUSY5, index=jobIndex, scroll='5m', timeout=\"5m\", size=10000) \n",
    "allScrolls = [jobsAOD,jobsSUSY5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOD\n",
      "100000.0\n",
      "200000.0\n",
      "300000.0\n",
      "400000.0\n",
      "500000.0\n",
      "600000.0\n",
      "700000.0\n",
      "800000.0\n",
      "900000.0\n",
      "1000000.0\n",
      "1100000.0\n",
      "1200000.0\n",
      "1300000.0\n",
      "AOD 1379514.0\n",
      "Time to extract information =  110.30352593003772\n",
      "SUSY5\n",
      "100000.0\n",
      "200000.0\n",
      "300000.0\n",
      "400000.0\n",
      "500000.0\n",
      "600000.0\n",
      "700000.0\n",
      "800000.0\n",
      "900000.0\n",
      "1000000.0\n",
      "1100000.0\n",
      "1200000.0\n",
      "1300000.0\n",
      "1400000.0\n",
      "SUSY5 1412717.0\n",
      "Time to extract information =  122.61857725982554\n"
     ]
    }
   ],
   "source": [
    "# Loop over the results\n",
    "jobType = \"\"\n",
    "for jobs in allScrolls:\n",
    "    start_time = timeit.default_timer()\n",
    "    if jobs is jobsAOD: jobType = \"AOD\"\n",
    "    if jobs is jobsSUSY5: jobType = \"SUSY5\"\n",
    "    print(jobType)\n",
    "    jobCounter = 0.0\n",
    "    for res in jobs: # Loop over jobs from that task\n",
    "        breakout = False\n",
    "        for item in quantities:\n",
    "            if item not in res['_source'].keys(): breakout = True\n",
    "        if(breakout): continue\n",
    "        cores = res['_source']['actualcorecount']\n",
    "        nevents = res['_source']['nevents']\n",
    "        inputSize = res['_source']['inputfilebytes']\n",
    "        outputSize = res['_source']['outputfilebytes']\n",
    "        wallclock = res['_source']['wall_time']\n",
    "        ioreadrate = res['_source']['IObytesReadRate']\n",
    "        iowriterate = res['_source']['IObytesWriteRate']\n",
    "        if any([wallclock is None, inputSize is None, outputSize is None, nevents is None, ioreadrate is None, iowriterate is None, cores is None]):\n",
    "            continue\n",
    "        nevents = float(nevents)\n",
    "        inputSize = float(inputSize)/1000000.0\n",
    "        outputSize = float(outputSize)/1000000.0\n",
    "        wallclock = float(wallclock)\n",
    "        ioreadrate = float(ioreadrate)/1000000.0\n",
    "        iowriterate = float(iowriterate)/1000000.0\n",
    "        cores = float(cores)\n",
    "        ioIntensity = (inputSize+outputSize)/(wallclock*cores)\n",
    "        eventRate = nevents/wallclock\n",
    "        addTo(data,jobType,\"I/O intensity\",ioIntensity)\n",
    "        addTo(data,jobType,\"Event rate\",eventRate)\n",
    "        addTo(data,jobType,\"IObytesReadRate\",ioreadrate)\n",
    "        addTo(data,jobType,\"IObytesWriteRate\",iowriterate)\n",
    "        jobCounter += 1\n",
    "        if jobCounter % 100000 == 0: print(jobCounter)\n",
    "        if (jobCounter == maxHits): break\n",
    "    print(jobType,jobCounter)\n",
    "    print(\"Time to extract information = \",timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save as pickle\n",
    "pickle.dump(data,open(\"io_analysis.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
