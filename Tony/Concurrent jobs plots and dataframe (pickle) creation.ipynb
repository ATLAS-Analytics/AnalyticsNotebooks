{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, exceptions as es_exceptions\n",
    "from elasticsearch.helpers import scan\n",
    "es = Elasticsearch([{'host':'uct2-es-door.mwt2.org', 'port':9200}])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose date range and pull ES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind=\"stashcp-2016.8\"\n",
    "#undirected\n",
    "myquery1={\n",
    "  \"query\": {\n",
    "    \"filtered\": {\n",
    "      \"query\": {\n",
    "        \"query_string\": {\n",
    "          \"query\": \"*\",\n",
    "          \"analyze_wildcard\": True\n",
    "        }\n",
    "      },\n",
    "      \"filter\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"query\": {\n",
    "                \"query_string\": {\n",
    "                  \"analyze_wildcard\": True,\n",
    "                  \"query\": \"*\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"range\": {\n",
    "                \"timestamp\": {\n",
    "                  \"gte\": 1472130846947,\n",
    "                  \"lte\": 1472150123020,\n",
    "                  \"format\": \"epoch_millis\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "}\n",
    "\n",
    "#undirected\n",
    "myquery2={\n",
    "  \"query\": {\n",
    "    \"filtered\": {\n",
    "      \"query\": {\n",
    "        \"query_string\": {\n",
    "          \"query\": \"*\",\n",
    "          \"analyze_wildcard\": True\n",
    "        }\n",
    "      },\n",
    "      \"filter\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"query\": {\n",
    "                \"query_string\": {\n",
    "                  \"analyze_wildcard\": True,\n",
    "                  \"query\": \"*\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"range\": {\n",
    "                \"timestamp\": {\n",
    "                  \"gte\": 1468002935971,\n",
    "                  \"lte\": 1468005422807,\n",
    "                  \"format\": \"epoch_millis\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  21763\n",
      "['IP', 'cache', 'download_time', 'end1', 'end2', 'filename', 'host', 'sitename', 'start1', 'start2', 'start3', 'status', 'timestamp', 'tries', 'xrdexit1', 'xrdexit2', 'xrdexit3', 'begin']\n",
      "                IP                        cache  download_time           end1  \\\n",
      "0  128.105.245.173  root://stash.osgconnect.net          10949  1472135046335   \n",
      "\n",
      "   end2                                           filename  \\\n",
      "0     0  /user/shenker/public/deploy/deploy.b12ab0a.000...   \n",
      "\n",
      "                          host  sitename         start1  start2  start3  \\\n",
      "0  root://stash.osgconnect.net  GLOW-OSG  1472135035386       0       0   \n",
      "\n",
      "    status      timestamp  tries  xrdexit1  xrdexit2  xrdexit3          begin  \n",
      "0  Success  1472135046000      1         0        -1        -1  1472135035051  \n"
     ]
    }
   ],
   "source": [
    "page= es.search(index=ind, body=myquery1, scroll='2m', search_type='scan', size=1)\n",
    "\n",
    "sid = page['_scroll_id']\n",
    "\n",
    "scroll_size = page['hits']['total']\n",
    "results=[]\n",
    "\n",
    "while (scroll_size > 0):\n",
    "    page = es.scroll(scroll_id = sid, scroll = '2m')\n",
    "    results.append(page['hits']['hits'])\n",
    "    sid = page['_scroll_id']\n",
    "    scroll_size = len(page['hits']['hits'])\n",
    "\n",
    "scroll_size = page['hits']['total']\n",
    "Res=[]\n",
    "for i in range(0,scroll_size):\n",
    "    Res.append(results[i][0]['_source'])\n",
    "    \n",
    "print('Number of records: ', scroll_size)\n",
    "\n",
    "df = pd.DataFrame(Res)\n",
    "#print(df.head(2))\n",
    "\n",
    "del df['destination_space']\n",
    "del df['xrdcp_version']\n",
    "#del df['tries']\n",
    "del df['download_size']\n",
    "del df['filesize']\n",
    "#del df['IP']\n",
    "#del df['xrdcp_exit']\n",
    "\n",
    "begin=[]\n",
    "for i in range(scroll_size):\n",
    "    begin.append((int(df['timestamp'][i])-int(df['download_time'][i]))) #convert to minutes\n",
    "    \n",
    "df['begin']=begin\n",
    "print(list(df.columns.values))\n",
    "print(df.head(1))\n",
    "df.to_pickle('august25.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472133224989\n",
      "1472133224\n",
      "2016-08-25 08:53:44\n"
     ]
    }
   ],
   "source": [
    "begin=int(df['begin'].iloc[1])//1000\n",
    "print(df['begin'].iloc[1])\n",
    "print(begin)\n",
    "print (datetime.datetime.fromtimestamp(begin).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "#print (datetime.datetime.fromtimestamp(df['begin'].iloc[1]).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formate datetime and save dataframe into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "length=df.shape[0]\n",
    "\n",
    "for i in range(length):\n",
    "    begin=int(df['begin'].iloc[i])//1000\n",
    "    end=int(df['timestamp'].iloc[i])//1000\n",
    "    start1=int(df['start1'].iloc[i])//1000\n",
    "    end1=int(df['end1'].iloc[i])//1000\n",
    "    start2=int(df['start2'].iloc[i])//1000\n",
    "    end2=int(df['end2'].iloc[i])//1000\n",
    "    start3=int(df['start3'].iloc[i])//1000\n",
    "    df['begin'].iloc[i]=datetime.datetime.fromtimestamp(begin).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['timestamp'].iloc[i]=datetime.datetime.fromtimestamp(end).strftime('%Y-%m-%d %H:%M:%S')  \n",
    "    df['start1'].iloc[i]=datetime.datetime.fromtimestamp(start1).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['start2'].iloc[i]=datetime.datetime.fromtimestamp(start2).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['start3'].iloc[i]=datetime.datetime.fromtimestamp(start3).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['end1'].iloc[i]=datetime.datetime.fromtimestamp(end1).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['end2'].iloc[i]=datetime.datetime.fromtimestamp(end2).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    \n",
    "df=df.set_index(['timestamp'])    \n",
    "df.index = pd.to_datetime(df.index, unit='s')\n",
    "df['begin']=pd.to_datetime(df['begin'], unit='s')\n",
    "df['start1']=pd.to_datetime(df['start1'], unit='s')\n",
    "df['start2']=pd.to_datetime(df['start2'], unit='s')\n",
    "df['start3']=pd.to_datetime(df['start3'], unit='s')\n",
    "df['end1']=pd.to_datetime(df.end1, unit='s')\n",
    "df['end2']=pd.to_datetime(df.end2, unit='s')\n",
    "df\n",
    "#df.to_pickle('august25.pkl')\n",
    "print ('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to find concurrent jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivukotic/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).sum()\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "jobs = pd.concat([pd.Series(1, df.begin), pd.Series(-1, df.index)]).resample('1Min', how='sum').cumsum()\n",
    "index=jobs.index\n",
    "\n",
    "df2=pd.DataFrame(columns=['index', 'Origin', 'Nebraska', 'UCSD', 'US-MWT2_UIUC', 'BNL ATLAS', 'FZU', 'Trunk'])\n",
    "finish=pd.DataFrame(columns=['index', 'Origin', 'Nebraska', 'UCSD', 'US-MWT2_UIUC', 'BNL ATLAS', 'FZU', 'Trunk'])\n",
    "\n",
    "df2['index']=index\n",
    "finish['index']=index\n",
    "\n",
    "length2=df2.shape[0]\n",
    "df2['Origin']=0\n",
    "df2['Nebraska']=0\n",
    "df2['UCSD']=0\n",
    "df2['US-MWT2_UIUC']=0\n",
    "df2['BNL ATLAS']=0\n",
    "df2['FZU']=0\n",
    "df2['Trunk']=0\n",
    "finish['Origin']=0\n",
    "finish['Nebraska']=0\n",
    "finish['UCSD']=0\n",
    "finish['US-MWT2_UIUC']=0\n",
    "finish['BNL ATLAS']=0\n",
    "finish['FZU']=0\n",
    "finish['Trunk']=0\n",
    "finish['Trunk Timeout']=0\n",
    "finish['BNL Timeout']=0\n",
    "\n",
    "\n",
    "for i in range(length2):\n",
    "    for j in range(length):\n",
    "        if df['tries'].iloc[j]==\"1\":\n",
    "            if df['begin'].iloc[j]<=df2['index'].iloc[i] and df.index[j]>=df2['index'].iloc[i]:\n",
    "                if df['host'].iloc[j]=='root://data.ci-connect.net':\n",
    "                    df2['Origin'].iloc[i]+=1\n",
    "                if df['host'].iloc[j]=='root://hcc-stash.unl.edu':\n",
    "                    df2['Nebraska'].iloc[i]+=1\n",
    "                if df['host'].iloc[j]=='root://mwt2-stashcache.campuscluster.illinois.edu':\n",
    "                    df2['US-MWT2_UIUC'].iloc[i]+=1\n",
    "                if df['host'].iloc[j]=='root://xrd-cache-1.t2.ucsd.edu':\n",
    "                    df2['UCSD'].iloc[i]+=1\n",
    "                if df['host'].iloc[j]=='root://osgxroot.usatlas.bnl.gov':\n",
    "                    df2['BNL ATLAS'].iloc[i]+=1\n",
    "                if df['host'].iloc[j]=='novastore.farm.particle.cz':\n",
    "                    df2['FZU'].iloc[i]+=1\n",
    "        if df['tries'].iloc[j]==\"3\":\n",
    "            if df['start1'].iloc[j]<=df2['index'].iloc[i] and df['end2'].iloc[j]>=df2['index'].iloc[i]:\n",
    "                if df['cache'].iloc[j]=='root://hcc-stash.unl.edu':\n",
    "                    df2['Nebraska'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://mwt2-stashcache.campuscluster.illinois.edu':\n",
    "                    df2['US-MWT2_UIUC'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://xrd-cache-1.t2.ucsd.edu':\n",
    "                    df2['UCSD'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://osgxroot.usatlas.bnl.gov':\n",
    "                    df2['BNL ATLAS'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='novastore.farm.particle.cz':\n",
    "                    df2['FZU'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://data.ci-connect.net':\n",
    "                    df2['Origin'].iloc[i]+=1\n",
    "            if df['start3'].iloc[j]<=df2['index'].iloc[i] and df.index[j]>=df2['index'].iloc[i]:\n",
    "                df2['Trunk'].iloc[i]+=1\n",
    "            if df['end1'].iloc[j].replace(second=0, microsecond=0)==finish['index'].iloc[i].replace(second=0, microsecond=0):\n",
    "                finish['BNL Timeout'].iloc[i]+=1\n",
    "            if df['end2'].iloc[j].replace(second=0, microsecond=0)==finish['index'].iloc[i].replace(second=0, microsecond=0):\n",
    "                finish['BNL Timeout'].iloc[i]+=1\n",
    "        if df['tries'].iloc[j]==\"2\":\n",
    "            if df['start2'].iloc[j]<=df2['index'].iloc[i] and df.index[j]>=df2['index'].iloc[i]:\n",
    "                if df['cache'].iloc[j]=='root://hcc-stash.unl.edu':\n",
    "                    df2['Nebraska'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://mwt2-stashcache.campuscluster.illinois.edu':\n",
    "                    df2['US-MWT2_UIUC'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://xrd-cache-1.t2.ucsd.edu':\n",
    "                    df2['UCSD'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://osgxroot.usatlas.bnl.gov':\n",
    "                    df2['BNL ATLAS'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='novastore.farm.particle.cz':\n",
    "                    df2['FZU'].iloc[i]+=1\n",
    "                if df['cache'].iloc[j]=='root://data.ci-connect.net':\n",
    "                    df2['Origin'].iloc[i]+=1\n",
    "        if df.index[j].replace(second=0, microsecond=0)==finish['index'].iloc[i].replace(second=0, microsecond=0):\n",
    "            if df['host'].iloc[j]=='root://hcc-stash.unl.edu':\n",
    "                finish['Nebraska'].iloc[i]+=1\n",
    "            if df['host'].iloc[j]=='root://mwt2-stashcache.campuscluster.illinois.edu':\n",
    "                finish['US-MWT2_UIUC'].iloc[i]+=1\n",
    "            if df['host'].iloc[j]=='root://xrd-cache-1.t2.ucsd.edu':\n",
    "                finish['UCSD'].iloc[i]+=1\n",
    "            if df['host'].iloc[j]=='root://osgxroot.usatlas.bnl.gov':\n",
    "                finish['BNL ATLAS'].iloc[i]+=1\n",
    "            if df['host'].iloc[j]=='novastore.farm.particle.cz':\n",
    "                finish['FZU'].iloc[i]+=1\n",
    "            if df['host'].iloc[j]=='root://data.ci-connect.net':\n",
    "                if df['status'].iloc[j]=='Timeout':\n",
    "                    finish['Trunk Timeout'].iloc[i]+=1\n",
    "                else:\n",
    "                    if df['tries'].iloc[j]==\"1\" or df['tries'].iloc[j]==\"2\":\n",
    "                        finish['Origin'].iloc[i]+=1\n",
    "                    elif df['tries'].iloc[j]==\"3\":\n",
    "                        finish['Trunk'].iloc[i]+=1\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_pickle('mwt2_total.pkl')\n",
    "#df2.to_pickle('mwt2_concurrent.pkl')\n",
    "#finish.to_pickle('undirected_finish.pkl')\n",
    "\n",
    "#df2=pd.read_pickle('nebraska_concurrent.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot concurrent jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.plot.bar(stacked=True,figsize=[24, 12],color=['b', '#7FFFD4', 'g', 'y', 'k', 'm', 'c'])\n",
    "plt.title('(5) Number of jobs running on each server per minute over a submit of 1,000 undirected jobs; timeout=1 mins', fontsize=20) \n",
    "plt.xlabel('Minutes', fontsize=15)\n",
    "plt.ylabel('Count of concurrent jobs',fontsize=15)\n",
    "#plt.text(90,95,'*No GLIDEIN_ResourceName specified in condor.submit')\n",
    "\n",
    "plt.ylim([0,600])\n",
    "plt.xticks(np.arange(0, length2+1, 5),np.arange(0, length2+1, 5))\n",
    "\n",
    "#plt.savefig('undirected_1min_3.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot finishing status of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finish.plot.bar(stacked=True,figsize=[24, 12],color=['b', '#7FFFD4', 'g', 'y', 'k', 'm', 'c', 'r', '#DDA0DD'])\n",
    "plt.title('(5) Final status of jobs', fontsize=20) \n",
    "plt.xlabel('Minutes', fontsize=15)\n",
    "plt.ylabel('Count of jobs',fontsize=15)\n",
    "plt.xticks(np.arange(0, length2+1, 5),np.arange(0, length2+1, 5))\n",
    "\n",
    "#plt.savefig('undirected_finish_1min_3.png')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot counts of caches picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caches=df.groupby(['cache'])['cache'].count()\n",
    "caches.plot.bar()\n",
    "plt.title('(1) Count of first pick caches', fontsize=15) \n",
    "plt.xlabel('Caches', fontsize=15)\n",
    "plt.ylabel('Count of jobs',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
