{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "study for tracking transfer errors. Send automatic alert if a link between a source and a receiving site has a sustained too high transfer failure rate over a given time inverval. Vary model thresholds to study how this affects the number of alerts being sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages etc\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import re\n",
    "from elasticsearch import Elasticsearch\n",
    "matplotlib.rc('font', **{'size': 15})\n",
    "from elasticsearch.helpers import scan\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declaring variables.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#declare variables\n",
    "print(\"Declaring variables.\")\n",
    "\n",
    "#epoch times of start and end of time interval. \n",
    "#first week of february. monday 30. Jan to sunday 5. feb.\n",
    "#found using epochconverter.com\n",
    "#epoch time must be in milliseconds\n",
    "epoch_start = 1485730800000 #jan 30th 00.00.00\n",
    "epoch_end = 1486335599000 #feb 5th 23.59.59\n",
    "#epoch_end = 1485820799000 # jan30th 23.59.59 (one day for testing)\n",
    "\n",
    "loop_time = epoch_start #time variable in loop\n",
    "\n",
    "#loop time increments . one minute? five minutes?\n",
    "increment = 5 * 60 * 1000; #milliseconds\n",
    "\n",
    "#thresholds for defining an error\n",
    "failure_rate = .9 #failure rate threshold. Q: what is the threshold of red cells in DDM dashboard?\n",
    "file_thresh = 10 #number of files threshold.\n",
    "persist_thresh = 15 * 60 * 1000; #milliseconds. time needed before alert is sent.\n",
    "\n",
    "#number of alarms\n",
    "alarms = 0\n",
    "\n",
    "\n",
    "\n",
    "#some kind of dictionary with pairs of sites, and some variable keeping track of time\n",
    "#if pairs stay on this list too long an alarm is raised {[source,destination]:loop_time}\n",
    "observed_endpoints = {}\n",
    "\n",
    "#dict of when an alert was made and what pair is failing {when: [source,receiver]}\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop.\n",
      "Alert!  ('CERN-PROD_DERIVED', 'UKI-SCOTGRID-DURHAM_DATADISK')  at time  1486130400000\n",
      "time spent:  693.5750691890717 seconds.\n",
      "alarms:  1\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#could be useful to track how much time is spent on this block\n",
    "time_tracker = time.time()\n",
    "\n",
    "# algorithm:\n",
    "\n",
    "print(\"Starting loop.\")\n",
    "# loop over time interval in small time increments\n",
    "while loop_time <= epoch_end:\n",
    "    loop_time = loop_time + increment\n",
    "    # define search queries for the time increment. one to get transfers overall and one to get failed transfers\n",
    "    query_done = {\n",
    "      \"size\": 0,\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "        \"must\": [\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"@timestamp\": {\n",
    "            \"gte\": loop_time - increment,\n",
    "            \"lte\": loop_time,\n",
    "            \"format\": \"epoch_millis\"\n",
    "             }\n",
    "            }\n",
    "           },\n",
    "          {\"term\": {\"event_type\": \"transfer-done\"}},\n",
    "          {\"term\": {\"payload.scope\": \"data16_13TeV\"}}\n",
    "        ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    query_failed = {\n",
    "      \"size\": 0,\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "        \"must\": [\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"@timestamp\": {\n",
    "            \"gte\": loop_time - increment,\n",
    "            \"lte\": loop_time,\n",
    "            \"format\": \"epoch_millis\"\n",
    "             }\n",
    "            }\n",
    "           },\n",
    "          {\"term\": {\"event_type\": \"transfer-failed\"}},\n",
    "          {\"term\": {\"payload.scope\": \"data16_13TeV\"}}\n",
    "        ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    # make scrolls\n",
    "    es = Elasticsearch(['atlas-kibana.mwt2.org:9200'],timeout=60) \n",
    "    my_index = \"rucio-events-2017*\"\n",
    "    scroll_done = scan(es, query=query_done, index=my_index, scroll='5m', timeout=\"5m\", size=100)\n",
    "    scroll_errors = scan(es, query=query_failed, index=my_index, scroll='5m', timeout=\"5m\", size=100)\n",
    "    \n",
    "    #define once-per-loop variables\n",
    "    endpoints_failures = {}\n",
    "    failure_sources = {}\n",
    "    failure_destinations = {}\n",
    "    endpoints_transfers = {}\n",
    "    transfer_sources = {}\n",
    "    transfer_destinations = {}\n",
    "    ratios = {}\n",
    "    counter = 0\n",
    "    \n",
    "    \n",
    "    #loop over transfers and store information about sources and destinations\n",
    "    for res in scroll_done:\n",
    "        source = res['_source']['payload']['src-rse']\n",
    "        destination = res['_source']['payload']['dst-rse']\n",
    "        pair = (source,destination)\n",
    "        \n",
    "        if pair not in endpoints_transfers.keys():\n",
    "            endpoints_transfers[pair] = 1\n",
    "        if pair in endpoints_transfers.keys():\n",
    "            endpoints_transfers[pair] = endpoints_transfers[pair]+1\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    \n",
    "    counter = 0 #reset counter\n",
    "    #loop over failures and store information about sources and destinations\n",
    "    for res in scroll_errors:\n",
    "        source = res['_source']['payload']['src-rse']\n",
    "        destination = res['_source']['payload']['dst-rse']\n",
    "        pair = (source,destination)\n",
    "        \n",
    "        if pair not in endpoints_failures.keys():\n",
    "            endpoints_failures[pair] = 1\n",
    "        if pair in endpoints_failures.keys():\n",
    "            endpoints_failures[pair] = endpoints_failures[pair]+1\n",
    "    \n",
    "        counter += 1\n",
    "    \n",
    "    \n",
    "    #calculate failure rate for each pair\n",
    "    sorted_endpoints_failures = sorted(endpoints_failures.items(), key=operator.itemgetter(1))\n",
    "        \n",
    "    ##and item[1] >= file_thresh    \n",
    "        \n",
    "    remove = []    \n",
    "    for item in sorted_endpoints_failures:\n",
    "        if item[0] in endpoints_transfers  and item[1]/(endpoints_transfers[item[0]]+item[1]) >= failure_rate:\n",
    "            #check here to see if pair is in list of already known failures. if it isn't add it, and some kind of time stamp\n",
    "            #if it is in list, check how long it has been in the list. if threshold time is reached, remove it and send an alarm\n",
    "            if item[0] not in observed_endpoints.keys():\n",
    "                observed_endpoints[item[0]] = loop_time\n",
    "            elif item[0] in observed_endpoints.keys():\n",
    "                if loop_time - observed_endpoints[item[0]] >= persist_thresh:\n",
    "                    print(\"Alert! \", item[0], \" at time \",loop_time)\n",
    "                    alarms += 1\n",
    "                    del observed_endpoints[item[0]]\n",
    "           \n",
    "        \n",
    "        ##item[1] <= file_thresh or\n",
    "        ##remove elements of observed_endpoints if they did not satisfy thresholds     \n",
    "        if item[0] in endpoints_transfers and ( item[1]/(endpoints_transfers[item[0]]+item[1]) <= failure_rate):\n",
    "            if item[0] in observed_endpoints.keys():\n",
    "                #print(\"hello\")\n",
    "                remove.append(item[0])\n",
    "    \n",
    "    for key in remove:\n",
    "        del observed_endpoints[key]\n",
    "    \n",
    "    ##\n",
    "    #remove elements of observed_endpoints if they did not satisfy thresholds\n",
    "    ##for key in observed_endpoints.keys():\n",
    "    ##    if not key in endpoints_failures.keys() and endpoints_failures[key] >= file_thresh and endpoints_failures[key]/(endpoints_transfers[key]+endpoints_failures[key]) >= failure_rate :\n",
    "    ##        remove.append(key)\n",
    "                \n",
    "    ##for key in remove:\n",
    "    ##    del observed_endpoints[key]\n",
    "            #print(\"alert\")\n",
    "            #print(item[0],item[1]/pairs[item[0]])\n",
    "            \n",
    "            #ratios[item[0]] = item[1]/(endpoints_transfers[item[0]]+item[1])\n",
    "     \n",
    "    \n",
    "\n",
    "    # record pairs of failing sites that are meeting the threshold requirements\n",
    "     \n",
    "    # at the end of the loop, loop over the pairs, update list. remove links that have gone away. have a check to see i a pair has been in the failure list for long enough.\n",
    "    # if requirement is met, send an alert.\n",
    "    \n",
    "    #as a start, simply print the word \"alert\" and increase a counter\n",
    "\n",
    "#print(observed_endpoints)\n",
    "    \n",
    "   \n",
    "print(\"time spent: \", (time.time() - time_tracker), \"seconds.\")\n",
    "print(\"alarms: \", alarms)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output block:\n",
    "\n",
    "#print number of alerts made (number of elements in alerts list)\n",
    "#print alerts\n",
    "\n",
    "\n",
    "\n",
    "#do the same links trigger multiple alerts. if so, maybe some action needs to be taken to suppress this?\n",
    "# end goal: vary the thresholds and see how the number of alerts behave. compare to number of tickets filed in this period?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
