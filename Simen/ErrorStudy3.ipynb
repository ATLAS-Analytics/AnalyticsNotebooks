{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trying to improve the efficiency over ErrorStudy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages etc\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import re\n",
    "from elasticsearch import Elasticsearch\n",
    "matplotlib.rc('font', **{'size': 15})\n",
    "from elasticsearch.helpers import scan\n",
    "import time\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declaring variables.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#declare variables\n",
    "print(\"Declaring variables.\")\n",
    "\n",
    "#epoch times of start and end of time interval. \n",
    "#first week of february. monday 30. Jan to sunday 5. feb.\n",
    "#found using epochconverter.com\n",
    "#epoch time must be in milliseconds\n",
    "#epoch_start = 1488668400000 #Mar 5th 00.00.00 (week 10)\n",
    "epoch_start =1485730800000 #jan 30th 00.00.00\n",
    "#epoch_end = 1489273199000 #mar 11th 23.59.59\n",
    "epoch_end = 1486335599000 #feb 5th 23.59.59\n",
    "#epoch_end = 1485820799000 # jan30th 23.59.59 (one day for testing)\n",
    "#epoch_end = 1485920799000\n",
    "\n",
    "loop_time = epoch_start #time variable in loop\n",
    "\n",
    "#loop time increments . one minute? five minutes?\n",
    "increment = (5 * 60 * 1000)\n",
    "timevector = [epoch_start]\n",
    "dummy = epoch_start\n",
    "while dummy <= epoch_end:\n",
    "    dummy += increment\n",
    "    timevector.append(dummy)\n",
    "\n",
    "\n",
    "#thresholds for defining an error\n",
    "failure_rate = .5 #failure rate threshold. Q: what is the threshold of red cells in DDM dashboard?\n",
    "file_thresh = 10 #number of files threshold.\n",
    "persist_thresh = 15 * 60 * 1000; #milliseconds. time needed before alert is sent.\n",
    "\n",
    "#number of alarms\n",
    "alarms = 0\n",
    "\n",
    "#date and time format of\n",
    "#ex: 2017-03-27 10:03:10\n",
    "pattern = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "\n",
    "#some kind of dictionary with pairs of sites, and some variable keeping track of time\n",
    "#if pairs stay on this list too long an alarm is raised {[source,destination]:interval}\n",
    "observed_endpoints = {}\n",
    "\n",
    "#dict of when an alert was made and what pair is failing {when: [source,receiver]}\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining ElasticSearch querries.\n",
      "Defining scrolls.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#Elasticsearch querries\n",
    "print(\"Defining ElasticSearch querries.\")\n",
    "query_done = {\n",
    "    \"size\": 0,\n",
    "    \"query\": {\n",
    "    \"bool\": {\n",
    "    \"must\": [\n",
    "    {\n",
    "        \"range\": {\n",
    "        \"@timestamp\": {\n",
    "            \"gte\": epoch_start,\n",
    "            \"lte\": epoch_end,\n",
    "            \"format\": \"epoch_millis\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "        {\"term\": {\"event_type\": \"transfer-done\"}},\n",
    "        {\"term\": {\"payload.scope\": \"data16_13TeV\"}}\n",
    "    ]\n",
    "    }\n",
    "    }\n",
    "}\n",
    "query_failed = {\n",
    "    \"size\": 0,\n",
    "    \"query\": {\n",
    "    \"bool\": {\n",
    "    \"must\": [\n",
    "    {\n",
    "        \"range\": {\n",
    "            \"@timestamp\": {\n",
    "            \"gte\": epoch_start,\n",
    "            \"lte\": epoch_end,\n",
    "            \"format\": \"epoch_millis\"\n",
    "             }\n",
    "            }\n",
    "           },\n",
    "          {\"term\": {\"event_type\": \"transfer-failed\"}},\n",
    "          {\"term\": {\"payload.scope\": \"data16_13TeV\"}}\n",
    "        ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#make scrolls\n",
    "print(\"Defining scrolls.\")\n",
    "# make scrolls\n",
    "es = Elasticsearch(['atlas-kibana.mwt2.org:9200'],timeout=60) \n",
    "my_index = \"rucio-events-2017*\"\n",
    "scroll_done = scan(es, query=query_done, index=my_index, scroll='5m', timeout=\"5m\", size=100)\n",
    "scroll_errors = scan(es, query=query_failed, index=my_index, scroll='5m', timeout=\"5m\", size=100)\n",
    "\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Loop over Scroll Transfers\n",
      "Loop over Scroll Transfers Done\n",
      "Constructing Transfer Dict\n",
      "Transfer Dict Constructed\n",
      "Starting Loop over Scroll Errors\n",
      "Loop over Scroll Errors Done\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-817cbbc7fc36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m#also remove entries in failures if they fall after last entry of transfers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted_failure_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_transfer_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_transfer_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "#could be useful to track how much time is spent on this block\n",
    "time_tracker = time.time()\n",
    "\n",
    "interval_transfers = {}\n",
    "interval_failures = {}\n",
    "interval_ratios = {}\n",
    "#for interval in timevector:\n",
    "#    interval_transfers[interval] = {}\n",
    "#    interval_failures[interval] = {}\n",
    "#    interval_ratios[interval] = {}\n",
    "\n",
    "    \n",
    "transfer_times = {}\n",
    "print('Starting Loop over Scroll Transfers')\n",
    "for entry in scroll_done:\n",
    "    submitted_at = entry['_source']['payload']['submitted_at'] \n",
    "    #convert submitted at to epoch time\n",
    "    #must be in milliseconds\n",
    "    submitted_at = int(time.mktime(time.strptime(submitted_at, pattern)))*1000\n",
    "    source = entry['_source']['payload']['src-rse']\n",
    "    destination = entry['_source']['payload']['dst-rse']\n",
    "    pair = (source,destination)\n",
    "    transfer_times[submitted_at] = pair\n",
    "print('Loop over Scroll Transfers Done')\n",
    "\n",
    "\n",
    "#sort transfers by time\n",
    "sorted_transfer_times = collections.OrderedDict(sorted(transfer_times.items()))\n",
    "#sorted(endpointPairs.items(), key=operator.itemgetter(1))\n",
    "\n",
    "\n",
    "print('Constructing Transfer Dict')\n",
    "bookkeeper = list(sorted_transfer_times.items())[0][0] #first key of sorted_trasfer_times\n",
    "interval_transfers[bookkeeper] = {}\n",
    "interval_failures[bookkeeper] = {} #ensure that transfers and failures are same length\n",
    "for entry in sorted_transfer_times.keys():\n",
    "    if entry - bookkeeper <= increment:\n",
    "        if sorted_transfer_times[entry] in interval_transfers[bookkeeper].keys():\n",
    "             interval_transfers[bookkeeper][sorted_transfer_times[entry]] = interval_transfers[bookkeeper][sorted_transfer_times[entry]] + 1\n",
    "        if sorted_transfer_times[entry] not in interval_transfers[bookkeeper].keys():\n",
    "             interval_transfers[bookkeeper][sorted_transfer_times[entry]] = 1\n",
    "    else:\n",
    "            bookkeeper = bookkeeper+increment\n",
    "            interval_transfers[bookkeeper] = {}\n",
    "            interval_failures[bookkeeper] = {}\n",
    "            \n",
    "print('Transfer Dict Constructed')\n",
    "    \n",
    "#print(interval_transfers)\n",
    "\n",
    "failure_times  = {}\n",
    "print('Starting Loop over Scroll Errors')\n",
    "for entry in scroll_errors:\n",
    "    submitted_at = entry['_source']['payload']['submitted_at'] \n",
    "    #convert submitted at to epoch time\n",
    "    #must be in milliseconds\n",
    "    submitted_at = int(time.mktime(time.strptime(submitted_at, pattern)))*1000\n",
    "    source = entry['_source']['payload']['src-rse']\n",
    "    destination = entry['_source']['payload']['dst-rse']\n",
    "    pair = (source,destination)\n",
    "    failure_times[submitted_at] = pair\n",
    "print('Loop over Scroll Errors Done')\n",
    "\n",
    "sorted_failure_times = collections.OrderedDict(sorted(failure_times.items()))\n",
    "\n",
    "#trim start of sorted failure_times such that times are before first entry of sorted_transfer_times.\n",
    "#also remove entries in failures if they fall after last entry of transfers\n",
    "for entry in sorted_failure_times.keys():\n",
    "    if list(sorted_transfer_times.items())[0][0] - entry > 0 or entry - list(sorted_transfer_times.items())[0][-1] >0: \n",
    "        del entry\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print('first transfer: ', list(sorted_transfer_times.items())[0][0])\n",
    "print('first failure: ', list(sorted_failure_times.items())[0][0])\n",
    "\n",
    "print('last transfer: ', list(sorted_transfer_times.items())[0][-1])\n",
    "print('last failure: ', list(sorted_failure_times.items())[0][-1])\n",
    "\n",
    "\n",
    "print('Constructing Failures Dict')\n",
    "bookkeeper = list(sorted_transfer_times.items())[0][0] #first key of sorted_trasfer_times\n",
    "for entry in sorted_failure_times.keys():\n",
    "    if entry - bookkeeper <= increment:\n",
    "        if sorted_failure_times[entry] in interval_failures[bookkeeper].keys():\n",
    "            interval_failures[bookkeeper][sorted_failure_times[entry]] = interval_failures[bookkeeper][sorted_failure_times[entry]] + 1\n",
    "        if sorted_failure_times[entry] not in interval_failures[bookkeeper].keys():\n",
    "            interval_failures[bookkeeper][sorted_failure_times[entry]] = 1\n",
    "    else:\n",
    "        bookkeeper = bookkeeper+increment\n",
    "        interval_failures[bookkeeper] = {}\n",
    "        \n",
    "print('Failures Dict Constructed')\n",
    "\n",
    "print('Calculating Failure Ratios')\n",
    "#calculating the file transfer failure rate betwen pairs of grid sites in each time interval\n",
    "for interval in interval_transfers:\n",
    "    interval_ratios[interval] = {}\n",
    "    for pair in interval_transfers[interval].keys():\n",
    "        if pair in interval_failures[interval].keys():\n",
    "            interval_ratios[interval][pair] = float(interval_failures[interval][pair])/(float(interval_failures[interval][pair])+float(interval_transfers[interval][pair]))\n",
    "        else:\n",
    "            interval_ratios[interval][pair] = 0.0\n",
    "    for pair in interval_failures[interval].keys():\n",
    "        if pair not in interval_transfers[interval].keys():\n",
    "            interval_ratios[interval][pair] = 1.0\n",
    "    \n",
    "    \n",
    "print('Failure Ratios Calulated')\n",
    "\n",
    "print('Starting Alarm Loop')\n",
    "\n",
    "alarm_list = []\n",
    "\n",
    "#observed_endpoints\n",
    "for interval in interval_ratios:\n",
    "    remove = []\n",
    "    for pair in interval_ratios[interval].keys():\n",
    "        #number of total failed and successful transfer betwen pair\n",
    "        transfers = 0\n",
    "        if pair in interval_transfers[interval].keys():\n",
    "            transfers += interval_transfers[interval][pair]\n",
    "        if pair in interval_failures[interval].keys():\n",
    "            transfers += interval_failures[interval][pair]\n",
    "        #failure rate must be over threshold and numer of transfers over threshold\n",
    "        if(interval_ratios[interval][pair] >= failure_rate and transfers >= file_thresh):\n",
    "            if pair not in observed_endpoints.keys():\n",
    "                observed_endpoints[pair] = interval\n",
    "            if pair in observed_endpoints.keys() and interval - observed_endpoints[pair]  >= persist_thresh:\n",
    "                #print('alarm')\n",
    "                alarms += 1\n",
    "                alarm_list.append([interval,pair])\n",
    "                del observed_endpoints[pair]\n",
    "                \n",
    "    # if not in ratios or threshold too low, remove from watchlist\n",
    "        if(pair in observed_endpoints.keys() and (interval_ratios[interval][pair] <= failure_rate or transfers < file_thresh)):\n",
    "            \n",
    "            del observed_endpoints[pair]\n",
    "            \n",
    "                        \n",
    "print('Alarm Loop Done')\n",
    "\n",
    "print(\"time spent: \", (time.time() - time_tracker)/60, \"minutes.\")  \n",
    "print('Alarms: ', alarms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in alarm_list:\n",
    "    print('When: ',time.strftime(pattern,time.localtime(entry[0]/1000)),', pair: ',entry[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
