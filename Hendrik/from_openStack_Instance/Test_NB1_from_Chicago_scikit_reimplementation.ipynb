{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/06\n"
     ]
    }
   ],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pprint\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from fractions import Fraction \n",
    "import scipy.odr.odrpack as odrpack\n",
    "import time\n",
    "from bisect import bisect_left\n",
    "import copy\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for the creation of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avageAndStdDeviationOverSeconds(dataPoints, currentIndex, collumToAnalyze, averagingSeconds):\n",
    "    '''\n",
    "    Returns a tupel, with outTupel[0] the average and outTupel[1] the standard deviation.\n",
    "    Calculates the average and standard deviation over a given time.\n",
    "    Starting from the data point at currentIndex in dataPoints and going back the number of averagingSeconds.\n",
    "    It is assumed, that dataPonts is a Pandas DataFrame, with timestamps as indexes\n",
    "    and that it is sortet, so that the latest/newest entry is at the beginning of the DataFrame.\n",
    "    '''\n",
    "    timestamps = dataPoints.axes[0]\n",
    "    data = dataPoints.values\n",
    "    outTupel = [0, 0]\n",
    "    secondsAgo = timestamps[currentIndex] - averagingSeconds\n",
    "    if ( timestamps[len(timestamps)-1] > secondsAgo):\n",
    "        secondsAgo = timestamps[len(timestamps)-1]\n",
    "    # cut array\n",
    "    lastIndex = 0\n",
    "    for i in xrange(currentIndex, len(data)):\n",
    "        if timestamps[i] <= secondsAgo :\n",
    "            lastIndex = i\n",
    "            break\n",
    "    cutData = np.split(dataPoints, [currentIndex, lastIndex + 1])[1]\n",
    "    data = cutData.values\n",
    "    columNames = cutData.axes[1]\n",
    "    # calculate average and variance\n",
    "    avg = cutData[columNames[collumToAnalyze]].mean()\n",
    "    outTupel[0] = avg\n",
    "    std = cutData[columNames[collumToAnalyze]].std()\n",
    "    outTupel[1] = std\n",
    "    return outTupel\n",
    "\n",
    "def nextMeasurementAndDistance(dataPoints, currentIndex, collumToAnalyze, numberOfMeasurementsToSkip=0):\n",
    "    '''\n",
    "    Returns a tuple with outTupel[0] the next measurement in time and outTupel[1]\n",
    "    the distance of the next measurement to the timestamp at currentIndex, devided by averagingSeconds\n",
    "    TODO: evaluate, how usefull it is to devide by averagingSeconds [edit: just removed it because it seemed useless]\n",
    "    '''\n",
    "    countNum = numberOfMeasurementsToSkip\n",
    "    timestamps = dataPoints.axes[0]\n",
    "    data = dataPoints.values\n",
    "    outTupel = [0, 0]\n",
    "    nextIndex = currentIndex + 1\n",
    "    while True:\n",
    "        if nextIndex >= len(timestamps):\n",
    "            nextIndex = currentIndex\n",
    "            break\n",
    "        if math.isnan(data[nextIndex][collumToAnalyze]) == False:\n",
    "            if countNum == 0:\n",
    "                break\n",
    "            else:\n",
    "                countNum -= 1\n",
    "        nextIndex = nextIndex + 1\n",
    "    outTupel[0] = data[nextIndex][collumToAnalyze]\n",
    "    outTupel[1] = (timestamps[currentIndex] - timestamps[nextIndex])\n",
    "    return outTupel\n",
    "\n",
    "\n",
    "def findIndexClostestThatIsNotNAN(startIndex, dataPoints, collumThatIsNotNAN):\n",
    "    '''\n",
    "    Returns an index for dataPoints, that is:\n",
    "    a) in the collum \"collumThatIsNotNAN\" not nan.\n",
    "    b) closest to startIndex (looking fowards and backwards at the same time in the array).\n",
    "       This \"proximity\" does not take the timestamp into account, just the numerical\n",
    "       distance from startIndex to the returned index.\n",
    "    If no occurence is found it will raise an error, but this case should be ultra rare.\n",
    "    ATENTION: This function may look into the \"future\" of the data set which may not be possible in the future.\n",
    "    '''\n",
    "    hitBeginningOfList = False\n",
    "    hitEndOfList = False\n",
    "    index1 = startIndex\n",
    "    index2 = startIndex\n",
    "    while not (hitEndOfList or hitBeginningOfList):\n",
    "        index1 += 1\n",
    "        index2 -= 1\n",
    "        if (hitEndOfList == True) or (index1 == len(dataPoints)):\n",
    "            hitEndOfList = True\n",
    "        else:\n",
    "            currentDataPoint = dataPoints.values[index1]\n",
    "            if not math.isnan(currentDataPoint[collumThatIsNotNAN]):\n",
    "                return index1\n",
    "        if (hitBeginningOfList == True) or (index2 == -1):\n",
    "            hitBeginningOfList = True\n",
    "        else:\n",
    "            currentDataPoint = dataPoints.values[index2]\n",
    "            if not math.isnan(currentDataPoint[collumThatIsNotNAN]):\n",
    "                return index2\n",
    "    raise StandardError(\"Could not find a closest occurence, does the data even contain values in that colum?\")\n",
    "\n",
    "\n",
    "def findDataPointClosestToTimestamp(timestamp, dataPoints, collumThatIsNotNAN):\n",
    "    '''\n",
    "    Returns a data point from dataPoints, that is closest to the given timestamp.\n",
    "    As well the dataPoint will not be nan in the collum \"collumThatIsNotNAN\"\n",
    "    Complexity of this command: O( log( len(dataPoints) ) )\n",
    "    '''\n",
    "    timestamps_toSearch = dataPoints.axes[0]\n",
    "    data = dataPoints.values\n",
    "    # bisect only works because we know our list is sorted\n",
    "    pos = bisect_left(timestamps_toSearch, timestamp)\n",
    "    if pos == len(dataPoints):\n",
    "        pos = len(dataPoints)-1\n",
    "    # find the closest datapoint, that is not a NAN and return it\n",
    "    currentDataPoint = dataPoints.values[pos]\n",
    "    if not math.isnan(currentDataPoint[collumThatIsNotNAN]):\n",
    "        return currentDataPoint\n",
    "    else:\n",
    "        pos = findIndexClostestThatIsNotNAN(pos, dataPoints, collumThatIsNotNAN)\n",
    "        currentDataPoint = dataPoints.values[pos]\n",
    "        return currentDataPoint\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def createDataSets(dataPoints_forth, dataPoints_back, averagingSeconds_Throughput, averagingSeconds_Delay_and_Loss):\n",
    "    '''\n",
    "    Returns a data sets (in form of a pandas DataFrame), derived from the given dataPoints_forth,\n",
    "    and small parts of dataPoints_back.\n",
    "    A data set contains information about throughput, packetloss and delay for a given point in time.\n",
    "    '''\n",
    "    timestamps = dataPoints_forth.axes[0]\n",
    "    data = dataPoints_forth.values\n",
    "    dataSetList = []\n",
    "    # go through the data\n",
    "    print(\"Current percentage of analyzed dataPoints: \")\n",
    "    for i in xrange(len(dataPoints_forth)):\n",
    "        # find a point, where we have throughput data\n",
    "        if math.isnan(data[i][5]) == False:\n",
    "            currentSet = {}\n",
    "            # get all the throughput data:\n",
    "            currentSet[\"timestamp\"] = timestamps[i]\n",
    "            currentSet[\"throughput\"] = data[i][5]\n",
    "            # take out this part at the moment as the network converges to fast\n",
    "            '''avgAStdThroughput = avageAndStdDeviationOverSeconds(dataPoints_forth, i, 5, averagingSeconds_Throughput)\n",
    "            currentSet[\"throughput_average\"] = avgAStdThroughput[0]\n",
    "            currentSet[\"throughput_std_deviation\"] = avgAStdThroughput[1]\n",
    "            nextAndDist = nextMeasurementAndDistance(dataPoints_forth, i, 5)\n",
    "            currentSet[\"throughput_last_measurement\"] = nextAndDist[0]\n",
    "            currentSet[\"throughput_last_measurement_time\"] = nextAndDist[1]'''\n",
    "            \n",
    "            # get all packetloss data:\n",
    "            # TODO: replace this with a search in both directions\n",
    "            nextValidIndex = findIndexClostestThatIsNotNAN(i, dataPoints_forth, 4)\n",
    "            currentSet[\"packet_loss\"] = data[nextValidIndex][4]\n",
    "            avgAStdPacket_loss = avageAndStdDeviationOverSeconds(dataPoints_forth, nextValidIndex, 4, averagingSeconds_Delay_and_Loss)\n",
    "            currentSet[\"packet_loss_average\"] = avgAStdPacket_loss[0]\n",
    "            currentSet[\"packet_loss_std_deviation\"] = avgAStdPacket_loss[1]\n",
    "            \n",
    "            # get all delay data\n",
    "            nextValidIndex = findIndexClostestThatIsNotNAN(i, dataPoints_forth, 2)\n",
    "            fittingDataPoint_back = findDataPointClosestToTimestamp(currentSet[\"timestamp\"], dataPoints_back, 2)\n",
    "            currentSet[\"delay_current_average_forth\"] = data[nextValidIndex][2]\n",
    "            currentSet[\"delay_current_average_back\"] = fittingDataPoint_back[2]\n",
    "            currentSet[\"delay_current_std_deviation_forth\"] = data[nextValidIndex][3]\n",
    "            currentSet[\"delay_current_std_deviation_back\"] = fittingDataPoint_back[3]\n",
    "            avgAStdPacket_loss = avageAndStdDeviationOverSeconds(dataPoints_forth, nextValidIndex, 1, averagingSeconds_Delay_and_Loss)\n",
    "            currentSet[\"delay_timed_average\"] = avgAStdPacket_loss[0]\n",
    "            currentSet[\"delay_timed_std_deviation\"] = avgAStdPacket_loss[1]\n",
    "            \n",
    "            dataSetList.append(currentSet)\n",
    "        if (i % 1000) == 0:\n",
    "            print(str(100*i/len(dataPoints_forth)) +\" %, \" , end=\"\")\n",
    "    print(\" \")\n",
    "    print(\"Total created data sets: \" + str(len(dataSetList)))\n",
    "    dataFrame = pd.DataFrame.from_dict(dataSetList)\n",
    "    return dataFrame\n",
    "\n",
    "\n",
    "def createDatasetsFromFilesInFolder(path, averagingSeconds):\n",
    "    '''\n",
    "    This function is outdated at the moment and will crash!\n",
    "    '''\n",
    "    count = 0\n",
    "    outputDataSets = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        # read all files\n",
    "        for filename in filenames:\n",
    "            print(\"----------------------- reading file: \" + filename)\n",
    "            dataPoints = pd.read_pickle(str(path + filename))\n",
    "            # make sure it is sorted\n",
    "            dataPoints.sort_index(inplace=True, ascending=False)\n",
    "            dataSets = createDataSets(dataPoints, averagingSeconds)\n",
    "            outputDataSets.append(dataSets)\n",
    "            count =  count + 1\n",
    "            print(\" \")\n",
    "    print(\"Number of read files: \" + str(count))\n",
    "    print(\" \")\n",
    "    return outputDataSets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for analytical aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcMathisModel_outBitsPerSec(packetloss, MSS, RTT, C=math.sqrt(3/2)):\n",
    "    '''\n",
    "    Returns the result of mathis model in Bits/s.\n",
    "    It does work with np.arrays.\n",
    "    '''\n",
    "    outVal = (MSS/RTT)*C/np.sqrt(packetloss)\n",
    "    # since Mathis forumlar gives us Mbit/sec, but we actualy have Bit/s as a throughput\n",
    "    # so we need to multipy by 1e6 to get bit/sec\n",
    "    outVal *= 1e6\n",
    "    return outVal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeDataSetToRoot(dataSet, rootFileName):\n",
    "    rootFile = ROOT.TFile(rootFileName, \"recreate\")\n",
    "    tree = ROOT.TTree(\"TreeR\", \"Tree with regression data\")\n",
    "    # prepare our varibles, that we want to add\n",
    "    variables = {}\n",
    "    for key in dataSet.axes[1]:\n",
    "        variables[key] = np.zeros(1, dtype=float)\n",
    "        tree.Branch(key, variables[key], key + '/D')\n",
    "    # add the data from our dataSet\n",
    "    for i in xrange(len(dataSet)):\n",
    "        for item in variables.keys():\n",
    "            variables[item][0] = float(dataSet[item][i])\n",
    "        tree.Fill()\n",
    "    # clean up\n",
    "    rootFile.Write()\n",
    "    rootFile.Close()    \n",
    "    \n",
    "def normalizeDataSet(dataSet):\n",
    "    # make sure we don't change our original object (wo don't want that)\n",
    "    # use the sktlearn.preprocessing procedures, they prommis to be quite flexible\n",
    "    workDataSet = dataSet.copy(deep=True)\n",
    "    # append zeroes so that we are actually normalized to zero\n",
    "    zeroesDataFrame = pd.DataFrame(np.zeros([1,len(workDataSet.axes[1])]), columns=workDataSet.axes[1])\n",
    "    workDataSet = workDataSet.append(zeroesDataFrame, ignore_index=True)\n",
    "    # fill up our nans as the function dosen't run with nans \n",
    "    workDataSet = workDataSet.fillna(0)\n",
    "    collums = []\n",
    "    for collum in workDataSet.axes[1]:\n",
    "        # what to skip:\n",
    "        if collum == \"timestamp\":\n",
    "            continue\n",
    "        collums.append(collum)\n",
    "    # if you want to keep the scaler, then split this into a fit and a transform call\n",
    "    scaler = preprocessing.MinMaxScaler().fit(workDataSet[collums].as_matrix())\n",
    "    workDataSet[collums] = scaler.transform(workDataSet[collums].as_matrix())\n",
    "    # remove zeroes again\n",
    "    workDataSet = workDataSet.drop(len(workDataSet)-1, axis=0)\n",
    "    return workDataSet, scaler\n",
    "\n",
    "def inverseNormalizeDataSet(dataSet, scaler):\n",
    "    # make sure we don't change our original object (wo don't want that)\n",
    "    # use the sktlearn.preprocessing procedures, they prommis to be quite flexible\n",
    "    workDataSet = dataSet.copy(deep=True)\n",
    "    collums = []\n",
    "    for collum in workDataSet.axes[1]:\n",
    "        # what to skip:\n",
    "        if collum == \"timestamp\":\n",
    "            continue\n",
    "        collums.append(collum)\n",
    "    workDataSet[collums] = scaler.inverse_transform(workDataSet[collums].as_matrix())\n",
    "    # remove zeroes again\n",
    "    #workDataSet = workDataSet.drop(len(workDataSet)-1, axis=0)\n",
    "    return workDataSet\n",
    "\n",
    "def filterOutliersFromDataSet(dataSet):\n",
    "    raise NotImplementedError(\"Jup, true\")\n",
    "    return\n",
    "\n",
    "def getDataSetWithPacketloss(dataSet):\n",
    "    dataSetsWithPacketloss = dataSet_CERN_to_RAL.copy(deep=True)\n",
    "    count = 0\n",
    "    while count < len(dataSetsWithPacketloss):\n",
    "        loss = dataSetsWithPacketloss['packet_loss'][count]\n",
    "        # remove unwanted data:\n",
    "        if loss < 0.0 and loss > 0.05:\n",
    "            dataSetsWithPacketloss = dataSetsWithPacketloss.drop(count, axis=0)\n",
    "            # no need to set the counter higher, since we removed a line\n",
    "        else:\n",
    "            # keep this line and conut one up\n",
    "            count += 1\n",
    "    print( \"Number of dataSets with packet_loss: \" + str(len(dataSetsWithPacketloss)))\n",
    "    return dataSetsWithPacketloss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Raw data and create data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current percentage of analyzed dataPoints: \n",
      "0.0 %, 7.59647523549 %, 15.192950471 %, 22.7894257065 %, 30.385900942 %, 37.9823761775 %, 45.5788514129 %, 53.1753266484 %, 60.7718018839 %, 68.3682771194 %, 75.9647523549 %, 83.5612275904 %, 91.1577028259 %, 98.7541780614 %,  \n",
      "Total created data sets: 639\n",
      "Current percentage of analyzed dataPoints: \n",
      "0.0 %, 7.98658254133 %, 15.9731650827 %, 23.959747624 %, 31.9463301653 %, 39.9329127067 %, 47.919495248 %, 55.9060777893 %, 63.8926603306 %, 71.879242872 %, 79.8658254133 %, 87.8524079546 %, 95.838990496 %,  \n",
      "Total created data sets: 646\n"
     ]
    }
   ],
   "source": [
    "# read our raw data\n",
    "rawDataPath1 = \"raw_data/raw_data_by_IP_from_CERN_to_RAL_and_time_2016-05-01_to_2016-08-30_sorted.pkl\"\n",
    "rawDataPath2 = \"raw_data/raw_data_by_IP_from_RAL_to_CERN_and_time_2016-05-01_to_2016-08-30_sorted.pkl\"\n",
    "dataPoints_CERN_RAL = pd.read_pickle(rawDataPath1)\n",
    "dataPoints_RAL_CERN = pd.read_pickle(rawDataPath2)\n",
    "# make sure it is sorted\n",
    "dataPoints_CERN_RAL.sort_index(inplace=True, ascending=False)\n",
    "dataPoints_RAL_CERN.sort_index(inplace=True, ascending=False)\n",
    "\n",
    "\n",
    "secondsToAverage_Throughput = 60 * 60 * 6 # average over the last 4 hours\n",
    "secontsToAverage_Delay_and_Loss = 60 * 5 # average over the last 5 minutes\n",
    "dataSet_CERN_to_RAL = createDataSets(dataPoints_CERN_RAL, dataPoints_RAL_CERN, secondsToAverage_Throughput, secontsToAverage_Delay_and_Loss)\n",
    "dataSet_RAL_to_CERN = createDataSets(dataPoints_RAL_CERN, dataPoints_CERN_RAL, secondsToAverage_Throughput, secontsToAverage_Delay_and_Loss)\n",
    "#dataSetList = createDatasetsFromFilesInFolder(\"raw_data/selected_data_points/\", secondsToAverage)\n",
    "#dataSetListAll = dataSetList[0] + dataSetList[1] + dataSetList[2] + dataSetList[3]\n",
    "#dataSetList = pd.read_pickle('dataSetList.pkl')\n",
    "dataSetListAll = []\n",
    "dataSetListAll.append(dataSet_CERN_to_RAL)\n",
    "dataSetListAll.append(dataSet_RAL_to_CERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSet_CERN_to_RAL_normalized, scaler_for_CERN_to_RAL = normalizeDataSet(dataSet_CERN_to_RAL)\n",
    "#filePath = \"/root/Downloads/dataSet_CERN_to_RAL.root\"\n",
    "#writeDataSetToRoot(dataSet_CERN_to_RAL_normalized, filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the ANN with scikit-neuralnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regressor(batch_size=1, callback=None, debug=False, dropout_rate=None,\n",
       "     f_stable=0.001,\n",
       "     hidden0=<sknn.nn.Layer `Tanh`: units=20, name=u'hidden0', frozen=False>,\n",
       "     hidden1=<sknn.nn.Layer `Tanh`: units=5, name=u'hidden1', frozen=False>,\n",
       "     layers=[<sknn.nn.Layer `Tanh`: units=20, name=u'hidden0', frozen=False>, <sknn.nn.Layer `Tanh`: units=5, name=u'hidden1', frozen=False>, <sknn.nn.Layer `Linear`: units=1, name=u'output', frozen=False>],\n",
       "     learning_momentum=0.9, learning_rate=0.001, learning_rule=u'sgd',\n",
       "     loss_type=None, n_iter=200, n_stable=10, normalize=None,\n",
       "     output=<sknn.nn.Layer `Linear`: units=1, name=u'output', frozen=False>,\n",
       "     parameters=None, random_state=None, regularize=None, valid_set=None,\n",
       "     valid_size=0.0, verbose=None, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sknn.platform import cpu64, threading\n",
    "from sknn.mlp import Regressor, Layer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "collums = []\n",
    "for collum in dataSet_CERN_to_RAL_normalized.axes[1]:\n",
    "    # what to skip:\n",
    "    if collum == \"timestamp\" or collum == \"throughput\":\n",
    "        continue\n",
    "    collums.append(collum)\n",
    "X_train = dataSet_CERN_to_RAL_normalized[collums].as_matrix()\n",
    "y_train = dataSet_CERN_to_RAL_normalized['throughput'].as_matrix()\n",
    "\n",
    "nn = Regressor(\n",
    "    layers=[\n",
    "        Layer(\"Tanh\", units=20),\n",
    "        Layer(\"Tanh\", units=5),\n",
    "        Layer(\"Linear\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=200)\n",
    "\n",
    "#gs = GridSearchCV(nn, param_grid={\n",
    "#    'learning_rate': [0.05, 0.01, 0.005, 0.001],\n",
    "#    'hidden0__units': [8, 15, 20],\n",
    "#    'hidden0__type': [\"Rectifier\", \"Sigmoid\", \"Tanh\"],\n",
    "#    'hidden1__units': [5, 7, 10],\n",
    "#    'hidden1__type': [\"Rectifier\", \"Sigmoid\", \"Tanh\"]})\n",
    "#gs.fit(X_train, y_train)\n",
    "\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31867046],\n",
       "       [ 0.31499029],\n",
       "       [ 0.31368055],\n",
       "       [ 0.20064875],\n",
       "       [ 0.2804376 ],\n",
       "       [ 0.31614639],\n",
       "       [ 0.31960162],\n",
       "       [ 0.3165777 ],\n",
       "       [ 0.3162226 ],\n",
       "       [ 0.31654395],\n",
       "       [ 0.31123824],\n",
       "       [ 0.31835093],\n",
       "       [ 0.31462367],\n",
       "       [ 0.31614207],\n",
       "       [ 0.30958622],\n",
       "       [ 0.31214597],\n",
       "       [ 0.2240996 ],\n",
       "       [ 0.14431983],\n",
       "       [ 0.16650611],\n",
       "       [ 0.1423625 ],\n",
       "       [ 0.11666191],\n",
       "       [ 0.17386424],\n",
       "       [ 0.07082986],\n",
       "       [ 0.07167708],\n",
       "       [ 0.10098808],\n",
       "       [ 0.11586642],\n",
       "       [ 0.10028501],\n",
       "       [ 0.10390051],\n",
       "       [ 0.17276479],\n",
       "       [ 0.10880109],\n",
       "       [ 0.09613894],\n",
       "       [ 0.22432699],\n",
       "       [ 0.0966203 ],\n",
       "       [ 0.15067797],\n",
       "       [ 0.25910938],\n",
       "       [ 0.20961216],\n",
       "       [ 0.23053763],\n",
       "       [ 0.19027165],\n",
       "       [ 0.31461981],\n",
       "       [ 0.3131322 ],\n",
       "       [ 0.32178368],\n",
       "       [ 0.31591509],\n",
       "       [ 0.31722828],\n",
       "       [ 0.29804775],\n",
       "       [ 0.20334021],\n",
       "       [ 0.20303598],\n",
       "       [ 0.31470038],\n",
       "       [ 0.31257477],\n",
       "       [ 0.23822083],\n",
       "       [ 0.21481002],\n",
       "       [ 0.10485843],\n",
       "       [ 0.09708928],\n",
       "       [ 0.31913702],\n",
       "       [ 0.31672661],\n",
       "       [ 0.30182162],\n",
       "       [ 0.30405802],\n",
       "       [ 0.30992296],\n",
       "       [ 0.28301204],\n",
       "       [ 0.3175447 ],\n",
       "       [ 0.30603776],\n",
       "       [ 0.29300544],\n",
       "       [ 0.23673539],\n",
       "       [ 0.30007732],\n",
       "       [ 0.31498893],\n",
       "       [ 0.30941177],\n",
       "       [ 0.31053203],\n",
       "       [ 0.31383615],\n",
       "       [ 0.3067309 ],\n",
       "       [ 0.31570989],\n",
       "       [ 0.30829345],\n",
       "       [ 0.31741076],\n",
       "       [ 0.31367861],\n",
       "       [ 0.31817586],\n",
       "       [ 0.31680022],\n",
       "       [ 0.2728293 ],\n",
       "       [ 0.26572126],\n",
       "       [ 0.31495519],\n",
       "       [ 0.31291646],\n",
       "       [ 0.2999262 ],\n",
       "       [ 0.29379871],\n",
       "       [ 0.09247582],\n",
       "       [ 0.31293601],\n",
       "       [ 0.31564049],\n",
       "       [ 0.31668689],\n",
       "       [ 0.31692248],\n",
       "       [ 0.21466666],\n",
       "       [ 0.16303533],\n",
       "       [ 0.31634488],\n",
       "       [ 0.31625487],\n",
       "       [ 0.31811948],\n",
       "       [ 0.31673204],\n",
       "       [ 0.31686366],\n",
       "       [ 0.31730258],\n",
       "       [ 0.31695149],\n",
       "       [ 0.27946136],\n",
       "       [ 0.27348523],\n",
       "       [ 0.31606187],\n",
       "       [ 0.31494176],\n",
       "       [ 0.31630268],\n",
       "       [ 0.31598518],\n",
       "       [ 0.24115916],\n",
       "       [ 0.17237954],\n",
       "       [ 0.31792574],\n",
       "       [ 0.31606078],\n",
       "       [ 0.30005936],\n",
       "       [ 0.31176536],\n",
       "       [ 0.31234282],\n",
       "       [ 0.27798132],\n",
       "       [ 0.30620431],\n",
       "       [ 0.31632383],\n",
       "       [ 0.31783478],\n",
       "       [ 0.24190924],\n",
       "       [ 0.31700059],\n",
       "       [ 0.29674821],\n",
       "       [ 0.28090813],\n",
       "       [ 0.28953823],\n",
       "       [ 0.14887301],\n",
       "       [ 0.31508918],\n",
       "       [ 0.31900979],\n",
       "       [ 0.31299297],\n",
       "       [ 0.31514663],\n",
       "       [ 0.29325548],\n",
       "       [ 0.28086198],\n",
       "       [ 0.3184768 ],\n",
       "       [ 0.32006858],\n",
       "       [ 0.31609249],\n",
       "       [ 0.32011373],\n",
       "       [ 0.31611735],\n",
       "       [ 0.31825299],\n",
       "       [ 0.31741531],\n",
       "       [ 0.3167158 ],\n",
       "       [ 0.31611989],\n",
       "       [ 0.30107203],\n",
       "       [ 0.31566196],\n",
       "       [ 0.30116829],\n",
       "       [ 0.31053479],\n",
       "       [ 0.27083589],\n",
       "       [ 0.31631291],\n",
       "       [ 0.31851078],\n",
       "       [ 0.28204031],\n",
       "       [ 0.24089807],\n",
       "       [ 0.15667844],\n",
       "       [ 0.11973959],\n",
       "       [-0.01996947],\n",
       "       [-0.08226499],\n",
       "       [ 0.03245222],\n",
       "       [ 0.06685841],\n",
       "       [-0.01112062],\n",
       "       [-0.09834838],\n",
       "       [ 0.27664476],\n",
       "       [ 0.14481769],\n",
       "       [-0.02472337],\n",
       "       [ 0.02245002],\n",
       "       [ 0.16927282],\n",
       "       [ 0.14168855],\n",
       "       [ 0.32013511],\n",
       "       [ 0.32019297],\n",
       "       [ 0.31927189],\n",
       "       [ 0.31091309],\n",
       "       [ 0.21083961],\n",
       "       [ 0.18511775],\n",
       "       [ 0.11971976],\n",
       "       [ 0.31329363],\n",
       "       [ 0.31635772],\n",
       "       [ 0.31967245],\n",
       "       [ 0.31837301],\n",
       "       [ 0.32001875],\n",
       "       [ 0.16242733],\n",
       "       [ 0.2003158 ],\n",
       "       [ 0.26851146],\n",
       "       [ 0.32018815],\n",
       "       [ 0.29063456],\n",
       "       [ 0.31692957],\n",
       "       [ 0.32013202],\n",
       "       [ 0.15872409],\n",
       "       [ 0.09997237],\n",
       "       [ 0.31582866],\n",
       "       [ 0.23626849],\n",
       "       [ 0.3176713 ],\n",
       "       [ 0.27280176],\n",
       "       [ 0.28382288],\n",
       "       [ 0.33160808],\n",
       "       [ 0.20312802],\n",
       "       [ 0.11071953],\n",
       "       [ 0.18885496],\n",
       "       [ 0.10765877],\n",
       "       [ 0.06659245],\n",
       "       [-0.03148674],\n",
       "       [ 0.03094195],\n",
       "       [-0.08769821],\n",
       "       [ 0.17048641],\n",
       "       [ 0.12021729],\n",
       "       [ 0.10942736],\n",
       "       [ 0.01511301],\n",
       "       [ 0.03138613],\n",
       "       [ 0.11172   ],\n",
       "       [ 0.18991363],\n",
       "       [-0.00885446],\n",
       "       [ 0.08282635],\n",
       "       [ 0.01403055],\n",
       "       [-0.01355103],\n",
       "       [ 0.28747999],\n",
       "       [ 0.12299426],\n",
       "       [ 0.03750589],\n",
       "       [ 0.05346898],\n",
       "       [ 0.07436581],\n",
       "       [ 0.0455726 ],\n",
       "       [ 0.02439162],\n",
       "       [ 0.00312222],\n",
       "       [ 0.16212525],\n",
       "       [ 0.01205781],\n",
       "       [ 0.11707612],\n",
       "       [ 0.0515011 ],\n",
       "       [ 0.01567072],\n",
       "       [ 0.09550604],\n",
       "       [ 0.13746068],\n",
       "       [-0.03299714],\n",
       "       [ 0.00905125],\n",
       "       [ 0.03818068],\n",
       "       [ 0.01637242],\n",
       "       [ 0.02945078],\n",
       "       [-0.02053093],\n",
       "       [ 0.01553041],\n",
       "       [ 0.02357874],\n",
       "       [ 0.03653855],\n",
       "       [ 0.0365683 ],\n",
       "       [ 0.02449493],\n",
       "       [ 0.03341179],\n",
       "       [ 0.1088936 ],\n",
       "       [ 0.14537617],\n",
       "       [ 0.08819406],\n",
       "       [ 0.029425  ],\n",
       "       [ 0.12084447],\n",
       "       [ 0.1085494 ],\n",
       "       [ 0.10499277],\n",
       "       [ 0.10878411],\n",
       "       [ 0.15273565],\n",
       "       [ 0.09631851],\n",
       "       [ 0.10784056],\n",
       "       [ 0.18707243],\n",
       "       [ 0.21356835],\n",
       "       [ 0.13836788],\n",
       "       [ 0.18310381],\n",
       "       [ 0.20395845],\n",
       "       [ 0.02785495],\n",
       "       [ 0.13664969],\n",
       "       [ 0.06049058],\n",
       "       [ 0.17076429],\n",
       "       [ 0.32148482],\n",
       "       [ 0.11661443],\n",
       "       [ 0.17118633],\n",
       "       [ 0.17300112],\n",
       "       [ 0.17304475],\n",
       "       [ 0.14277622],\n",
       "       [ 0.05237222],\n",
       "       [ 0.01282461],\n",
       "       [ 0.17918818],\n",
       "       [ 0.14265256],\n",
       "       [-0.0888664 ],\n",
       "       [-0.00977479],\n",
       "       [-0.07390015],\n",
       "       [ 0.13543179],\n",
       "       [ 0.07885046],\n",
       "       [-0.00038623],\n",
       "       [ 0.12922968],\n",
       "       [ 0.28446581],\n",
       "       [ 0.27633005],\n",
       "       [ 0.0879893 ],\n",
       "       [-0.07060807],\n",
       "       [ 0.14111223],\n",
       "       [ 0.14202021],\n",
       "       [ 0.13510823],\n",
       "       [ 0.16051507],\n",
       "       [ 0.10938729],\n",
       "       [ 0.15306268],\n",
       "       [ 0.15654179],\n",
       "       [ 0.12114417],\n",
       "       [ 0.09503877],\n",
       "       [ 0.09760644],\n",
       "       [-0.06702871],\n",
       "       [ 0.13335349],\n",
       "       [ 0.2304109 ],\n",
       "       [ 0.02158982],\n",
       "       [ 0.05238266],\n",
       "       [ 0.33861953],\n",
       "       [ 0.33861953],\n",
       "       [ 0.33178444],\n",
       "       [ 0.22090921],\n",
       "       [ 0.33791264],\n",
       "       [ 0.33775736],\n",
       "       [ 0.32354591],\n",
       "       [ 0.26888581],\n",
       "       [ 0.32974075],\n",
       "       [ 0.33983658],\n",
       "       [ 0.33771937],\n",
       "       [ 0.33862605],\n",
       "       [ 0.33069175],\n",
       "       [ 0.29014808],\n",
       "       [ 0.32930062],\n",
       "       [ 0.32929382],\n",
       "       [ 0.32300565],\n",
       "       [ 0.33104607],\n",
       "       [ 0.32854163],\n",
       "       [ 0.33088083],\n",
       "       [ 0.33109518],\n",
       "       [ 0.33027441],\n",
       "       [ 0.31914236],\n",
       "       [ 0.31681047],\n",
       "       [ 0.26041081],\n",
       "       [ 0.32898397],\n",
       "       [ 0.33081019],\n",
       "       [ 0.33130119],\n",
       "       [ 0.33085586],\n",
       "       [ 0.32225367],\n",
       "       [ 0.33056904],\n",
       "       [ 0.20585076],\n",
       "       [ 0.27959042],\n",
       "       [ 0.33043495],\n",
       "       [ 0.19589353],\n",
       "       [ 0.20902788],\n",
       "       [ 0.33107309],\n",
       "       [ 0.32219902],\n",
       "       [ 0.33121478],\n",
       "       [ 0.32974064],\n",
       "       [ 0.32945468],\n",
       "       [ 0.33095427],\n",
       "       [ 0.26586856],\n",
       "       [ 0.33109367],\n",
       "       [ 0.33270877],\n",
       "       [ 0.27950625],\n",
       "       [ 0.33112404],\n",
       "       [ 0.32333139],\n",
       "       [ 0.33005045],\n",
       "       [ 0.32727482],\n",
       "       [ 0.31469139],\n",
       "       [ 0.32951468],\n",
       "       [ 0.32708431],\n",
       "       [ 0.33061978],\n",
       "       [ 0.33007414],\n",
       "       [ 0.23557863],\n",
       "       [ 0.32527029],\n",
       "       [ 0.18797044],\n",
       "       [-0.07834875],\n",
       "       [-0.12664278],\n",
       "       [-0.03343796],\n",
       "       [-0.03668274],\n",
       "       [-0.07800171],\n",
       "       [-0.12776136],\n",
       "       [ 0.12079897],\n",
       "       [-0.00287773],\n",
       "       [ 0.28438852],\n",
       "       [ 0.33838594],\n",
       "       [-0.00202868],\n",
       "       [ 0.16889448],\n",
       "       [ 0.26981415],\n",
       "       [ 0.00615674],\n",
       "       [ 0.26830259],\n",
       "       [ 0.15300911],\n",
       "       [ 0.14672174],\n",
       "       [-0.01776988],\n",
       "       [ 0.34255158],\n",
       "       [ 0.34252317],\n",
       "       [ 0.33827115],\n",
       "       [ 0.33881015],\n",
       "       [ 0.33867411],\n",
       "       [ 0.33924422],\n",
       "       [ 0.33606628],\n",
       "       [ 0.32889318],\n",
       "       [ 0.33001252],\n",
       "       [ 0.33793336],\n",
       "       [ 0.33845324],\n",
       "       [ 0.33822171],\n",
       "       [ 0.3377894 ],\n",
       "       [ 0.33970028],\n",
       "       [ 0.33912039],\n",
       "       [ 0.3312765 ],\n",
       "       [ 0.33834236],\n",
       "       [ 0.33899935],\n",
       "       [ 0.33445551],\n",
       "       [ 0.29539595],\n",
       "       [ 0.33873519],\n",
       "       [ 0.33593964],\n",
       "       [ 0.33751217],\n",
       "       [ 0.33843779],\n",
       "       [ 0.32715762],\n",
       "       [ 0.33790971],\n",
       "       [ 0.30909913],\n",
       "       [ 0.33773314],\n",
       "       [ 0.21399907],\n",
       "       [ 0.33449311],\n",
       "       [ 0.33427882],\n",
       "       [ 0.33840329],\n",
       "       [ 0.34013622],\n",
       "       [ 0.33832069],\n",
       "       [ 0.33829938],\n",
       "       [ 0.20769568],\n",
       "       [ 0.33787193],\n",
       "       [ 0.33838223],\n",
       "       [ 0.28117595],\n",
       "       [ 0.28613805],\n",
       "       [ 0.24497483],\n",
       "       [ 0.33822975],\n",
       "       [ 0.33723383],\n",
       "       [ 0.33779185],\n",
       "       [ 0.33717097],\n",
       "       [ 0.33878837],\n",
       "       [ 0.33793889],\n",
       "       [ 0.33916011],\n",
       "       [ 0.33863907],\n",
       "       [ 0.33902169],\n",
       "       [ 0.33884668],\n",
       "       [ 0.33819285],\n",
       "       [ 0.33954186],\n",
       "       [ 0.33907445],\n",
       "       [ 0.32487067],\n",
       "       [ 0.33843248],\n",
       "       [ 0.33900542],\n",
       "       [ 0.17913124],\n",
       "       [ 0.22496912],\n",
       "       [ 0.33758507],\n",
       "       [ 0.33802536],\n",
       "       [ 0.33895247],\n",
       "       [ 0.17109307],\n",
       "       [ 0.31151349],\n",
       "       [ 0.33722258],\n",
       "       [ 0.31214595],\n",
       "       [ 0.28472483],\n",
       "       [ 0.33716018],\n",
       "       [ 0.33754657],\n",
       "       [ 0.30806772],\n",
       "       [ 0.33768619],\n",
       "       [ 0.3258158 ],\n",
       "       [ 0.33434269],\n",
       "       [ 0.33804434],\n",
       "       [ 0.25936727],\n",
       "       [ 0.33865009],\n",
       "       [ 0.33936409],\n",
       "       [ 0.3396642 ],\n",
       "       [ 0.33840511],\n",
       "       [ 0.33653558],\n",
       "       [ 0.33809866],\n",
       "       [ 0.33797957],\n",
       "       [ 0.33638544],\n",
       "       [ 0.33939335],\n",
       "       [ 0.33774089],\n",
       "       [ 0.3390989 ],\n",
       "       [ 0.02956359],\n",
       "       [-0.06854858],\n",
       "       [ 0.26446365],\n",
       "       [ 0.33751399],\n",
       "       [ 0.33841186],\n",
       "       [ 0.33780919],\n",
       "       [ 0.33755107],\n",
       "       [ 0.3380708 ],\n",
       "       [ 0.12816015],\n",
       "       [ 0.33969005],\n",
       "       [ 0.24992654],\n",
       "       [ 0.33775264],\n",
       "       [ 0.33904206],\n",
       "       [ 0.33994507],\n",
       "       [ 0.33828835],\n",
       "       [ 0.33857198],\n",
       "       [ 0.33518565],\n",
       "       [ 0.33177732],\n",
       "       [ 0.33748148],\n",
       "       [ 0.33841827],\n",
       "       [ 0.3389768 ],\n",
       "       [ 0.33259337],\n",
       "       [ 0.33828347],\n",
       "       [ 0.33888203],\n",
       "       [ 0.33674622],\n",
       "       [ 0.33520395],\n",
       "       [ 0.33796921],\n",
       "       [ 0.28306056],\n",
       "       [ 0.00666737],\n",
       "       [ 0.33738954],\n",
       "       [ 0.33842149],\n",
       "       [ 0.25329547],\n",
       "       [ 0.33639805],\n",
       "       [ 0.33840063],\n",
       "       [ 0.33861502],\n",
       "       [ 0.33864971],\n",
       "       [ 0.33864971],\n",
       "       [ 0.27150507],\n",
       "       [ 0.33876424],\n",
       "       [ 0.33170193],\n",
       "       [ 0.15508134],\n",
       "       [ 0.15124559],\n",
       "       [ 0.33735371],\n",
       "       [ 0.33838608],\n",
       "       [ 0.32122304],\n",
       "       [ 0.33830103],\n",
       "       [ 0.33817834],\n",
       "       [ 0.33920157],\n",
       "       [ 0.31553591],\n",
       "       [ 0.33844396],\n",
       "       [ 0.26844708],\n",
       "       [ 0.33703224],\n",
       "       [ 0.33782045],\n",
       "       [ 0.33853411],\n",
       "       [ 0.33786006],\n",
       "       [ 0.33804016],\n",
       "       [ 0.33844763],\n",
       "       [ 0.33708995],\n",
       "       [ 0.33753368],\n",
       "       [ 0.33821389],\n",
       "       [ 0.33896257],\n",
       "       [ 0.3378944 ],\n",
       "       [ 0.33810338],\n",
       "       [ 0.21627498],\n",
       "       [ 0.33792678],\n",
       "       [ 0.27646782],\n",
       "       [ 0.33755066],\n",
       "       [ 0.33804425],\n",
       "       [ 0.33785489],\n",
       "       [ 0.33980728],\n",
       "       [ 0.33700378],\n",
       "       [ 0.33734942],\n",
       "       [ 0.33326433],\n",
       "       [ 0.3386217 ],\n",
       "       [ 0.33853947],\n",
       "       [ 0.33873161],\n",
       "       [ 0.33984378],\n",
       "       [ 0.33695506],\n",
       "       [ 0.33743016],\n",
       "       [ 0.33835328],\n",
       "       [ 0.33933526],\n",
       "       [ 0.33316356],\n",
       "       [ 0.33525927],\n",
       "       [ 0.33907131],\n",
       "       [ 0.33516038],\n",
       "       [ 0.33829887],\n",
       "       [ 0.33809719],\n",
       "       [ 0.33928091],\n",
       "       [ 0.33749952],\n",
       "       [ 0.33609492],\n",
       "       [ 0.33644585],\n",
       "       [ 0.33806555],\n",
       "       [ 0.33898691],\n",
       "       [ 0.33861962],\n",
       "       [ 0.33776183],\n",
       "       [ 0.33874228],\n",
       "       [ 0.33843602],\n",
       "       [ 0.33816318],\n",
       "       [ 0.3387832 ],\n",
       "       [ 0.32863885],\n",
       "       [ 0.33744154],\n",
       "       [ 0.33787241],\n",
       "       [ 0.33948313],\n",
       "       [ 0.33836375],\n",
       "       [ 0.33758394],\n",
       "       [ 0.3377148 ],\n",
       "       [ 0.33803362],\n",
       "       [ 0.33732194],\n",
       "       [ 0.33769504],\n",
       "       [ 0.33886312],\n",
       "       [ 0.33164065],\n",
       "       [ 0.33854876],\n",
       "       [ 0.33867128],\n",
       "       [ 0.33607919],\n",
       "       [ 0.15850566],\n",
       "       [ 0.32506562],\n",
       "       [ 0.33165544],\n",
       "       [ 0.03312875],\n",
       "       [ 0.33748915],\n",
       "       [ 0.33778145],\n",
       "       [ 0.33977398],\n",
       "       [ 0.23332511],\n",
       "       [ 0.33579172],\n",
       "       [ 0.33796146],\n",
       "       [ 0.33945525],\n",
       "       [ 0.33832248],\n",
       "       [ 0.33822629],\n",
       "       [ 0.29368058],\n",
       "       [ 0.24762584],\n",
       "       [ 0.20053024],\n",
       "       [ 0.33705716],\n",
       "       [ 0.33817939],\n",
       "       [ 0.33736959],\n",
       "       [ 0.33889328],\n",
       "       [ 0.3322438 ],\n",
       "       [ 0.02273413],\n",
       "       [ 0.33064009],\n",
       "       [ 0.22992217],\n",
       "       [ 0.3268257 ],\n",
       "       [ 0.33044911],\n",
       "       [ 0.32270085],\n",
       "       [ 0.32757247],\n",
       "       [ 0.10931196],\n",
       "       [ 0.32976592],\n",
       "       [ 0.32923081],\n",
       "       [ 0.21762772],\n",
       "       [ 0.32997233],\n",
       "       [ 0.33084453],\n",
       "       [ 0.3309151 ],\n",
       "       [ 0.33144158],\n",
       "       [ 0.33107283],\n",
       "       [ 0.33015166],\n",
       "       [ 0.33012662],\n",
       "       [ 0.3301289 ],\n",
       "       [ 0.32976074],\n",
       "       [ 0.30370862],\n",
       "       [ 0.33079832],\n",
       "       [ 0.33107205],\n",
       "       [ 0.32370493],\n",
       "       [ 0.33123455],\n",
       "       [ 0.14540096],\n",
       "       [ 0.33051581],\n",
       "       [ 0.32896259],\n",
       "       [ 0.3290534 ],\n",
       "       [ 0.3281614 ],\n",
       "       [ 0.32748754],\n",
       "       [ 0.33127026],\n",
       "       [ 0.33860601],\n",
       "       [ 0.33924281],\n",
       "       [ 0.33840406],\n",
       "       [ 0.33847459],\n",
       "       [ 0.34014239],\n",
       "       [ 0.33666898],\n",
       "       [ 0.3378878 ],\n",
       "       [ 0.34120023],\n",
       "       [ 0.3369516 ],\n",
       "       [ 0.33901583],\n",
       "       [ 0.33717759],\n",
       "       [ 0.33711342],\n",
       "       [ 0.33887459],\n",
       "       [ 0.25841838],\n",
       "       [ 0.17148429],\n",
       "       [ 0.33826907],\n",
       "       [ 0.3378485 ],\n",
       "       [ 0.33887084],\n",
       "       [ 0.33841512],\n",
       "       [ 0.34530573],\n",
       "       [ 0.33770155],\n",
       "       [ 0.33729284],\n",
       "       [ 0.33825105],\n",
       "       [ 0.33746151],\n",
       "       [ 0.33920245],\n",
       "       [ 0.33834187]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X_train)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data to plot from trained ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cpp\n",
    "// get the ann data\n",
    "// cpp imports\n",
    "#include <cstdlib>\n",
    "#include <vector>\n",
    "#include <iostream>\n",
    "#include <map>\n",
    "#include <string>\n",
    "\n",
    "#include \"TFile.h\"\n",
    "#include \"TTree.h\"\n",
    "#include \"TString.h\"\n",
    "#include \"TSystem.h\"\n",
    "#include \"TROOT.h\"\n",
    "#include \"TStopwatch.h\"\n",
    "\n",
    "#include \"TMVA/Tools.h\"\n",
    "#include \"TMVA/Reader.h\"\n",
    "// our vectors, which we are using to get around the fundamental problem, that rootpy can't construct root/cpp floats\n",
    "// and we therefore otherwiese couldn't give a reference over to tmva in the later code\n",
    "std::vector<float> vars;\n",
    "std::vector<TString> varsName;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get metadata from the original trainingset\n",
    "originalTrainingSet = filePath\n",
    "inputFile = ROOT.TFile.Open( originalTrainingSet )\n",
    "regTree = inputFile.Get(\"TreeR\")\n",
    "leaves = regTree.GetListOfLeaves()\n",
    "varsName = []\n",
    "# add all variables, except throughput and timestamp\n",
    "for i in xrange(len(leaves)):\n",
    "    if (leaves[i].GetName() == \"timestamp\") or (leaves[i].GetName() == \"throughput\"):\n",
    "            continue\n",
    "    ROOT.varsName.push_back(leaves[i].GetName())\n",
    "    # keep a copy in python which is easyer to handle\n",
    "    varsName.append(leaves[i].GetName())\n",
    "# resize other vector to fit\n",
    "ROOT.vars.resize(len(ROOT.varsName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cpp\n",
    "// switch to C++ to avoid the annoying reference problem, mentioned above\n",
    "// --- Create the Reader object\n",
    "TMVA::Reader *reader = new TMVA::Reader( \"!Color:!Silent\" );\n",
    "\n",
    "// Create a set of variables and declare them to the reader\n",
    "// - the variable names MUST corresponds in name and type to those given in the weight file(s) used\n",
    "// add the variables that we just stored in our C++ vector (what a time to be alive)\n",
    "\n",
    "for (int i = 0; i < varsName.size(); i++){\n",
    "    reader->AddVariable( varsName[i], &vars[i] );\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodMLP object (\"MLP\") at 0x8a6ce40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reader                   : Booking \"MLP method\" of type \"MLP\" from /root/Downloads/weights/TMVARegression_MLP.weights.xml.\r\n",
      "--- MethodBase               : Reading weight file: /root/Downloads/weights/TMVARegression_MLP.weights.xml\r\n",
      "--- MLP                      : Read method \"MLP\" of type \"MLP\"\r\n",
      "--- MLP                      : MVA method was trained with TMVA Version: 4.2.1\r\n",
      "--- MLP                      : MVA method was trained with ROOT Version: 6.06/06\r\n",
      "--- DataSetInfo              : Added class \"Regression\"\t with internal class number 0\r\n",
      "--- MLP                      : Building Network\r\n",
      "--- MLP                      : Initializing weights\r\n",
      "--- Reader                   : Booked classifier \"MLP\" of type: \"MLP\"\r\n"
     ]
    }
   ],
   "source": [
    "methodName = \"MLP method\"\n",
    "weightfile = \"/root/Downloads/weights/TMVARegression_MLP.weights.xml\"\n",
    "ROOT.reader.BookMVA( methodName, weightfile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add the data to our dataset\n",
    "dataSet_with_ann_data = dataSet_CERN_to_RAL_normalized.copy(deep=True)\n",
    "for i in xrange(len(dataSet_with_ann_data)):\n",
    "    for j in xrange(len(varsName)):\n",
    "        ROOT.vars[j] = dataSet_with_ann_data[varsName[j]][i]\n",
    "    output = ROOT.reader.EvaluateRegression( \"MLP method\" )[0]\n",
    "    dataSet_with_ann_data.set_value(i, 'throughput', output)\n",
    "# rescale stuff\n",
    "dataSet_with_ann_data = inverseNormalizeDataSet(dataSet_with_ann_data, scaler_for_CERN_to_RAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataSets with packet_loss: 639\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAIxCAYAAAB3mM9PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xt8VNXV//HvSgj3YAQEpUKCKAoJUm1RkIIRi1IR9dG2\nVmtroRetvTy2Fduax2vNUytVtBdrL16rrX28tFpirfLTAEbUIncCWBGCBgWLRALIJcn6/XEmMYRk\nkpBJzpzM5/16zWtmztlzzpoTmKzsWXtvc3cBAAAASIy0sAMAAAAAOhMSbAAAACCBSLABAACABCLB\nBgAAABKIBBsAAABIIBJsAAAAIIFIsAF0amZWY2bnt8Nx7zOzpxJ93GRiZpeaWWXYccQThRgBpB4S\nbAChiSWpNWZWbWZ7zWydmc0ys55hx1bLzE6Nxdg37Fjak5mtN7PvN7IrCosldEiMqfBHFYDE6BJ2\nAABS3nOSLpHUVdIESfdI6iHp22EGVY8pSOAs7ECiwMzS3b067DgAIEz0YAMI2x53f8/dy939EUkP\nSTpPkswszcz+YGZvmtkuM3vdzGY2PECsTGC5me02s3fM7L6mTmZmPzSzLWZ2Uux5hpn9zMzeMrOd\nZvaKmZ0R25ct6fnYS9+L9bTf28Rxu5rZHWb2rpl9aGYLzWx8vf1dzOwXZlYei7PMzP633v7zzWxZ\n7H1uNbMXzOywJs71sJk91mCbmdlGM7sy9nxiLIZKM6sws5fNbGQTx3tBUrakWbXfKDTYP8nMVpjZ\nDjN73sxy6u27PrbvUjN7Q9JuM+vZgutxwDcDZpYd23ZivW1TzWxN7BjPm9nnY22GHESMX41d911m\n9lcz61evzQG907Wvq30s6VJJU+t96zKxsesJACTYAJLNHkndYo/TJL0t6bOSjpN0jaQfm9n02sZm\ndpmkuxX0fOdJmiJpeWMHNrOfS/qWpInu/mps8/0Kes6/IClX0gOSnjKzUZI2Srog1m6EpCMk/XcT\ncc+S9DlJX5H0cUkrJD1jZgNj+/9b0rmSPi/paEkXSlobi2ugpD9Lui/2PidI+mNTF0jBHyFnmVlm\nvW35kg6X9CczS5f0N0nzJY2SdJKkOyQ11bN8voLrfGPsGEfU29dd0o9i72uspCxJv2nw+qGSLlLw\ncxqt4GfY3PWQGi/tqNsWS6Ifl/R3ScdL+pWkWxt5XUtizJH0RUnTJJ0u6RgF/2aaU3uun0v6P0lz\nJQ1UcI1easHrAaSgyJSImNk9ks6WtNndj2+m7RBJ90o6TNJWSZe4+6b2jxJAW8R6lS+W9KwkuXuV\npBvqNdloZp9QkMzV9lL/j6Tb3f3Oeu2WNTh0eqxXe5ykU9z97dj5jlKQWGfXbpN0l5lNlnSZu3/b\nzN6PbX/P3d9XIyyoGb9c0gx3fya27XJJkxQk9NdJGiLpdXcvib3sbUkvxx4PUvB5/Li7vxXbVtrE\nZZKC67NdQUJbex0ulvS8u28xs0MlHSJpjrtviO1/vamDufu2WK/1Dnff0mB3uqQr3P2N2Pv6uQ5M\nTDMUfM7+pxXXoyn1S3G+KWmdu9d+a/FvMztW0s0HEWN3SV9y9/JYm8skLTCzYe6+Lk48kiR332lm\nH0rq6e7vNdceQGqLUg/2fZLObGHbn0u6391HS7pJ0i3tFhWAtvpMrIzhQ0klkl6Q9N3anWZ2uZn9\ny4KyjkpJ31OQrCpWQvExfVTG0ZTbJE2U9Kl6ibQknaggoSuNxVAZO8dZkoa14j0MU5Ag1/VounuN\npIWSassy7pd0ggVlLr8ys7PMrDaZXCbp/0laZWaPxd5z/6ZOFqtx/ouCHlmZWVcFPe1/jO3fpqAn\n/lkzm2Nm3zOzwa14P/XtqU1cYzZJ6mpmWfW2vV2bXMe05Hq0xLGS/tVg2ysHGWN5bXJd7zg1Cr6Z\nAICEikyC7e4vStpWf5uZHWVm/4j98p1nZsNju0Yq+CUtdy9W8LUsgOQ0T8HX/8MldXf3z9XrCb1Q\n0mwF30idoaD84C4FAyJb41kFpQ9TG2xPU5BkfTJ27NrbCEkzDubNNMIlyd2XKKhz/pGCpP4BfdRT\nX+PuZ0iarCDZ/qqC3tpRcY77kKRTzewIBd/uZUj6a91J3WcoKA2ZJ+kcSWtjPfOtVdXY+9H+vz92\ntuJ4ta+vid3X77HOaMVx6mtJjM2paRBLW+IBkOIik2A34XeSvu3uYyTN1Ec1d0sV1BTKgvlve8e+\nMgWQfHa5+3p3f6uR2SfGS3rZ3X/j7kvd/U0F9cuSpNhX9eUKamrjeVpBPfBvzOzL9bYvUZBUHeHu\nbza4vRNrszd2nx7n+Osk7YvFKykYoKmgJKWu1MPdd7r7E+7+LQXJ/ulmVv/9vOLuP4l9pm1SUKfd\nKHf/l6Q3FJSGXCzpSXff1aDNCnef5e6nSSpWMEivKXubeY+t0ZLr8Z5i177e607Q/vXVaxT88VPf\nyQcZ08fM7GMNjmOSVteL54gGr/l4g+eJvEYAOrHIJthm1kvSKZIeNbMlkn6rYOCJFCTb+Wb2moLB\nQuVqenAPgOT1uqQTzWyKmR1tZtcqKPWor1DSlWZ2pZkdY2Yft0bmc3b3+kn2l2Lb/i3pT5LuN7ML\nzGyomX3CzH5gZufFXlqmIOmbamb9Y589DY+9S8Ef+D8zs8+Y2XEKBl4OkPRrSYqVaXzBzI6LJdVf\nlPSBpLfN7GQzKzCzT5rZYDM7V9KRklY1c33+JOlrCkpaHqrdaGY5ZvZTMxtnZkPM7DQF3xLEO94G\nSRPMbFD92TWaEHfKwmaux12xZm9IekvSDbGf2xmSChoc6m5JwyyYG314rMPkG7WnaWWMuyU9YGaj\nzWxcLL459eqvn1dQwjPdzIZZMFvN+AbH2CApLxZLPzOLzDgmAB3M3SNzU/D16vLY40wFNXXNvaaX\npI1hx86NG7cDbwrGVjwVZ3+GpN8rGKz8fuzx/0h6s0G76ZJWKkiiNkn6Q7191ZLOr/f8bAUlDZfE\nnqcrGHT3Rr3X/03SCfVeU6DgD/UqSfc2FruCspXbJb0j6UMF9cfj6u3/mqTXFCTVFQrK2E6O7TtO\nQS977Wtfl/SDFly/oQpKGzZJSqu3fYCC2Tfeih1vg6SfSkqPc6yTFfTofyipOrbtUknbG7Q7NXZN\n+8aeX1/7udygXdzrEWszVtLi2M+jRNJnYsc+sV6bsxT0ZO9SUO7ylVibw1obY+xnsDF2vick9Wvw\nuutiP+dtCmYsubn+e5PUX9IzCgaYViuYjSb0/0fcuHFLvpu5h7tIl5n9WMEiE9UKpnGa7u57m2ib\nI+nv7j4q9vxFSXe4+2Ox58e7+/JY78v77u5mdrOkKne/od3fDACgXZnZf0u6wd1bXPZnwRzWF3gz\nM1ABQKKEWiJiwSIOX1fQU3S8glHnX2ii7Z8U9IAMt2AxhekKvmL9qpktNbOVCgbySMF8sGvNbI2C\nnpzC9n0nAID2YGZXmNmYWNnLRQq+wWhyISEASAZh149tVzBopJeZ1UjqqeCrzgO4+8VNHOMzjbR9\nXMHXowCAaDtawQJDfRXMHX6XpJ+EGhEANCMZSkS+rqBOb5ekZ939S6EGBAAAALRB2CUiRylYNCJb\nwUpmvc2sqZ5qAAAAIOmFXSLySUklHlt+2MyeUDD13p/qNzKzcLvZAQAAkDLcPe50pM0Jex7stZLG\nmln32JLBp+ujSf/3E/Z0K1G4XX/99aHHEJUb14rrxLXiOiXzjevEteI6hXdLhFATbHdfJulBBXPD\nLlOwMMDvwowJAAAAaIuwS0Tk7rMkzQo7DgAAACARwi4RQQLl5+eHHUJkcK1ahuvUclyrluE6tQzX\nqeW4Vi3DdepYoU/T1xJm5lGIEwAAANFmZvKID3IEAAAAOpXQa7ABAEDqyMnJUVlZWdhhIMVlZ2dr\nw4YN7XZ8SkQAAECHiX39HnYYSHHx/h1SIgIAAAAkGRJsAAAAIIFIsAEAAIAEIsEGAAAAEogEGwAA\nIIWVlZUpLS1NixcvDjuUToMEGwAAoBnTp09XWlqa0tPT1bVrVw0cOFCTJk3SXXfdpaqqqlYda968\neUpLS9P777/fTtG2zpAhQ/Tuu+/q4x//eItf88ADDygzM7Mdo4o2EmwAAIAWmDx5st59912VlZXp\nueee0znnnKPrr79eEyZM0Icfftji47h7Uk1XaGYaMGCA0tJanhbWvgc0jgQbAAAkl8pKaeHC4D6J\njtWtWzcddthhOuKII3T88cfryiuvVHFxsRYvXqxbb721rt3DDz+sk046SX369NHAgQP1+c9/Xps2\nbZIUlGNMmjRJknTYYYcpPT1dM2bMkCT985//1MSJE9W3b1/169dPU6ZM0Zo1a+LGNH36dE2bNk2F\nhYU6/PDDlZmZqRkzZmjPnj11bfbu3asrr7xShx9+uHr06KFx48appKSkbn/DEpHaHvbnn39eY8eO\nVa9evTRmzBgtWbKkbv+MGTO0c+fOul79m266SZL0xBNPaPTo0erZs6f69eun0047Te+9915bL33k\nkGADAIDkUVkpTZggTZwY3LclMU7ksZqQm5urKVOm6PHHH6/btm/fPt10001avny5ioqKtHXrVl18\n8cWSpMGDB9e1Xb16td555x3deeedkqSdO3fqe9/7nhYtWqR58+YpKytL06ZNa7YEZd68eVq+fLme\nf/55PfHEE3r22Wf1wx/+sG7/zJkz9eijj+r+++/X0qVLNWrUKE2ZMkWbN2+ua9NYb/Q111yjW2+9\nVUuWLFG/fv10ySWXSJJOOeUU3XHHHerZs6c2b96sd955R1dddZU2b96siy66SNOnT9eaNWu0YMEC\nfelLXzrIKxtx7p70tyBMAAAQdc3+Tn/pJfcuXdwl94wM94ULD/5kCTzWV77yFZ82bVqj+370ox95\nr169mnzt6tWr3cy8vLzc3d2Li4s9LS3Nt27dGvecO3bs8PT0dC8pKYkb16GHHuq7du2q2/bQQw95\n9+7dfdeuXb5z507v2rWrP/TQQ3X7q6urfdiwYX7ttde6u/uGDRvczPy1116ri8/M/Lnnnqt7TUlJ\niaelpdW9h/vvv98zMzP3i2Xx4sWelpbmGzdujPu+kkG8f4exfW3KXenBBgAAySMvT8rNlTIypJEj\ng8fJcKw4vEE98uLFi3XeeecpJydHffr00ZgxY2Rm2rhxY9zjvPnmm7r44ot19NFH65BDDtHhhx8u\nd2/2dccff7x69OhR93zcuHHau3ev1q1bp3Xr1qmqqkqnnHJK3f60tDSNGzdOpaWlTR7TzDRq1Ki6\n54MGDZK7a8uWLU2+ZvTo0Tr99NOVm5urz372s7r77rv1n//8J27snRUJNgAASB6ZmdKCBdL8+cF9\nW2aqSOSx4igtLdVRRx0lSdq1a5emTJmi3r1766GHHtKiRYv0zDPPyN21d+/euMeZOnWqtm7dqt/9\n7nd69dVXtXTpUqWnpzf7usZ4vQGU9R/X19wgxYyMjAPa1tTUNNk+LS1Nzz77rJ577jmNHj1a99xz\nj4455hitWLGiNaF3CiTYAAAguWRmSmPHJiYhTuSxGrFy5Uo988wz+tznPidJWrNmjbZu3arCwkJ9\n6lOf0vDhw7V58+b9ktmuXbtKkqqrq+u2vf/++1q7dq2uueYaTZo0Sccee6w++OCDFk0BuGLFiv1m\nMVm4cKG6deumYcOGadiwYeratet+gxpramq0cOFCjRw58qDfd9euXfeLv76TTz5Z1157rf71r39p\n0KBB+stf/nLQ54mqLmEHAAAAEAV79uzR5s2bVVNTo/fee09z587VT3/6U40ZM0Y/+MEPJAVzSnfr\n1k2//OUv9a1vfUulpaW67rrr9jtOdna2zExFRUU6++yz1aNHDx166KHq37+/fv/73+vII4/U22+/\nrauvvnq/XuSmVFVVacaMGbr22mtVXl6uH//4x/rGN75RVzbyzW9+Uz/84Q/Vr18/DR06VLfffru2\nbNmiK664osljNtXrXSsnJ0e7d+/W3LlzdcIJJ6hnz55avny55s6dqzPPPFMDBw7U4sWL9fbbbyu3\nnUpzkhk92AAAAC0wd+5cDRo0SNnZ2fr0pz+tOXPm6KabbtK8efPqktn+/fvrgQce0JNPPqnc3Fz9\n5Cc/0ezZs/c7zqBBg3TjjTeqoKBAhx9+uL7zne/IzPSXv/xFy5cv16hRo/Sd73xHN998s7p169Zs\nXKeeeqpyc3N12mmn6YILLtCnP/1p/exnP6vb/7Of/UwXXnihZsyYoRNOOEErV67UP//5Tw0cOLCu\nTcNykcbKR+pvGzdunC6//HJddNFFGjBggGbNmqVDDjlEJSUlmjZtmoYPH66ZM2fquuuu00UXXdSy\nC9yJWHN/oSQDM/MoxAkAAOJLpgVWOoPp06dr69ateuqpp8IOJVLi/TuM7WvTKjr0YAMAAAAJRIIN\nAAAAJBAlIgAAoMNQIoJkQIkIAAAAECEk2AAAAEACkWADAAAACUSCDQAAACQQCTYAAACQQCTYAAAA\nQAKRYAMAAETQqFGjdNNNN4UdxkGbN2+e0tPT9f7774cdSsKRYAMAALTQkiVLlJaWpgkTJoQdSqs9\n8MADyszMDDuMOuPHj9c777yjvn37tvg1N954o0aNGtWOUSUGCTYAAEgKRUVSRcX+2yoqgu1hHqu+\nP/zhDzrppJP08ssva+3atW07WAdzd5m1af2UhOrSpYsGDBjQ6tcl03toCgk2AABICuPHSwUFHyXG\nFRXB8/Hjwz1Wrd27d+tPf/qTbrjhBk2aNEn33HPPfvvLysqUlpamJ554QmeccYZ69eql3NxczZ07\nt67NvHnzlJaWpueff15jx45Vr169NGbMGC1ZsiTuud977z2de+656tmzp4YOHar77rvvgDazZ8/W\n6NGj1bt3bx155JH6+te/ru3bt9edd8aMGdq5c6fS0tKUnp5eV17y8MMP66STTlKfPn00cOBAff7z\nn9emTZvixnPaaafpm9/8pq688kr17dtXffv21dVXX71fm4qKCl166aXq27evevbsqcmTJ6u0tPSA\na1FbIlLbw/78889r1KhR6t27tyZNmqSysrK6/TfeeKNWrVpV9x4efPBBSdJvf/tbHXvsserRo4cO\nO+wwfeYzn1FNTU3c99Cu3D3pb0GYAAAg6pr7nb5tm/sVV7ivXx/cb9t28OdK5LHc3R988EHPzs52\nd/dHH33UBw4c6FVVVXX7N2zY4GbmI0aM8KKiIn/jjTf80ksv9f79+/vOnTvd3b24uNjNzE8++WSf\nN2+er1271s8880wfOXJk3HN/5jOf8by8PF+4cKEvXbrU8/PzPTMz02+88ca6Nnfeeae/8MILXlZW\n5vPnz/fRo0f7l7/8ZXd337t3r995553eu3dv37Jli2/evLkupvvuu8//8Y9/+Pr16/1f//qXT5o0\nyU899dS48eTn53ufPn38u9/9rq9du9YfffRRP+SQQ3z27Nl1bc455xwfMWKEv/jii75y5Uo/55xz\nfPDgwb579+66a5GWluZbt251d/f777/fMzIyfPLkyb5o0SJfsWKFn3DCCT5lyhR3d//www/9qquu\n8hEjRtS9h927d/uiRYu8S5cu/uc//9k3btzoy5cv9zvuuMOrq6ubjD/ev8PYvrblrm09QEfcSLAB\nAOgcWvI7ff36IENZv77t50vksfLz8/2mm25yd/d9+/b54Ycf7o8//njd/toE+/e//33dtvLycjcz\nLykpcfePEuznnnuurk1JSYmnpaV5eXl5o+d9/fXX3cx84cKFddvKyso8PT19vwS7oWeeeca7d+9e\n9/z+++/3zMzMZt/n6tWr3cyajMc9uBbHHnvsfttuvvlmHzx48H4xv/jii3X7P/jgAz/kkEP8nnvu\ncffGE+y0tDT/97//Xfeahx9+eL/3cMMNN/ioUaP2O+8TTzzhWVlZvmPHjmbfW632TrApEQEAAEmj\nokKaNUtavz64b1hHHdax3njjDb344ouaPn26pKB++NJLLz2gTETSfoPwBg0aJEnasmVL3TYzO6CN\nu+/Xpr7Vq1crPT1dY8aMqds2ZMiQumPXev7553XGGWdo8ODB6tOnj84//3zt3btX7777btz3tnjx\nYp133nnKyclRnz59NGbMGJmZNm7cGPd1Y8eO3e/5uHHjVF5erh07dmjNmjVKT0/fr02fPn00atSo\n/cpEGurWrZuOPvrouueDBg3S3r17VRHnhzd58mRlZ2crJydHl1xyiR588EHt2LEjbuztjQQbAAAk\nhdo66cJCKScnuK9fRx3WsaRgcGNNTY2GDh2qjIwMZWRk6LbbbtOzzz6r8vLy/dpmZGQc8PqG9cD1\n29QO2muuZjje4L6NGzfq7LPPVm5urh577DEtXrxY9957ryRp7969Tb5u165dmjJlinr37q2HHnpI\nixYt0jPPPCN3j/u6toj3Prp06dJo23jXpnfv3lq8eLEeffRRZWdn65ZbbtFxxx3X7B8W7YkEGwAA\nJIWSkiARzsoKnmdlBc9LSsI9VnV1tR588EHdcsstWrZs2X63448/vtEBh4l03HHHqaamRq+++mrd\nto0bN+43EHHRokXat2+fbr/9dp188sk6+uijD0j8u3btqurq6v22rVmzRlu3blVhYaE+9alPafjw\n4dq8eXOLZup45ZVX9nu+cOFCDRo0SL1799aIESNUU1OjhQsX1u3fvn27VqxYodzc3Fa9/+begySl\npaUpPz9fhYWFWrZsmXbu3Kk5c+Yc9HnaigQbAAAkhalTP0qIa2VlBdvDPNacOXO0detWfe1rX9PI\nkSP3u1144YV1PcUtFZT5ttzw4cN15pln6rLLLtPLL7+spUuXavr06erZs2ddm2OOOUY1NTWaPXu2\nNmzYoD//+c+688479ztOTk6Odu/erblz52rr1q368MMPNWTIEHXr1k2//OUvtX79ehUVFem6665r\nUVybNm3S9773Pb3++ut67LHH9POf/1zf//73JUlHH320zjnnHF122WV68cUXtWLFCl1yySU65JBD\ndNFFF7XqWtRvk5OTo7KyMi1ZskRbt27V3r17VVRUpF/84hdaunSpNm7cqIcfflg7duzQiBEjWvQ+\n2gMJNgAAQBz33nuvJk2apEMPPfSAfZ/73OdUVlZWNxVfYz2/Dbe1pE1DDzzwgIYOHarTTz9d5557\nrr74xS8qJyenbv+oUaN05513avbs2crNzdW9996r2267bb9jjBs3TpdffrkuuugiDRgwQLNmzVL/\n/v31wAMP6Mknn1Rubq5+8pOfaPbs2XFjqfXFL35R1dXVOvnkk3XZZZfp61//uq688sq6/ffff79O\nOukknXvuuRo7dqz27NmjZ555Rt26dWvx+27Y5oILLtBZZ52l008/XQMGDNAjjzyirKws/e1vf9Pk\nyZM1YsQI3X777brnnns0vi1zMraRtfavqDCYmUchTgAAEJ+ZtboHF8nntNNO06hRo/SLX/wi7FAO\nSrx/h7F9bVrNhh5sAAAAIIFIsAEAANAqUViuPEyUiAAAgA5DiQiSASUi9VRUSEVFYUcBAAAANC0y\nCXbthPEhDggFAAAAmhVqgm1mw81siZktjt1/YGbfbaxt7WpMDee0BAAAAJJJ0tRgm1mapLclnezu\nbzXY5+vXu+pN9wgAACKIGmwkg/auwe7SfJMO82lJ6xom17VmzaIHGwCAqMvOzmYGCoQuOzu7XY+f\nTD3Y90h6zd3vamSfb9vmlIkAAACgXXWaHmwzy5B0jqQfNdXmjjtuUGamdMUV0je+ka/8/PwOiw8A\nAACdU3FxsYqLixN6zKTowTazcyRd4e5TmtjPPNgAAABod51pHuyLJP057CAAAACAtgq9B9vMekoq\nk3SUu1c20YYebAAAALS7RPRgh55gtwQJNgAAADpCZyoRAQAAADoFEmwAAAAggaKTYFc2Wp4NAAAA\nJJXoJNgTJpBkAwAAIOlFJ8EuLZVWrQo7CgAAACCu6CTYI0dKublhRwEAAADEFZ1p+srLpUGDwg4F\nAAAAnVhqTdN31lnUYAMAACDpRSfBpgYbAAAAERCdBJsabAAAAERAdGqwt2+XMjPDDgUAAACdWGrV\nYAMAAAAREJ0Em4VmAAAAEAHRSbAZ5AgAAIAIiE6CfeyxDHIEAABA0otOgg0AAABEQHQS7LVrKREB\nAABA0otOgp2eLg0ZEnYUAAAAQFzRSbCrqqSNG8OOAgAAAIgrOgl2bi6DHAEAAJD0WMkRAAAAiEnE\nSo7RSbAjECcAAACijaXSAQAAgCRDgg0AAAAkUHQS7MrKsCMAAAAAmhWdBPuUU0iyAQAAkPSik2Cv\nXCm9+mrYUQAAAABxRSfBBgAAACIgOgn2scdKJ50UdhQAAABAXNFJsDdsoAYbAAAASS86CfaePdLT\nT4cdBQAAABBXdFZy7N5dWrdOGjQo7HAAAADQSaXWUunl5STXAAAAaFeplWBHIE4AAABEWyIS7OjU\nYAMAAAARQIINAAAAJBAJNgAAAJBAJNgAAABAAkUvwa6slBYuZNEZAAAAJKXoJNibNgVJ9YQJ0sSJ\nwT1JNgAAAJJMdBLsYcOkF16QVq2Sqqqk0tLgMQAAAJBEopNg794tlZVJublSRoY0cmTwGAAAAEgi\n0Vlopnap9MzMoOc6Nzd4DAAAACRIaq3kyFLpAAAAaGeptZLjjh1hRwAAAAA0KzoJ9nHHSa+/HnYU\nAAAAQFzRSbDdpbvvDjsKAAAAIK7QE2wzO8TMHjWz1Wa2ysxObrLxMcd0YGQAAABA63UJOwBJd0p6\n2t0/Z2ZdJPVssiV12AAAAEhyoSbYZtZH0gR3/4okuXuVpO1NviA7u2MCAwAAAA5S2CUiQyX9x8zu\nM7PFZvY7M+vRZOt+/TouMgAAAOAghF0i0kXSiZK+5e6LzOwOST+SdH3Dhjekp0tPPy0tWKD8/Hzl\n5+d3cKgAAADobIqLi1VcXJzQY4a60IyZDZS00N2Pij3/lKQfuvu0Bu3c09OlF1+Uxo4NI1QAAACk\ngMgvNOPumyW9ZWbDY5tOl1TaaOMuXaQhQzoqNAAAAOCghF2DLUnflfSwmS2VNFrS/zbaas8e6fHH\npcrKjox64VivAAAgAElEQVQNAAAAaJVQS0RaysyCKNPTpbw8acECKTMz7LAAAADQyUS+RKTVqqul\n0lJp1aqwIwEAAAAaFfYsIi1nFtRhjxwp5eaGHQ0AAADQqOj0YKenS3fdRXkIAAAAklp0arC7dpXW\nr5cGDQo7HAAAAHRSqVWDvXev9NprYUcBAAAAxBWdBFuSNmwIOwIAAAAgruiUiHTrJr35JiUiAAAA\naDepVSLy5puq6DlIRUVhBwIAAAA0LTIJdkXPQSookMaPDzsSAAAAoGmRKRG54mt7VDirq7Kywo4G\nAAAAnVVKlYjMLDlPWemVYYcBAAAAxBWZBHvW2mmqeHlN2GEAAAAAcUUmwS4c+ScV/N9oVVSEHQkA\nAADQtMjUYHt5uSp6DlJJiTR1atgRAQAAoDNKRA12dBLs0aOlBQukzMywwwEAAEAnlVKDHFVaKq1a\nFXYUAAAAQFzRSbBHjpRyc8OOAgAAAIgrOiUi5eUskw4AAIB2lVolImedJVUyDzYAAACSW3QSbGqw\nAQAAEAHRSbDT06UhQ8KOAgAAAIgrOgl2VZW0cWPYUQAAAABxRSfBzs2tm0WkokIqKgo5HgAAAKAR\nkUmwK/4eLDJTUSEVFEjjx4cdEQAAAHCgyCTYBTd10/Ll0iWXSIWFUlZW2BEBAAAAB4rMPNjLhv2X\nRq97QsuWSccfH3ZEAAAA6IxSah7sL667Uct++7J++9ugBhsAAABIRpFJsB/WF3X8Ee+psDCowSbJ\nBgAAQDKKTIL9W12mss3dVVIS1GCXlIQdEQAAAHCgyNRgb9AQnZ2zSnOKeys7O+yIAAAA0BmlVA32\nrbpac+7dopUrw44EAAAAaFqXsANoqZmapex13ZT9taPCDgUAAABoUmR6sGel/0gV46eGHQYAAAAQ\nV2QS7MKXP62CXx3B7CEAAABIapEZ5OjDh6ti7iKVLM/UVDqyAQAA0A4SMcgxOgm2JD3yiHThhWGH\nAwAAgE4qpWYRkSS98krYEQAAAABxRSvBvuSSsCMAAAAA4opWgr1tW9gRAAAAAHFFK8HetSvsCAAA\nAIC4IpVgV9T0UVFR2FEAAAAATYtMgl0x/CQVzBmn8ePDjgQAAABoWmSm6bsi6yEVLj9HWYMzww4H\nAAAAnVRKTdM3s6JAWUuLww4DAAAAiCsyCfYszVTFkvVhhwEAAADEFZkEu1AFKnhlmioqwo4EAAAA\naFpkEuyskR9T4d39VVISdiQAAABA00If5GhmGyR9IKlG0j53P6mRNu6vvSadeGJHhwcAAIAUkohB\njsmQYL8p6RPu3uQyjWYWRLl2rTR8eIfFBgAAgNTSWWYRMbU0jrvvbt9IAAAAgDZKhgTbJT1nZv8y\ns6/HbTl2bMdEBAAAABykLmEHIGm8u79jZocpSLRXu/uLDRvdkJYmvfKKVFqq/Px85efnd3ykAAAA\n6FSKi4tVXFyc0GOGXoNdn5ldL6nS3W9vsD2I8qmnpGnTQokNAAAAnV/ka7DNrKeZ9Y497iXpDEkr\nm3xBWVkHRQYAAAAcnLBLRAZK+quZeSyWh9392UZbdu0qnX9+R8YGAAAAtFqoCba7r5f08RY1HjZM\nysxs34AAAACANkqGWURa5o03pFWrwo4CAAAAiCs6CfbIkVJubthRAAAAAHEl1SwiTTEzd1ZxBAAA\nQDuL/CwirTJ6tLRpU9hRAAAAAHFFJ8HevVt6+umwowAAAADiik6JSPfu0rp10qBBYYcDAACATioR\nJSLRSbDLy0muAQAA0K5SqwabObABAAAQAdFJsCdMkCorw44CAAAAiCs6CXZpKQvNAAAAIOlFJ8FO\nT5eGDJEkVVRIRUUhxwMAAAA0IjIJdsW+XtLGjaqokAoKpPHjw44IAAAAOFBkEuwC3awNNlQFBVJh\noZSVFXZEAAAAwIEiM03f+rSjNLRmndavl3Jywo4IAAAAnVFKTdM3y2Zq/cubNWtWUIMNAAAAJKPI\nJNiFdq1yfL0KC4MabJJsAAAAJKPIlIj4yJHSyy9LmZmqqJBKSqSpU8OODAAAAJ1Jai2V3rWrtH49\ny6UDAACg3aRUDbb27pUefzzsKAAAAIC4opNgS0wfAgAAgKQXrQT72GPDjgAAAACIK1oJ9vz5YUcA\nAAAAxBWdQY7du0vr1jHIEQAAAO0mtWYRKS8nuQYAAEC7Sq0EOwJxAgAAINpSa5q+TZvCjgAAAABo\nVnQS7GHDSLIBAACQ9KKTYO/eLT39dNhRAAAAAHFFJ8GWpBNPDDsCAAAAIK5oJdgvvRR2BAAAAEBc\n0UqwBwwIOwIAAAAgrmgl2P36hR0BAAAAEFd0Euxu3aQRI8KOAgAAAIgrOgl2dbW0cWPYUQAAAABx\nRSfBzs0NbgAAAEASi06CvWCBKqozVVQUdiAAAABA0yKTYFdUZ6qgQBo/PuxIQlBZKS1cGNwDAAAg\nqUUmwS6YuVeFhVJWVtiRdLDKSmnCBGnixOCeJBsAACCpRSbBnjl/mrIWzU29BHPlSmnVKqmqSiot\nDR4DAAAgaUUmwZ71+jkqO/MbKhp9TWol2Xl5weDOjAxp5EgGegIAACQ5c/ewY2iWmfkGDdHZmqM5\n6ecp+8WHpbFjww6r41RWBj3XublSZmbY0QAAOrvKyuAb1Lw8fu8g5ZiZ3N3acozI9GDfmvZjzUk/\nTyuHnJV6vbiZmcEfFHzIAQDaG2N/gDaLTA/2+vRhyrn7R9KFF5JoAgDQXhYuDJLrqqqgPHH+/NT6\n1hgpL6V6sGdlFariTJJrAADaFWN/gDaLTA/2to3bVXBLZmpO1QcAQEdi7A9SWCJ6sCOTYPv27aqo\nzlRJiTR1atgRAQAAoDPqNAm2maVJWiTpbXc/p5H97nl50ksv8Zc0AAAA2k1nqsH+b0mlcVusXCm9\n+mrHRAMAAAAcpNATbDM7UtJZkv4QdiwAAABAW4WeYEuaLWmmpPi1KmbS4MEdEhAAAABwsEJNsM1s\nqqTN7r5UksVujXMP5uIEAAAAkliX5hqY2f9z99Ob23aQxks6x8zOktRDUqaZPejuX27Y8Ib0dGn1\naumGG5Sfn6/8/PwEnB4AAACprLi4WMXFxQk9ZpOziJhZd0k9Jb0gKV8f9S73kfSMux+X0EDMTpX0\ngyZnEVm7Vho+PJGnBAAAAPbT3rOIXCbpNUnHSVoce/yapCcl/aotJz0on/98MPE9AAAAkMSanQfb\nzL7j7r/soHiaisE9IyOowR47NsxQAAAA0Ikloge72RpsSR+Y2QE10e7+YFtO3GojRwZLtgIAAABJ\nrCU92PV7r7tLOl3SYnf/bHsG1iAG9+3bWcURAAAA7SqUpdLNLEvSI+4+pS0nbuU53cvLpbIyKS+P\nRBsAAADtIqyl0ndKGtqWkx6Uo45SxYRpKhp9DYMdAQAAkLSaTbDN7O9m9lTsViRpraS/tn9o+6vY\n010F1Tdq/FuPSKtWdfTpAQAAgBZpSQ32qfWeVkkqc/e32zWqA2PwK/QrFaZdp6xRg6UFCygTAQAA\nQMJ1WA22mR0u6SRJLulf7v5uW07aWmbm6zOOUc7jt0n5+STXAAAAaBcdUoNtZl+T9Kqk8yV9VtLL\nZjajLSc9GLPOK1HFhGkk1wAAAEhqLSkRWSvpFHffGnveT9JL7n5sB8RXG4Nv6zpABRe9qcI7eikr\nq6PODAAAgFTSUbOIbJVUf9qOyti2DpW1d4sKRzykkpKOPjMAAADQci1ZyfENSa+Y2ZMKarDPlbTc\nzL4vSe5+ezvGt5+snCxNndpRZwMAAABaryUJ9rrYrdaTsfuOL4bu37/DTwkAAAC0RqtXcgyDmbmb\nSWvWSMOHhx0OAAAAOqlE1GA324NtZsMlXSUpp357d5/UlhO3mrs0fz4JNgAAAJJaS2YRWSbpbkmv\nSaqu3e7ur7VvaPvF4N69u7RunTRoUEedFgAAACmmQ3qwJVW5+2/acpKEWLaM5BoAAABJr8kebDPr\nG3v4XUlbJP1V0p7a/e7+frtH91Es7nl50ksvsdAMAAAA2k27LpVuZusVTMvX2Anc3Y9qy4lbw8yC\nKOfOlU4/vaNOCwAAgBTTriUi7j60LQcGAAAAUlFLZhE5v5HNH0ha4e5bEh9SE7p1k0aM6LDTAQAA\nAAejJYMcvyppnKQXYs/zFcwoMtTMbnL3P7ZTbPvbs0davZqBjgAAAEhqLUmwu0ga4e6bJcnMBkp6\nUNLJkuZL6pgEGwAAAIiAtBa0GVybXMdsiW17X9K+9gmrESNGqGL4SSoq6rAzAgAAAK3WkgS72Mzm\nmNmlZnappCdj23pJqmjf8D5SUZ2pgpu6afz4jjojAAAA0HotWcnRJF0gqTa1LZH0uDf3wgQyM79C\nv1Lh3/KUde6pHXVaAAAApJh2nQc7mZiZr1e2cp76pTRtWtjhAAAAoJNKRILdbImImVWa2fbYbbeZ\nVZvZ9rac9GDM0kxV1PTp6NMCAAAArdJsgu3ume7ex937SOqhoFzkrnaPrIFCFajg/0arosOqvgEA\nAIDWa8kgxzoe+JukM9spniZl6QMVnvyUSko6+swAAABAy7V2Jcc0SZ+UtLvdImpK9+7S5MnSmx1+\nZgAAAKDFWrLQTP1RhVWSNkg6t12iiaPimZdV8KsjVFjY0WcGAAAAWi4ys4hckf4bFa44V1kjjgg7\nHAAAAHRSHTWLyJFm9lcz2xK7PW5mR7blpAdjZvUtyiphGUcAAAAkt5YMcrxP0lOSBsVuf49t61Cz\n0n6kivFTO/q0AAAAQKu0JME+zN3vc/eq2O1+SYe1c1wHKBz6BxXc3o9p+gAAAJDUWpJgbzWzS8ws\nPXa7RNLW9g6soax1r6nw7IVM0wcAAICk1pIEe4akz0t6V9I7kj4raXp7BtWUrN3vaipVIgAAAEhi\ncafpM7N0See7+zkdFE98W7aEHQEAAAAQV7PT9JnZq+5+UgfF01QM7t26SW++KQ0aFGYoAAAA6MQS\nMU1fSxLs2ZIyJP1F0s7a7e6+uC0nbg0zcy8vJ7kGAABAu+qoBPuFRja7u09qy4lbw8zct2+XMjM7\n6pQAAABIQR2SYCcDM3MfPVpasIAkGwAAAO2mo3qwu0m6QFKO6g2KdPeb2nLi1jAz94wMVRSVqGTv\nGGYSAQAAQLvokKXSJT0p6VxJVQpqsGtvHari2JNV8H+jNX58R58ZAAAAaLmW9GCvdPe8DoqnqRj8\niq/tUeGsrsrKCjMSAAAaUVkprVwp5eVRyghEXEf1YL9kZqPacpJEmFlAcg0ASEKVldKECdLEicF9\nZWXYEQEIWZMJtpmtNLPlkj4labGZrTWz5Wa2Ira9Q826+j1VVHT0WQEAaMbKldKqVVJVlVRaGjwG\nkNKaLBExs22SPt7UC929rM0nDwZQzpfUNXZ70t2vaaSdb9Mhuuq8NzT5C/114YVtPTMAAAlS24Nd\nWiqNHMmMV0DEJaJEJN5S6esTkUTH4+57zOw0d98VW5a9xMzGu3tJoy9YsVL6Qn57hgQAQOtkZgZJ\n9apVUm4uyTWAuAn2ADP7flM73f32RATg7rtiD7spKFnZ1li7AhXq5/ccqqxTE3FWAAASKDNTGjs2\n7CgAJIl4gxzTJfWWlNnELSHMLM3Mlkh6V1Kxu5c21m5mzmPKOvGoRJ0WAAAAaBfxarAXu/uJHRaI\nWR9Jz0r6obvPa7DPr7C7VPjPTypr8piOCgkAAAAppr1rsNt04NZy9+1mViTpk5LmNdyfmTZTk2d+\nV6dPKdKUKfnKz8/vyPAAAADQCRUXF6u4uDihx4zXg93X3d9P6NkOPEd/Sfvc/QMz6yHpn5JudPf/\n16AdS6UDAACg3bVrD3Z7J9cxR0h6wMxMQT34Hxsm13XS0qQjj5Te7ICoAAAAgIPU7FLpyaB2HuyC\nc1aq8IEjWdERAAAA7aKjlkpPCgUqVOGMdSTXAAAASGqR6cFeP+x05Sz5KxP4AwAAoN2kVA/2rG1f\nU1mZVFQUdiQAAABA0yLTg70h/Sidnb1cc57vpezssCMCAABAZ5RSPdi3Zv2vHv5jje67L+xIAAAA\ngKZFJsG+7JHT9It7MzViRNiRAAAAAE2LTIL9hbMrVbltb9hhAAAAAHFFJsE+ds8yLX6lWgsXShUV\nDHYEAABAcopMgr24y0mqSu+qPXukggJp/PiwIwIAAAAOFJlZRDK0R/0Hpqtbj3QtWSIWnAEAAEDC\npdQsIlnaqnc2p+uTnyS5BgAAQPKKTIL9ngZqYJ9dev31oAYbAAAASEaRSbAP02bt3G068cSgBpsk\nGwAAAMkoMgl2hfrqkKx0vf++VFgolZSEHREAAABwoMgk2IfrXW3Zmq5du4Ia7KlTw44IAAAAOFBk\nEmxTlbp1rZHEHNgAAABIXpFJsCvUT+NO3KWtW5kDGwAAAMkrMgn2x7VUry7urhkzmKYPAAAAySsy\nCfZ85evEkXv01lthRwIAAAA0LTIJ9n36sl5a2kP9+4cdCQAAANC0yCTYt2mm/vjp+/T73zMHNgAA\nAJJXZBLs3+hyXb30YmVmMgc2AAAAkpe5e9gxNMvMPEf/VrnlaOKkLpo7N+yIAAAA0BmZmdzd2nKM\nyPRgl2uwumVU67/+K+xIAAAAgKZFJsFO1z5NznuHQY4AAABIapFJsPeoh957Z48efTTsSAAAAICm\nRSbBHqB39OI7w/X222FHAgAAADQtMoMcM7Rb+2Tq2SNdO3elhx0SAAAAOqGUGuTYR9skpctrasIO\nBQAAAGhSZHqwpRpJLjNXTQ092AAAAEi8RPRgd0lUMB3DZBaZTncAAACkoMhlq1SIAAAAIJlFLsEG\nAAAAkhkJNgBEXWWltHBhcA8ACF0kE+yKCqmoKOwoACAJVFZKEyZIEycG9yTZABC6SCbYBQXS+PFh\nRwEASWDlSmnVKqmqSiotDR4DAEIVyQR74sTgnl5sACkvL0/KzZUyMqSRI4PHAIBQRWwe7GBKwg0b\npFtvla6+Oui8mTo11PAAIFyVlUHPdW6ulJkZdjQAEGmJmAc7Ygm2JJnOOEP63e+CJLuwUMrKCjU8\nAAAAdBIptVR6be+1JL3/vvQ//xMk11JQKsLARwAAACSDCCXYH/W0L1okrV8vffBBMOAxL4+BjwAA\nAEgOESoRcQU301lnSUuWBKWGjz4q/fa3lIoAAACg7RJRItIlUcG0v2oFHe7V2rUrXe+8I+XkSKNH\nB73ZJNcAAABIBhEqEbG6+yOPlJYtC+quf/Yz6VvfCh4DAAAAYYtQgi1Jpi5dpLFjg7KQRx6R/vhH\n6ac/DWqwSbIBAAAQtggl2KY0c40alaannpIuuyxIsufMkd56K6jBLikJO0YAHaqyUlq4MGWXB6+d\nQak+ZlQCgPBFKMF21bi0c6c0YEBQez1zppSdHSw0k5XFgjNASqmslCZMCJZ2nTAhJZPs8eP3//au\nooIZlQAgGYSaYJvZkWb2vJmtMrMVZvbdptp20y5Jrk2bpG7dpHvukWbNoiwESFkrVwarF1ZVSaWl\nweMUk5UVfHtXUBCscFtQwIxKAJAMQp2mz8wOl3S4uy81s96SXpN0rruvadDOu2iPqpSujIx0bdkS\n/AKp7a3hFwqQgmp7sEtLpZEjpQULUnaZ8A0bpKFDgxmVcnLCjgYAoi3yKzm6+7vuvjT2eIek1ZI+\n1ljbLtorSRoz5qNkurb3htprIAVlZgZJ9fz5KZ1cV1QE3+atX8+3egCQLJJmoRkzy5FULCkvlmzX\n3+dSlTK77NK+Lpn68MNge0VFkFxTew0gFTX8Fo9v9QCg7TrNQjOx8pDHJP13w+S6ro2uV2VVurqa\n66c/naRvfjO/7hcJAKSikpL9k+n63+rR8QAALVNcXKzi4uKEHjP0Hmwz6yJpjqR/uPudTbRxqSb2\nrEbLlqWzPDoAAAASLvI12DH3SiptKrluzOjR0ic+QXINAACA5BP2LCLjJc2XtEKSx27XuPszDdr5\nR7trNHZsunbvll54qlJZb6+U8vJSdoATAAAAEifyPdjuXuLu6e7+cXc/wd1PbJhc12sdu6/RW2XV\neuDXlSo44WlVTJiWsotMAAAANIXVXsOTDCUirWCSumjyif/R8bZShRXfUkn1ySm7yAQAAEBTWO01\nPBFKsGt76l2fyM+U8vKUlXekpmY8FywykZsbanQAAADJhNVewxP6LCItsX8NtnTeeabsbGny+F2a\nOnh5kFxTgw0AAHAAVnttncjXYB8cU1GR9PLL0vjJPaWxY0muO1plpbRwIXXvAAAkOVZ7DUeEEuyP\netpHj5ZOPZWvOEJRWRkMKp04kcGlAAAksfqru+bkfFQuQpLd/iKUYFeptg573z7pxz/efy+jYjvI\nypXBgNKqKgaXAgCQxOKt9or2FaEEu4vSVS1J2rVLuuoqRsWGIi8vqHnPyGBwKQAASWzq1AO/7c/K\nCrYnClMBNi4yCXaa9qlaaeraVerSJahMuOoqRsV2uMxMacECaf784J76dwAAUhZTATYucrOI9OlT\no9mz07V2rXTssdJXv8qoWAAAgLDUJtUzZwYDKaPe6ZmIWUQilGBXK6jBrtG2bemSOtcPEwBSQmVl\nMJYjL49vwIBOpDNNBZhi0/RZ3f3GjYyKBYDISbJZiKgdBRKDqQAPFLkEu0cP1y23MCoWACInyWYh\nonYUaDumAmxchEpEaiRJvXqZduwIOSAAQOvV9mCXlgazECXBQOnOVjvaUYqKgj9E6l+rioqgoyuR\nM1Qg+XXGfwspVoNdU/tM27bxAQgAkVRZGfRc5+aGnlzX6ky1ox2lfq9lVtaBz4EoS7Ea7ECPHpSC\nAEBkZWZKY8cmTXLd1trRVK3jri3NLChgulygMZHrwe7Tx/TBByEHBACIvET0wqZ6Ty69/+iMUqoH\nO01VkkT9NQAgIRKxjHQq9+QycwTQtMj0YHdXpXarp3r0SNOuXWFHBADAR1KtJzfVe+7RuaVUD/Zu\ndZdJGjMm7EgAAMkorHroVOzJTUTvP9CZRSbBHqgt6pmxTzt3hh0JACBsjSXTeXnSJZd07LzWqToH\n8NSpB/ZUZ2VFd1o2INEik2BvVT+N/8SHOv30sCMBAIStsUVibr1V+vWvO7Yemp5cAI2JTA12b1XI\nunbT/97WXd++tDJYESwvL2mmegIAdKymFolJtXpoAImVUjXYE1WsGkvT7NuqgpXAJk4M7isrww4N\nABCCrKwguR46NLivHWyXavXQAJJPZBLs1zVS7ibbuzdYBayqKlhud9WqsEMDAISgYTJdVpaa9dAA\nkk9kEuwPlaF9nq5vXK5gid2MDGnkyOAxACClNDa48IorpKuvph66LVJ1ZUog0SKTYG/REfrd1L9p\n6eqe0oIF0vz5wT012HX4YASQKhobXPjww8HwnPqY2aJ1Ghs82t4zsQCdUWQGOQ7Q29qTcahuvr2n\nhg4N/rPXHxleURF84KbyBykT/wMA2qqpwaNAqkipQY7/0UBVKV0Sf2E3JZWX7AUAJEZjg0cBtE5k\nEuxT9YLSupiefppEMh4+GAEAbcFMLEDbRSbB3qhsjR6yVStWBM9TIZE8mJpqPhgBAAcrVVemBBIt\nMgn2XnXRS2sH6Hd3BPNep0Ii2dpSmFT4YGQgJwC0n/ZYmZLPbaSiyAxy7KNt+pTmK++w/+jHr31O\nBbdkpsRgvtYMNikq6ryDP2vfm/TRz1qS/vnPYEKZzvizB4DOgAH4iJpEDHKMTIJ9hv6hK3W7CnWt\nPj0jR1feNrhTJpKNYdnf/T+QJemqq6Q9e6Ru3aSf/5wPaQBIZsxMgihJqQQ7UxXare76RM9S/WPN\n0coanBrzX/Oh9JH61+Laa6WHHkrtPzoAIEroLEJUpNQ0fTUy7VOGjjpjuLLeXilVVoYdUrtLhZrq\n1qg/sFXq3PX3ANCZpMK4KaC+yPRgS67T+i7Rrg/Tde2e/9HUURs7/UqOnbmm+mBUVBxYGiJRywcA\nyYwabERNSpWIdNFufaz3Dk3Y8bR+qe8oK2NXMLpt7Niww0MHqP1AnjhROvPMYFv9muxU/aMDAJId\nnUWImpRKsD+mjdpiR+jszBd0766LlZX7sU7fg42P8AENAAA6Qkol2JJrwjHl2uwDdfvlb2jqNz5G\ncg2g0+CPSABIDik1yHGqntLLbwzQKZ/qoqk/OI7kGkCn0tqFpQAAySsyPdjDVaoPew2Q9eunZcsY\nGAGg82FaTgAIX0qViJyhp7XhiFP0nWsO0dChfGUKoHNirmAACFdKlYgU6zTd85NN+va3g69Mi4oU\nzIW9cGFKzIkNoPNjrmAA6Bwi04N9mp5V+SHH6zs3D9Tq1VLhjyqVNW2CtGqVlJvLjCIAIo25ggEg\nOaRUicghel+9eroyDuurpUulrNULg0mRq6qkjAzmxAYQacwigk6vslJauVLKy6NDDEktpUpExmu+\nNu3qq1NOif0CyssLeq4zMqSRI4PHABBRU6ce2FOdlUVyjU6islKaMCHoGJswgdJOdHqRSbBf10id\nlbNSa1ZVBXWJmZlBWcj8+ZSHAJ1UUdGBdcgVFbExGEBTGJ+TfFauDEo6q6qk0tLgMdCJhZ5gm9k9\nZrbZzJbHa+dy/XjDZZpY/oguuXDfR0n22LEk14iLJC26mBsarUZPaXLiW2ekmNATbEn3STqzuUbH\naY3O1t/1ztYM/fryFSop6YDI0CmQpEVXVlYwyK+gIJi+rj0G/fEHWCdDT2ly4ltnpJikGORoZtmS\n/u7uxzex3/tom7K0Tef1K9Gd68/lPydahQU8oq0954Zm9o5OprYHu7Q06CklmQPQSik1yHG7spTW\ns/v/b+/u46uq7nyPf34mAYtCIqD4xJNVeZZWy4NCLaNFkdqRWhG9Qx+otShqb9sL2Bnq2NtqZ0rp\njCNFhRlqO4NW1KvcTqAO3o7xIaJVimhQrAoCUtGCiQmgkIR1/1jnkJMQwnnYOfvss7/v1+u8cnKy\n9zn7rKzs/M7av/VbcOUVOllKxioqfHA9cKD/qsApOtqrDR3kqHM+RskljzRSKiIFoDTsA0hXV77P\nB14m+QcAABxbSURBVI3NPLf2GKqqJjBhwoSwD0kipG2QpgAqGtqOJicD4blzWx6vrvbpnfPn+++T\n+2VS3i71A9jmzeobkZecnyMikoaqqiqqqqoCfc7IpIhMZgXVXT7PxVOOYfFi/QOU9CkFILo6qg2d\nzK2fORP+5m+gshL698/u91tQKURp1ApWzWwRkc5TTCkilrgd1psM4o7pL/Lyy2iCo2Skurp1wJQc\nCVU/Knwd1YZOjjqPHAn33edHsLNJ8UgNyAcMaBklD2WZ8jQrYGjirohIYQt9BNvM7gcmAL2A94Bb\nnXP3ttnGXUQlT5ZN4v/9dwnjx4dwoCJSUNqOOs+c6YPtTCdCFtRo8Jr0V6gtqFF3EZEiEqul0rvy\nEeeP2cenP1fOT38a9hHFU0EFIhJrbdNAtmyBSy/1I9mLF0c42MywAkZnVlcREYmrYkoROaJ/4rts\n2fgx+/aFfSTxpcvSUihS037q6nx6SGUlbNsWcopHrjKogNFedRURESkMkRrB/vzAt/jKPwxj2rTE\nD9KYDCTBCuOytEbOpSNx7B+auCsi0nliNYI9kdU8884A/vL8Wz6w1nK4oQijnrRGzqUjHU2ELFbZ\nTtzVqpUiIvkRmQD7GPYyvqmKB/75zz6gfv55LYcbgjAuS2shEJHWsv1QoQ+rIiL5EZkAex0j2ejO\n4Bss9QG1GQwb5mfaDx3q70unCrOcmVZiFMldUX5YbWjw1Vd0FVNECkhkAuyhbKCktAQ7qsQH1KNH\nazncPAuznrQmdIkEo6g+rCpVUEQKVGQC7FcZztJJD7Hl6z9sCaiTy+EquM6LsHJdC2ohEJGIK6oP\nqzU1ShUUkYIUmQB7KDV89elvsm5nXwXUMaOVGEWCUXQfVocPV6qgiBSkyATY6/k02z6soGfPsI9E\n8i2OVSJEgtC2akh1Ncyd2/LhNNsPqwVTjSSDuuEiIvkUmQB7J73p23svn/1s2EciIhINbauGjBvn\nF+VJrRqSzYfVgqpGolRBESlAkQmwy6ljxdT76NMn7CMREYmGzqoaks3zFsyod3tUiUREAhaZlRx7\nUMslZ73LPU8OifasdxGRPHv7bV81ZPNmn3sdxvMW7OqTyUokGzb4HG6lmojEXqxWcpzEKh7bdAbL\nloV9JFIQNOIkkpbOqhqS6fMWbA1uVSIRkU4QmRHsWsqZOeJZms8cysMPh31EEiqNOImkpbNGjXN5\n3s4aTc9a8nzy6qu+EonOJyKxF6sR7Ao+ZPGYe5kxbW/YhyJh04iTSFo6q8Tl4Z73jjs6zrMuyBrc\nHVQiKei8cREpaJEZwXYApaUasRSNOIkUioYG/4F3+HDo3r3DkW0o0BzsDhRs3riIdKogRrCjFWCD\nX1Dgqad8WSaJr4aGlhQRBdci+XeYVK1kEHrOOfDss7BggQ9GV670cXhNTUtZwLo6PxpeyDXtk+9n\nzhw/6q7gWqT4xTPA7toVNm2Ck08O85BEROJtzRo4/3yfqtVm4COZZz19OixcGP3R34LLGxeRThWr\nHGyAOspZue9CeO21sA9FRCTeDrNMeWqeddeuMHt2gVUNyVBB5o2LSMGLTIBdRznzuJ1x5Dg7R0RE\nctfO5MDUUeoBA3x6yL59fvR3zpxoBtep7ydZZlBBtogcSWRSRGbxC25nHhXD+/rEPuXdiogUlJUr\n/XLpyUC6rs6PYJ93HqxdG70R7LbvB6KRNy4iuYlVDvZm+lMx7FSqb13NuInddIITESlgqsAhIlEV\nqwB7Or+i62dGcsvDn2L+fJ2kRUQKmUZ/RSSqYhVgD6GGQcO7sOekM3jwQQXXsdSm5q6IFBYF1SJS\nDGJVReTnJTezouYMNm1ScB1LyZq755/vvzY0hH1EItLGuHGtJwEm00LGjQv3uERE8i0yAfa05vso\nKTnACSdoBncU5bzksJZHFyl4ySXT582Ldmk+EZFcRSbA3svR9Ou2i3vu8bPSly8P+4gkEzmPbB2m\n5q6IFJaKCl+S72BpvpIGvyiNrjqJSIxEJsDuzS5WfHGp1piJqJxHttqpuSsihafVwiy376fuvMlK\n7RKR2InMJEdo5IITN1J61nCWL9clx6jSksPFp2gmtmkSbc4OKc23+g/Mm7SW293fUlG2t9Vy6iIi\nhSpWkxwv4An+e8dwhg5VcB1VWnK4OBXFxDZNog1EdXXrK1MV5w7h9mH3U13yOaV2iUisRGYEewg1\nlJ10PDuaT+D111uvFNbRSFnRjK5FnBadKG7J3+ecOf7DU+R+r2vW+OC6qcnn+WukNTgNDX5S8rBh\nujIgIpEQqzrY6xlB/TEn8rXev6P/aSVMnw6XX94SpEH7QbMCu8KgDzrFr1PTfzo7fSM5gv3qq36k\nVXn+IiKxFasA+0ru4xVGsuSeA1zzTyPo0wfOPBMWLPDbdBQ0R350TSRVAeYKd+rfWDL4TY6Cdlbw\nq5FWEREhZgH2cexiUMlbnD51JHP+tgsjR8L06f4f+t/9HSxb1vE/dE2uk6KQr2AzA51+lUjpGyIi\nkkexmuS4mG/xXPMo1r3ShQULYOlS2L8fRo6En/yk43/kmlwnRaMAF9w5ZGJboiRjdXVAL6Aa6LGR\n84JUIiIFIjIB9rX8KxP7rGfnTvj97+Evf4GXXoIrr4Q77/Qn4fZOxKmjaRs2wNy5h1Y8SOfkrRO/\nFIQCDDa/8IVDP+BWVASYW68a6LFRFBVpRESIUIrIAN5gO33p0bOUMWNLWLXKB9fz5sH998POnX7b\nBQta/7NPnVyXPFnPnesHApMn83QuZWuypBQM5QpLocthnoDmzIhI2GKVIjKQzTTSlVK3n48+goUL\noWtXmDoVTj0Vtm07tErF8uWwe3frS9dz58INN/jYJJMAOeeVCMVr0LLJ2Tp4FaV7d5+D3L27rqJI\n4cmxpvghS63rHCsiERSZAPsJJjKeJ2j4qIzycrj0UnAODhyAm26CL34RXnyxJW1jyxZ4/HF/S6aP\nLF8O8+f7nO1sTt468edIi3nkRJfPJRJynCegOTMiUgwiE2Cfwtts4nQW/cOHrF7tg9zGRjj7bJgw\nwedjJ/Or+/b1Mdy3v+1TRmbP9kF4ZSWccw4sXpzdyVsn/hyFPUEv4qPnuooikZDDPIHU1LsBA1r6\nu861IhI1kcnBnsJDvEk/ajiHXr1K2LXLB9njx/vJVGPH+tHpmTN9ZZEf/tBXGqms9MHwsmUwZQrs\n2QMPPph5HrVysAMQ5mIeBVjeLlsqOSkFL8t5AlqQSiTCCnCNhmzFKgf7Kc6jhlGAY8igRmbM8AHG\n2rVwyikwa5ZPG7nmGli1yudoDxnig+3du/2EyBdfbD0JMpNyYp1eiiwOwqwGEfboeUB0FUUC0dlX\nc1LmCWSi0yvSSPAifmVQAqIU0ENEJsD+gJMBowcfMu3tn7F9SyPjxvkR6auugq9/HS67DKZN88H0\n3XfD88/74HvFCjCDZ57x6SGpQUm6J2+d+AOS5T/enBVgebtM6fK5BEL/CCUo6kuSVCSDWEGKTIAN\ncBSNlNDMwj9/mQsHb2f4cF9J5KST4Ctf8aPXc+bArbfCj34E110He/f6fdet819jMeqsEYVDFUEt\nZV1FkaylnhOK7B+h1igIUZH1JclBEQxiBS1CAbajK3tppowuXZr5l0f7smcPXH21T/3o3x/uuQe+\n8x0fZI8aBXfcAYMH+8vpY8bAtdfChx8e+sxFdYIu9hGFXD48hDV6HpCCv4oS9ge7sF+/ULU9J/Tv\nX1T/CFVdJ0QKqiSpCAaxghahANv4iHLq6cGrTUOYeV0JY8bAz38OXbrAn/7kJ34tWuSD63vvhW7d\n4MQTfarInXf6+zNm+JxsaAmsU0/QyXJ+kT1BF/OIQrF/eIiysH83Yb9+IWt7Tti6taj+Eaq6TogU\nVEVHPgYgIj6IFbTIVBGBZsAAo98pjdTWl+Gcz8F2Dk4/HTZtgpISX75v8GCorYVPfMIH3r/8Jdxy\nC7z3XvtVRMCX89u3z6edtF0RMjLCrNTR2das8QFUU5MfMXnqKf/HLOEL+3cT9uuHJZ1Z+8V8Tkhx\nSHWdIqpoIJKTIqqilS9FUUXEzCaZ2UYz+5OZ3Xz4LY8CjAp2sHV7KQ0NfiS6Sxe46CIfDB844INr\n8P3pvPNg/34oL/cnXmgJrqH1yEddnQ+uly2DH/wgosE1FPeIgi5HFq6wfzdhv34Y0h21D+OckOto\nWYb7p1bXufFG2FLTum3qtjVEM+VPJAjFfGW7gIUaYJvZUcAvgIuBYcDVZja4/a0PAHup40SMJgBK\n2M/+fc18tHs/Gzb4keejj4aysgNs3w5PPdnMt77l00cANm70OdvLl/tb8oR7zjktAXhRlD8r1ss0\nxfzhIerC/t2E/fphyOSfZj7PCbmm62S4f9vqOosWwaWXHcWWV+qhqYm6DduZ95090Uz5EwlCHAcg\nCkCoKSJmNha41Tl3SeL77wPOOffTNts5oxFH6cHHurGLvfSiBx9QT0/KrY7uJXvY7brTvbmObfTD\naKaitIEKq6e8bDcbPjqdriXNTBy6nZ4fv8stk9fy43dmsK92D9t3Hs0p/UtYeO5voF8/5j3xeeb+\noAs1NW0mkR3usmOmj8dBnN+7SGcr1NSPXNN1Mtz/4OI0JS3nmy1bYNZ561j00TX8rPw2bl83mYq+\nObSNzmXhULsHJ8vFn+IqiBQRnHOh3YAvA0tSvp8O3NnOdg4OpNyaHDS7b3CXA+d682fnM7GdG8Vz\n7iS2uh8yzw1ko4Mm15vtroT9rhc7XD82uZPZ6hZyvZvOr9w1LHEPMNW9TT83nV+7i3jM1VLu3v7k\nBW7yRftdba1rUV/v3MiRzpWW+q/19dk9Hgdxfu8i+VJf79yaNYX195X82y8ry+5vP5v92znfbH6l\nwYFzm19pyO59dPDc0rkqK52r3dq63Wu31rvKyrCPTOLCh8e5xbilh428C87/Trk/gQqG8kuu53r+\nmcXcCEBvdvAexzOArSznaq7jX/k53+V9TgFgF33YBfyU2dzEXUzg9/yKb9CfrdRRTlf2cQI7eIQv\nsfatUdx390tUVIxqedn2LsmOHZv543EQ5/cuki/J1I9CkkzXyXa0LJv925xv6p7byM9WjEqk/B2b\nW1URncvybtw4mHfNHm6veYeK5pY0n9uXauRVOkdVVRVVVVXBPmmuEXouN2As8FjK998Hbm5nu8TI\ntXNwwJ3IZgdN7mQ2O6PR9eJddy7PuLE87U7iHXcl97kv8H8dOFfKPlfO+66Mj10/Nrkv8bAbQo1b\nzwh3DUvcNSxxm+nvZvELV0uF20x/P+rxyQsPHak43MhKpo/HQZzfu4jkV8r5pnb4eDfrm/sOXn2s\nrXVu1izX+mpkls+tc1n+1G6td7N6PeA2l57uZvV6wI9oi+QJAYxgh52DXQK8DlwIvAv8AbjaOfda\nm+0cJI+zESihjH000pWTu9XR3Ogop5bSoxyDuu+gvHkXlbs/x87G4wA4rWwLQ7pt5ek9Z3N0WROj\nPvkBe3d9zPQxb/DEgQks+20PFt64kelfK2Xed/cy52vvc9tT5zPxC12YNq3NQbfJY2qV/5d4vK65\nO9XVidztOOc9xfm9i0h+Jc43K7edxbiJ3VqNWNfV0XJOzuG5dS7Lr7drdjNwxLFsfmU3A4YfG/bh\nSIwEkYMdeh1sM5sE/Au+oslS59w/trNNSoDd4rjj4OOPfc3rdeugTx9ftq++Ho46Csz81927YcQI\nXxMb4M03fdWQq67y1URqa315v9GjYeFCv83s2f7rkephp85gT62tff75cPHFBHuSj4iDHzpi+N5F\nRCR3yf+lc+b4yl5aPEjyqSjqYDvnHnPODXLOndFecN2Rbt3g+OPhrbd84NatG2zb5lPlmppg4kS/\njPoll/g0ui1bfMm+0aPh1FP9Uurvvw/33w+TJsHatX6Rs3nzfGC9YIEPCjtyuFXELr44vsv3auli\nERHJVtvSi6nrVYhERegj2Ok43Ag2QP/+/qrdqlUwebIPkt97z/9s+nT48Y/httvgzDPh5sQyNgMH\nQs+eftunn4bf/Mb/AW/dCiNHpqwEloFDVhEj3p/A4/zeRUQke7oKKmErihSRdJiZKylxNDe3frys\nzKd2nHuuTw9ZscIH2fX1fmR62DB49FFYvx7uvNOv1Lh7t98O/KqOP/oRVFb61R6zDQg7CibbC7zj\nIs7vXURERKKpKFJE0tXcDCUl/n5ZGRx7rK8p0qOHD+DMYMoUv0bBokXw0EPwwgv+salTfXB9221+\ntccePXyKyJVXwt13+1Hu2bOzuxzV0aWs1OV7I786ZIbi/N5FREQk3iIzgj1qlOOKK2DJEp/KceKJ\nPu1j/344cAD27IGbboLPfMaPJPftC7fcAnfd5SdCfvCBD8J37IC//3t/a2qCnTvhhhugd29aVQxJ\n93LU4S5l/dd/+QXI2k5+jEOqxOEmfsbhvYuIiEi0xSpFpLbWUV3tg9lly2D1apg506d8gJ9UmAyI\nly/3j6UGzMuX+0oj118P8+f7YA/gkUf8bdmyYIO/OOeQxfm9i4iISLTFKsAO6jgV/ImIiIjI4SjA\nFhEREREJUKwmOYqIiIiIRIECbBERERGRACnAFhEREREJkAJsEREREZEAKcAWEREREQmQAmwRERER\nkQApwBYRERERCZACbBERERGRACnAFhEREREJkAJsEREREZEAKcAWEREREQmQAmwRERERkQApwBYR\nERERCZACbBERERGRACnAFhEREREJkAJsEREREZEAKcAWEREREQmQAmwRERERkQApwBYRERERCZAC\nbBERERGRACnAFhEREREJkAJsEREREZEAKcAWEREREQmQAmwRERERkQApwBYRERERCZACbBERERGR\nACnAFhEREREJkAJsEREREZEAKcAWEREREQmQAmwRERERkQApwBYRERERCZACbBERERGRACnAFhER\nEREJkAJsEREREZEAKcAWEREREQmQAmwRERERkQApwBYRERERCZACbBERERGRACnAFhEREREJUGgB\ntpldYWY1ZtZsZmeHdRwiIiIiIkEKcwT7FeBLwJMhHkNRqaqqCvsQIkNtlR61U/rUVulRO6VH7ZQ+\ntVV61E75FVqA7Zx73Tn3BmBhHUOx0R9P+tRW6VE7pU9tlR61U3rUTulTW6VH7ZRfysEWEREREQlQ\naWc+uZk9DvRJfQhwwDzn3H925muLiIiIiITBnHPhHoDZE8D/cs79sYNtwj1IEREREYkN51xOKcyd\nOoKdgQ7fRK5vUkREREQkX8Is0zfFzLYBY4FKM/tdWMciIiIiIhKU0FNERERERESKSahVRMxskplt\nNLM/mdnNh9nmTjN7w8xeMrNPZbJvMcmirT6d8vjbZrbezNaZ2R/yd9T5d6R2MrNBZvasmX1sZt/L\nZN9ik2NbqU+1/Px/JNpivZk9Y2ZnpbtvMcmxnWLTnyCttvrrlPZ40cwuSHffYpJjO6lPtb/dKDNr\nNLPLM923GOTYTpn1KedcKDd8cP8m0B8oA14CBrfZ5hJgZeL+GOC5dPctplsubZX4fhNwXNjvo0Da\nqTdwDvBj4HuZ7FtMt1zaSn3qkHYaC5Qn7k+K43kql3aKU3/KoK26pdwfAbypPpV+O6lPtd8vEtv9\nHqgELlefSr+dsulTYY5gjwbecM5tcc41Ag8Al7XZ5jLg3wGcc88D5WbWJ819i0kubQV+Emkcap4f\nsZ2cczudc2uBpkz3LTK5tBWoTx3knHvOOfdh4tvngFPS3beI5NJOEJ/+BOm11d6Ub48Fdqa7bxHJ\npZ1Afaq9fnET8DDwfhb7FoNc2gky7FNhdr5TgG0p379D6xNuR9uks28xyaattqds44DHzewFM7u2\n044yfLn0C/WpzN6v+lT7vgkkJ2zHqU/l0k4Qn/4EabaV+UIArwGrgG9nsm+RyKWdQH2qVVuZ2cnA\nFOfc3bSu3KY+laKDdoIM+1ShlOlLl8r1ZWecc+5dMzse3zlec849E/ZBSaSpT7VhZn8FzADGh30s\nheww7aT+1IZzbgWwwsw+C/wHMCjkQypIKe00ntbtpD7V2h1AUedXB6RtO6XGnRn1qTAD7O1Av5Tv\nT0081nabvu1s0yWNfYtJLm2Fc+7dxNe/mNmj+MskxXiiSaedOmPfKMrp/apPtZaYsLcEmOScq81k\n3yKRSzvFqT9Bhv3COfe0mZWaWa9M9424TNvpmWQ7Oed2qU8d0lafAR4wM8PPr7nEzJrS3LdYZNtO\njc6532bcp0JMNi+hJdm8Cz7ZfEibbSbTMnFvLC2Th464bzHdcmyrbsCxifvHANXARWG/p7DaKWXb\nW/EriGa8bzHccmwr9anW2/QD3gDGZtvGUb/l2E6x6U8ZtNUnU+6fDbylPpVRO6lPddAvgHtpmeSo\nPpVeO2Xcp0IbwXbONZvZjcBqfC74Uufca2Y20//YLXHOrTKzyWb2JrAHf1nxsPuG9FY6XS5tBfQB\nHjW/3HwpcJ9zbnUY76OzpdNOiYmfLwLdgQNm9j+Boc653epT6bUVcDzqUwfbCbgF6AnclRj1aHTO\njY7TeSqXdiJG5yhIu62+bGZfBfbjz+dXdbRvKG+kk2XZTtMSu6tPHdpWrXY50r75OvZ8yqWdyKJP\naaEZEREREZEAxaWEjYiIiIhIXijAFhEREREJkAJsEREREZEAKcAWEREREQmQAmwRERERkQApwBYR\nERERCZACbBGRPDOzZjP7o5m9YmbLzezoLJ7jVjP7XgbbX2Zmg1O+v9fMLs/0dUVE5MgUYIuI5N8e\n59zZzrkRQCNwXR5ecwowLA+vIyISewqwRUTC9TRwOoCZPWpmLyRGtr+Z3MDMJpnZWjN7ycweb/sE\nZnatma00s65mdpqZ/S7xPE+a2Zlmdi7w18D8xMj5wDb7X5h4fL2Z/ZuZlSUe/0czq0m87vzEY1MT\nx7fOzKo6r1lERKIrtKXSRURizADMrBS4BPhd4vEZzrm6RMrIC2b2f4ASYAkw3jm31cwqUp/HzG4A\nPg9c5pxrMrMlwEzn3FtmNhq42zl3oZn9FvhP59wjiR2TT9AVuBf4q8Q+vwauN7NlwBTn3ODEdj0S\nr3kLcJFz7t2Ux0REJIUCbBGR/PuEmf0xcf9pYGni/nfMbEri/qnAGcAJwJPOua0Azrm6lOf5KrAV\nHwg3m9kxwHnAQ5aMoKHsCMcyCNjknHsr8f2vgVnAIuAjM/s3YCVQmfj5M8CvzexB4JFM3rSISFwo\nwBYRyb+9zrmzUx8ws88BFwBjnHP7zOwJIDn50do+QcLLwKeAvsDb+LS/2rbPnYZDnj8RsI8GLgSm\nAjcCFzrnZpnZKOBSYK2Zne2cq83w9UREippysEVE8q+9gLkcHxzvS1T7GJt4/Dngs2bWH8DMjkvZ\nZx0wE/itmZ3onGsANpvZFQdfyOysxN0GoL2UjteB/mZ2WuL7rwBPmlk3oMI59xjwPeCsxPOd5px7\nwTl3K/A+PrgXEZEUCrBFRPLPtfPYY0CZmW0AfgKsAXDO7QS+BTxqZuuAB1o9kXPPArOBlWbWE5gO\nXJOYmFiDn9xIYr85icmSA5PH4JzbB8wAHjaz9UAzcA8+GK9MPPYU8N3E8/zMzF42s5eBaufcywG0\nh4hIUTHn2jvPi4iIiIhINjSCLSIiIiISIAXYIiIiIiIBUoAtIiIiIhIgBdgiIiIiIgFSgC0iIiIi\nEiAF2CIiIiIiAVKALSIiIiISIAXYIiIiIiIB+v9nn8NmUdKlsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9113d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataSetsWithPacketloss = getDataSetWithPacketloss(dataSet_CERN_to_RAL)\n",
    "\n",
    "# sort for packetloss\n",
    "# when sorted mathis formular dosen't work anymore...\n",
    "#dataSetsWithPacketloss.sort_values('packet_loss', ascending=1, inplace=True)\n",
    "\n",
    "RTT_Array = np.empty(len(dataSetsWithPacketloss))\n",
    "for i in xrange(len(dataSetsWithPacketloss)):\n",
    "    RTT_Array[i] = float(dataSetsWithPacketloss['delay_current_average_forth'][i] + dataSetsWithPacketloss['delay_current_average_back'][i])\n",
    "\n",
    "\n",
    "MSS = 8860\n",
    "\n",
    "# plot the data we got\n",
    "plt.figure(figsize=(12,9), dpi=300)\n",
    "title = \"Packetloss vs throughput\"\n",
    "plt.title(title,fontsize=14)\n",
    "plt.plot(dataSetsWithPacketloss['packet_loss'], dataSetsWithPacketloss['throughput'], 'r.', label=r'Data points')\n",
    "# we need to take Mathis modell\n",
    "plt.plot(dataSetsWithPacketloss['packet_loss'], calcMathisModel_outBitsPerSec(dataSetsWithPacketloss['packet_loss'], MSS, RTT_Array), 'b.', label=r'Mathis points')\n",
    "# plot ann data\n",
    "plt.plot(dataSet_with_ann_data['packet_loss'], dataSet_with_ann_data['throughput'], 'bx', label=r'Ann data points')\n",
    "plt.legend(loc='best',fontsize=14)\n",
    "plt.ylabel(\"Throughput\")\n",
    "plt.xlabel(\"Packetloss\")\n",
    "plt.axis([0, 0.05, 0, 6*1e9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.odr import *\n",
    "def mModelForODR(Vars, packetloss_or_x_Array):\n",
    "    MSS = 8860\n",
    "    return calcMathisModel_outBitsPerSec(packetloss_or_x_Array, MSS, RTT_Array, C=Vars[0])\n",
    "\n",
    "# scipy model\n",
    "mathis_model = Model(mModelForODR)\n",
    "# our data\n",
    "fiting_data = Data(dataSetsWithPacketloss['packet_loss'], dataSetsWithPacketloss['throughput'])\n",
    "# do the actual fit\n",
    "mathisodr = ODR(fiting_data, mathis_model, beta0=[1.224], maxit=500)\n",
    "# all params:\n",
    "# mathisodr = ODR(fiting_data, mathis_model, beta0=[1.224, 1, 0.0, 2])\n",
    "odroutput = mathisodr.run()\n",
    "\n",
    "# print the output\n",
    "odroutput.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot with fitted function\n",
    "plt.figure(figsize=(12,9), dpi=300)\n",
    "title = \"Packetloss vs throughput with fitted Mathis formular\"\n",
    "plt.title(title,fontsize=14)\n",
    "plt.plot(packetlossArray, throughputArray, 'r.', label=r'Data points')\n",
    "plt.plot(packetlossArray, mModelForODR(odroutput.beta, packetlossArray), 'b.', label=\"Mathis model\")\n",
    "plt.legend(loc='best',fontsize=14)\n",
    "plt.ylabel(\"throughput\")\n",
    "plt.xlabel(\"packet loss\")\n",
    "plt.axis([0, 0.05, 0, 6*1e9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
