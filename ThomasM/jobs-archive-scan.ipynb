{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blub\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "\n",
    "def convert_to_unix_time(time_string, time_format = \"%Y-%m-%dT%H:%M:%S\", time_delta_hours = 0):\n",
    "    ## Make datetime object from time_string\n",
    "    date = datetime.datetime.strptime(time_string, time_format)\n",
    "    ## Define timedelta object to take into account any deviation from UTC of the input time_string\n",
    "    ## Example: if time_string refers to UTC+1 we have to subtract 1h before evaluating the unix time\n",
    "    time_delta = datetime.timedelta(hours = time_delta_hours)\n",
    "    date += time_delta\n",
    "    time_tuple = date.timetuple()\n",
    "    ## Get unix time (this assumes that time_tuple was created with a UTC time)\n",
    "    time_unix = calendar.timegm(time_tuple)\n",
    "    \n",
    "    return time_unix\n",
    "\n",
    "print ('blub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tables import *\n",
    "\n",
    "class JobEntry(IsDescription):\n",
    "    proddblock = StringCol(200)\n",
    "    produsername = StringCol(100)\n",
    "    creationtime = Int32Col()\n",
    "    starttime = Int32Col()\n",
    "    endtime = Int32Col()\n",
    "    jeditaskid = Int32Col()\n",
    "    computingsite = StringCol(100)\n",
    "    queue_time = Int32Col()\n",
    "    jobstatus = StringCol(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Processing (1/31) jobs_archive_2017-08-15\n",
      "Processing (2/31) jobs_archive_2017-08-29\n",
      "Processing (3/31) jobs_archive_2017-08-26\n",
      "Processing (4/31) jobs_archive_2017-08-27\n",
      "Processing (5/31) jobs_archive_2017-08-14\n",
      "Processing (6/31) jobs_archive_2017-08-30\n",
      "Processing (7/31) jobs_archive_2017-08-25\n",
      "Processing (8/31) jobs_archive_2017-08-01\n",
      "Processing (9/31) jobs_archive_2017-08-10\n",
      "Processing (10/31) jobs_archive_2017-08-07\n",
      "Processing (11/31) jobs_archive_2017-08-13\n",
      "Processing (12/31) jobs_archive_2017-08-31\n",
      "Processing (13/31) jobs_archive_2017-08-04\n",
      "Processing (14/31) jobs_archive_2017-08-18\n",
      "Processing (15/31) jobs_archive_2017-08-20\n",
      "Processing (16/31) jobs_archive_2017-08-19\n",
      "Processing (17/31) jobs_archive_2017-08-28\n",
      "Processing (18/31) jobs_archive_2017-08-22\n",
      "Processing (19/31) jobs_archive_2017-08-24\n",
      "Processing (20/31) jobs_archive_2017-08-11\n",
      "Processing (21/31) jobs_archive_2017-08-08\n",
      "Processing (22/31) jobs_archive_2017-08-06\n",
      "Processing (23/31) jobs_archive_2017-08-03\n",
      "Processing (24/31) jobs_archive_2017-08-21\n",
      "Processing (25/31) jobs_archive_2017-08-12\n",
      "Processing (26/31) jobs_archive_2017-08-16\n",
      "Processing (27/31) jobs_archive_2017-08-02\n",
      "Processing (28/31) jobs_archive_2017-08-23\n",
      "Processing (29/31) jobs_archive_2017-08-09\n",
      "Processing (30/31) jobs_archive_2017-08-05\n",
      "Processing (31/31) jobs_archive_2017-08-17\n",
      "done\n",
      "total: 2953.4929921627045\n",
      "write: 0.362246036529541\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import VERSION\n",
    "from collections import OrderedDict\n",
    "from elasticsearch import helpers\n",
    "import time\n",
    "\n",
    "es = Elasticsearch([{'host':'atlas-kibana.mwt2.org', 'port':9200, 'timeout':200}])\n",
    "\n",
    "fieldNames = ['computingsite', 'proddblock', 'produsername', 'jeditaskid', 'jobstatus', 'queue_time']\n",
    "timeNames = ['creationtime', 'starttime', 'endtime']\n",
    "fieldNames += timeNames\n",
    "\n",
    "usrc={\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                    {\"match\": {\"prodsourcelabel\": \"user\"}}\n",
    "                ],\n",
    "        }\n",
    "    },\n",
    "    \"_source\": fieldNames\n",
    "}\n",
    "\n",
    "monthPrefixes = [\n",
    "#    \"2016-08\",\n",
    "#    \"2016-09\",\n",
    "#    \"2016-10\",\n",
    "#    \"2016-11\",\n",
    "#    \"2016-12\",\n",
    "#    \"2017-01\",\n",
    "#    \"2017-02\",\n",
    "#    \"2017-03\",\n",
    "#    \"2017-04\",\n",
    "#    \"2017-05\",\n",
    "#    \"2017-06\"\n",
    "#    \"2017-07\",\n",
    "    #\"2017-08\",\n",
    "    \"2017-09\"\n",
    "]\n",
    "\n",
    "indices = es.cat.indices(index=\"jobs_archive_*\", h=\"index\", request_timeout=600).split('\\n')\n",
    "my_indices = {}\n",
    "for monthPrefix in monthPrefixes:\n",
    "    my_indices[monthPrefix] = []\n",
    "    my_indices[monthPrefix] += [l for l in indices if monthPrefix in l]\n",
    "\n",
    "time_total = time.time()\n",
    "time_write = 0\n",
    "\n",
    "print ('start')\n",
    "\n",
    "for monthPrefix in my_indices.keys():\n",
    "    filters = Filters(complevel=1, complib='lzo')\n",
    "    h5file = open_file(\"jobs_archive-{}.h5\".format(monthPrefix), mode = \"w\", title = \"jobs_archive_{}\".format(monthPrefix), filters = filters)\n",
    "    group = h5file.create_group(\"/\", 'jobs', 'Jobs information')\n",
    "    table = h5file.create_table(group, 'table', JobEntry, \"Jobs table\")\n",
    "    job = table.row\n",
    "    \n",
    "    n_indices = len(my_indices[monthPrefix])\n",
    "\n",
    "    for i, ind in enumerate(my_indices[monthPrefix]):\n",
    "        print ('Processing ('+str(i+1)+'/'+str(n_indices)+')', ind)\n",
    "        \n",
    "        res = helpers.scan(es, query=usrc, index=ind, size=10000)\n",
    "\n",
    "        for hit in res:\n",
    "            source = hit['_source']\n",
    "            if not source['proddblock']: continue\n",
    "            if not source['proddblock'].startswith('data') and not source['proddblock'].startswith('mc'): continue\n",
    "            if not 'DAOD' in source['proddblock'] and not 'NTUP' in source['proddblock']: continue\n",
    "            source['proddblock'] = source['proddblock'].split(':', 1)[-1]\n",
    "            for timeName in timeNames:\n",
    "                if not source[timeName]:\n",
    "                    source[timeName] = -1\n",
    "                    continue\n",
    "                source[timeName] = convert_to_unix_time(source[timeName])\n",
    "            \n",
    "            if source['queue_time'] is None:\n",
    "                source['queue_time'] = -1\n",
    "            if source['jeditaskid'] is None:\n",
    "                source['jeditaskid'] = 0\n",
    "            \n",
    "            if len(source['proddblock']) > 200: print('proddblock too long!')\n",
    "            if len(source['produsername']) > 100: print('produsername too long!')\n",
    "            if len(source['computingsite']) > 100: print('computingsite too long!')\n",
    "            if len(source['jobstatus']) > 20: print('jobstatus too long!')\n",
    "            \n",
    "            for fieldName in fieldNames:\n",
    "                job[fieldName] = source[fieldName]\n",
    "            job.append()\n",
    "    \n",
    "        time_tmp = time.time()\n",
    "        \n",
    "        table.flush()\n",
    "        \n",
    "        time_tmp = time.time() - time_tmp\n",
    "        time_write += time_tmp\n",
    "    \n",
    "    h5file.close()\n",
    "\n",
    "print ('done')\n",
    "\n",
    "time_total = time.time() - time_total\n",
    "print ('total:', time_total)\n",
    "print ('write:', time_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
