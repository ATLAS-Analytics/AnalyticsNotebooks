{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, exceptions as es_exceptions\n",
    "from elasticsearch.helpers import scan\n",
    "es = Elasticsearch(hosts=[{'host':'atlas-kibana.mwt2.org', 'port':9200}],timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function to print a few job information\n",
    "def print_info(job):\n",
    "    \n",
    "    print('\\n')    \n",
    "    errors = ['pilot','brokerage','taskbuffer','sup','jobdispatcher','ddm','exe']\n",
    "    #print(job)\n",
    "    \n",
    "    print('pandaid ' + str(job['_source']['pandaid']))\n",
    "    print('modificationtime ' + str(job['_source']['modificationtime']))\n",
    "    print('site '    + str(job['_source']['computingsite']))\n",
    "    \n",
    "    for e in errors:\n",
    "        errorcode = e + 'errorcode'\n",
    "        exitcode = job['_source'][errorcode] \n",
    "      \n",
    "        if exitcode:\n",
    "            print(errorcode + ' ' + str(exitcode))  \n",
    "            errordiag = e +'errordiag'   \n",
    "            print(j['_source'][errordiag])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function to debug job information\n",
    "def debug(job):\n",
    "        \n",
    "    errors = ['pilot','brokerage','taskbuffer','sup','jobdispatcher','ddm','exe']\n",
    "    #print(job)\n",
    "    pandaid=int(job['_source']['pandaid'])\n",
    "    \n",
    "    if (pandaid==3155163997): #3186999624):  #3155206788):\n",
    "        print('pandaid ' + str(job['_source']['pandaid']))\n",
    "        print('modificationtime ' + str(job['_source']['modificationtime']))\n",
    "        print('site '    + str(job['_source']['computingsite']))\n",
    "    \n",
    "        for e in errors:\n",
    "            errorcode = e + 'errorcode'\n",
    "            exitcode = job['_source'][errorcode] \n",
    "      \n",
    "            if exitcode:\n",
    "                print(errorcode + ' ' + str(exitcode))  \n",
    "                errordiag = e +'errordiag'   \n",
    "                print(j['_source'][errordiag])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function to filter on time\n",
    "def time_filter(indices, last_days=1, pattern=''):\n",
    "    if last_days == 0:\n",
    "        return [\"jobs_archive_*\"]\n",
    "    filtered = []\n",
    "    if pattern:\n",
    "        for i in indices:\n",
    "            if pattern in i:\n",
    "                filtered.append(i.rstrip())\n",
    "        return filtered\n",
    "    today = datetime.date.today()\n",
    "    filtered = []\n",
    "    datefmt = '%Y-%m-%d'\n",
    "    for i in indices:\n",
    "        day = re.sub(r'jobs_archive_', '', i).rstrip()\n",
    "        #print(day)\n",
    "        day = datetime.datetime.strptime(day, datefmt).date()\n",
    "        diff = today - day\n",
    "        if diff.days < last_days:\n",
    "            filtered.append(i.rstrip())\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get job archive indices from ES\n",
    "indices = es.cat.indices(index=\"jobs_archive_*\", h=\"index\", request_timeout=600).split('\\n')\n",
    "indices = sorted(indices)\n",
    "indices = [x for x in indices if x != '']\n",
    "if 'jobs_archive_2016_status' in indices:\n",
    "    indices.remove('jobs_archive_2016_status')\n",
    "#remove data due to central problem\n",
    "if 'jobs_archive_2016-12-29' in indices:\n",
    "    indices.remove('jobs_archive_2016-12-29')\n",
    "#print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs_archive_2016-12-27,jobs_archive_2016-12-28,jobs_archive_2016-12-30,jobs_archive_2016-12-31,jobs_archive_2017-01-01,jobs_archive_2017-01-02,jobs_archive_2017-01-03,jobs_archive_2017-01-04,jobs_archive_2017-01-05,jobs_archive_2017-01-06,jobs_archive_2017-01-07,jobs_archive_2017-01-08,jobs_archive_2017-01-09,jobs_archive_2017-01-10,jobs_archive_2017-01-11,jobs_archive_2017-01-12,jobs_archive_2017-01-13,jobs_archive_2017-01-14,jobs_archive_2017-01-15,jobs_archive_2017-01-16,jobs_archive_2017-01-17,jobs_archive_2017-01-18,jobs_archive_2017-01-19,jobs_archive_2017-01-20,jobs_archive_2017-01-21,jobs_archive_2017-01-22,jobs_archive_2017-01-23,jobs_archive_2017-01-24,jobs_archive_2017-01-25,jobs_archive_2017-01-26,jobs_archive_2017-01-27,jobs_archive_2017-01-28,jobs_archive_2017-01-29,jobs_archive_2017-01-30,jobs_archive_2017-01-31,jobs_archive_2017-02-01,jobs_archive_2017-02-02,jobs_archive_2017-02-03,jobs_archive_2017-02-04,jobs_archive_2017-02-05,jobs_archive_2017-02-06,jobs_archive_2017-02-07,jobs_archive_2017-02-08,jobs_archive_2017-02-09,jobs_archive_2017-02-10,jobs_archive_2017-02-11,jobs_archive_2017-02-12,jobs_archive_2017-02-13,jobs_archive_2017-02-14,jobs_archive_2017-02-15,jobs_archive_2017-02-16,jobs_archive_2017-02-17,jobs_archive_2017-02-18,jobs_archive_2017-02-19,jobs_archive_2017-02-20,jobs_archive_2017-02-21,jobs_archive_2017-02-22,jobs_archive_2017-02-23,jobs_archive_2017-02-24\n"
     ]
    }
   ],
   "source": [
    "# use e.g. last_days=7 or pattern='2016-02' (no wildcard !)\n",
    "ind = time_filter(indices, last_days=60, pattern='')\n",
    "ind = ','.join(ind)\n",
    "print(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try either simple query\n",
    "query = \"jobstatus:failed AND processingtype:gangarobot-pft\"\n",
    "\n",
    "#or add it to body\n",
    "body = {\n",
    "    \"size\": 2,\n",
    "    \"_source\": [\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"], #returns only certain fields\n",
    "    \"query\": { \n",
    "        \"bool\" : {\n",
    "            \"filter\" : [\n",
    "                { \"match\" : { \"processingtype\":\"gangarobot-pft\" } },\n",
    "                { \"match\" : { \"jobstatus\":\"failed\" } },\n",
    "              ],\n",
    "           #\"must\" :                 \n",
    "           #     {\"match\": {\"processingtype\":\"gangarobot-pft\"}},\n",
    "           # \"should\" :\n",
    "           #     {\"match\": {\"jobstatus\":\"failed\"}}\n",
    "     \n",
    "        }\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pandaid 3162626191\n",
      "modificationtime 2017-01-03T00:01:52\n",
      "site UKI-SCOTGRID-DURHAM-ARC\n",
      "piloterrorcode 1008\n",
      "LRMS error: (91) Job failed\n",
      "exeerrorcode 91\n",
      "LRMS error: (91) Job failed\n",
      "\n",
      "\n",
      "pandaid 3162652373\n",
      "modificationtime 2017-01-03T00:01:36\n",
      "site INFN-T1_TEST\n",
      "piloterrorcode 1099\n",
      "STAGEIN FAILED: Get error: Staging input file failed: lfn=EVNT.04972714._000035.pool.root.1, error=Copy operation failed [is_stagein=True]: LOCAL-SETUP> NO PANDA RESOURCE FOUND\n",
      "AUTO-SETUP> INFO: CUSTOM_SITE_NAME=, ATLAS_SITE_NAME=, SITE_NAME=INFN-T1,\n"
     ]
    }
   ],
   "source": [
    "#test query with search -> gets only a limited number of records (size=x). Cannot be used for big searches x>10000\n",
    "res = es.search(index=ind, q=query, size = 2, request_timeout=600, \n",
    "                _source=[\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"])\n",
    "#res = es.search(index=ind, body=body, request_timeout=600)\n",
    "\n",
    "jobs = res['hits']['hits']\n",
    "\n",
    "#print(json.dumps(jobs))\n",
    "#print a few information\n",
    "for j in jobs:\n",
    "    print_info(j)\n",
    "    \n",
    "#save to file\n",
    "with open('data_few.txt', 'w') as outfile:  \n",
    "    json.dump(jobs, outfile)\n",
    "outfile.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits: 234549\n",
      "processing hit 10000...\n",
      "processing hit 20000...\n",
      "processing hit 30000...\n",
      "processing hit 40000...\n",
      "processing hit 50000...\n",
      "processing hit 60000...\n",
      "processing hit 70000...\n",
      "processing hit 80000...\n",
      "processing hit 90000...\n",
      "processing hit 100000...\n",
      "processing hit 110000...\n",
      "processing hit 120000...\n",
      "processing hit 130000...\n",
      "processing hit 140000...\n",
      "processing hit 150000...\n",
      "processing hit 160000...\n",
      "processing hit 170000...\n",
      "processing hit 180000...\n",
      "processing hit 190000...\n",
      "processing hit 200000...\n",
      "processing hit 210000...\n",
      "processing hit 220000...\n",
      "processing hit 230000...\n",
      "saved 234549 results\n",
      "check: reading in 234549 hits\n",
      "\n",
      "\n",
      "pandaid 3186999624\n",
      "modificationtime 2017-01-15T00:41:25\n",
      "site RRC-KI-T1_TEST\n",
      "piloterrorcode 1099\n",
      "STAGEIN FAILED: Get error: Staging input file failed: lfn=EVNT.04972714._000035.pool.root.1, error=Copy operation failed [is_stagein=True]: LOCAL-SETUP> NO PANDA RESOURCE FOUND\n",
      "AUTO-SETUP> INFO: CUSTOM_SITE_NAME=, ATLAS_SITE_NAME=, SITE_NAME=INFN-T1,\n",
      "\n",
      "\n",
      "pandaid 3186999624\n",
      "modificationtime 2017-01-15T00:41:25\n",
      "site RRC-KI-T1_TEST\n",
      "piloterrorcode 1099\n",
      "STAGEIN FAILED: Get error: Staging input file failed: lfn=EVNT.04972714._000035.pool.root.1, error=Copy operation failed [is_stagein=True]: LOCAL-SETUP> NO PANDA RESOURCE FOUND\n",
      "AUTO-SETUP> INFO: CUSTOM_SITE_NAME=, ATLAS_SITE_NAME=, SITE_NAME=INFN-T1,\n"
     ]
    }
   ],
   "source": [
    "#count hits\n",
    "count =(es.count(index=ind, q=query, request_timeout=600))\n",
    "print('hits: '+str(count['count']))\n",
    "\n",
    "#use scroll to get all hits (allows unlimted result queries)\n",
    "scroll = scan(es, index=ind, q=query, scroll='5m', timeout=\"5m\", size=100, _source=[\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"])\n",
    "\n",
    "outfile = open('data.txt', 'w') \n",
    "\n",
    "#write results to file\n",
    "i = 0   \n",
    "jobs = []\n",
    "for result in scroll:\n",
    "    #print(result['_source']['pandaid'])\n",
    "    #print_info(result)\n",
    "    jobs.append(result)\n",
    "    #if i<1: print_info(result)\n",
    "    i = i+1\n",
    "    if not i%10000:  print('processing hit '+str(i)+'...')\n",
    "\n",
    "json.dump(jobs, outfile)         \n",
    "outfile.close()\n",
    "print('saved '+str(i)+' results') \n",
    "\n",
    "#check written results\n",
    "infile = open('data.txt', 'r')\n",
    "savedjobs = json.load(infile)\n",
    "print('check: reading in '+str(len(savedjobs))+' hits')\n",
    "infile.close()\n",
    "\n",
    "print_info(savedjobs[0])\n",
    "print_info(jobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing hit 10000...\n",
      "processing hit 20000...\n",
      "processing hit 30000...\n",
      "processing hit 40000...\n",
      "processing hit 50000...\n",
      "processing hit 60000...\n",
      "processing hit 70000...\n",
      "processing hit 80000...\n",
      "processing hit 90000...\n",
      "processing hit 100000...\n",
      "processing hit 110000...\n",
      "processing hit 120000...\n",
      "processing hit 130000...\n",
      "processing hit 140000...\n",
      "processing hit 150000...\n",
      "processing hit 160000...\n",
      "processing hit 170000...\n",
      "processing hit 180000...\n",
      "processing hit 190000...\n",
      "processing hit 200000...\n",
      "processing hit 210000...\n",
      "processing hit 220000...\n",
      "processing hit 230000...\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for j in jobs:\n",
    "    debug(jobs[i])\n",
    "    i = i+1\n",
    "    if not i%10000:  print('processing hit '+str(i)+'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggregations': {'models': {'sum_other_doc_count': 0, 'doc_count_error_upper_bound': 0, 'buckets': [{'key': 'failed', 'doc_count': 141998}]}}, 'took': 14, 'hits': {'total': 141998, 'max_score': 0.0, 'hits': [{'_id': '3124983243', '_type': 'jobs_data', '_source': {'taskbuffererrorcode': 0, 'jobdispatchererrorcode': 0, 'ddmerrordiag': None, 'computingsite': 'ATLAS_OPP_OSG-MIT_CMS', 'brokerageerrorcode': 0, 'exeerrorcode': 0, 'modificationtime': '2016-12-14T02:46:42', 'brokerageerrordiag': None, 'superrorcode': 0, 'pandaid': 3124983243, 'superrordiag': None, 'jobdispatchererrordiag': None, 'piloterrordiag': 'Job killed by signal 15: Signal handler has set job result to FAILED, ec = 1201', 'ddmerrorcode': 0, 'piloterrorcode': 1201, 'exeerrordiag': None, 'taskbuffererrordiag': None}, '_score': 0.0, '_index': 'jobs_archive_2016-12-14'}]}, '_shards': {'total': 155, 'failed': 0, 'successful': 155}, 'timed_out': False}\n",
      "check: reading in 1 hits\n",
      "{'_id': '3124983243', '_type': 'jobs_data', '_source': {'taskbuffererrorcode': 0, 'jobdispatchererrorcode': 0, 'ddmerrordiag': None, 'computingsite': 'ATLAS_OPP_OSG-MIT_CMS', 'brokerageerrorcode': 0, 'exeerrorcode': 0, 'modificationtime': '2016-12-14T02:46:42', 'brokerageerrordiag': None, 'superrorcode': 0, 'pandaid': 3124983243, 'superrordiag': None, 'jobdispatchererrordiag': None, 'piloterrordiag': 'Job killed by signal 15: Signal handler has set job result to FAILED, ec = 1201', 'ddmerrorcode': 0, 'piloterrorcode': 1201, 'exeerrordiag': None, 'taskbuffererrordiag': None}, '_score': 0.0, '_index': 'jobs_archive_2016-12-14'}\n"
     ]
    }
   ],
   "source": [
    "#Example of more refined queries\n",
    "#better to use filters if the score is not needed (faster)\n",
    "s = {\n",
    "    \"size\": 1,\n",
    "    \"_source\": [\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"], #returns only certain fields\n",
    "    \"query\": { \n",
    "        \"bool\" : {\n",
    "            \"filter\" : [\n",
    "                { \"match\" : { \"processingtype\":\"gangarobot-pft\" } },\n",
    "                { \"match\" : { \"jobstatus\":\"failed\" } },\n",
    "              ],\n",
    "           #\"must\" :                 \n",
    "           #     {\"match\": {\"processingtype\":\"gangarobot-pft\"}},\n",
    "           # \"should\" :\n",
    "           #     {\"match\": {\"jobstatus\":\"failed\"}}\n",
    "     \n",
    "        }\n",
    "    },\n",
    "    \"aggs\": {  #build aggregation\n",
    "        \"models\": \n",
    "            {\"terms\": { \"field\": \"jobstatus\" } }\n",
    "    }    \n",
    "}\n",
    "\n",
    "res = es.search(index=ind, body=s, request_timeout=12000)\n",
    "\n",
    "print(res) \n",
    "\n",
    "jobs = res['hits']['hits']\n",
    "print('check: reading in '+str(len(jobs))+' hits')\n",
    "#print_info(jobs[0])\n",
    "print(jobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
