{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, exceptions as es_exceptions\n",
    "from elasticsearch.helpers import scan\n",
    "es = Elasticsearch(hosts=[{'host':'atlas-kibana.mwt2.org', 'port':9200}],timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function to print a few job information\n",
    "def print_info(job):\n",
    "    \n",
    "    print('\\n')    \n",
    "    errors = ['pilot','brokerage','taskbuffer','sup','jobdispatcher','ddm','exe']\n",
    "    #print(job)\n",
    "    \n",
    "    print('pandaid ' + str(job['_source']['pandaid']))\n",
    "    print('modificationtime ' + str(job['_source']['modificationtime']))\n",
    "    print('site '    + str(job['_source']['computingsite']))\n",
    "    \n",
    "    for e in errors:\n",
    "        errorcode = e + 'errorcode'\n",
    "        exitcode = job['_source'][errorcode] \n",
    "      \n",
    "        if exitcode:\n",
    "            print(errorcode + ' ' + str(exitcode))  \n",
    "            errordiag = e +'errordiag'   \n",
    "            print(j['_source'][errordiag])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function to debug job information\n",
    "def debug(job):\n",
    "        \n",
    "    errors = ['pilot','brokerage','taskbuffer','sup','jobdispatcher','ddm','exe']\n",
    "    #print(job)\n",
    "    pandaid=int(job['_source']['pandaid'])\n",
    "    \n",
    "    if (pandaid==3155163997): #3186999624):  #3155206788):\n",
    "        print('pandaid ' + str(job['_source']['pandaid']))\n",
    "        print('modificationtime ' + str(job['_source']['modificationtime']))\n",
    "        print('site '    + str(job['_source']['computingsite']))\n",
    "    \n",
    "        for e in errors:\n",
    "            errorcode = e + 'errorcode'\n",
    "            exitcode = job['_source'][errorcode] \n",
    "      \n",
    "            if exitcode:\n",
    "                print(errorcode + ' ' + str(exitcode))  \n",
    "                errordiag = e +'errordiag'   \n",
    "                print(j['_source'][errordiag])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define function to filter on time\n",
    "def time_filter(indices, last_days=1, pattern=''):\n",
    "    if last_days == 0:\n",
    "        return [\"jobs_archive_*\"]\n",
    "    filtered = []\n",
    "    if pattern:\n",
    "        for i in indices:\n",
    "            if pattern in i:\n",
    "                filtered.append(i.rstrip())\n",
    "        return filtered\n",
    "    today = datetime.date.today()\n",
    "    filtered = []\n",
    "    datefmt = '%Y-%m-%d'\n",
    "    for i in indices:\n",
    "        day = re.sub(r'jobs_archive_', '', i).rstrip()\n",
    "        #print(day)\n",
    "        day = datetime.datetime.strptime(day, datefmt).date()\n",
    "        diff = today - day\n",
    "        if diff.days < last_days:\n",
    "            filtered.append(i.rstrip())\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get job archive indices from ES\n",
    "indices = es.cat.indices(index=\"jobs_archive_*\", h=\"index\", request_timeout=600).split('\\n')\n",
    "indices = sorted(indices)\n",
    "indices = [x for x in indices if x != '']\n",
    "if 'jobs_archive_2016_status' in indices:\n",
    "    indices.remove('jobs_archive_2016_status')\n",
    "#remove data due to central problem\n",
    "if 'jobs_archive_2016-12-29' in indices:\n",
    "    indices.remove('jobs_archive_2016-12-29')\n",
    "#print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs_archive_2016-03-01,jobs_archive_2016-03-02,jobs_archive_2016-03-03,jobs_archive_2016-03-04,jobs_archive_2016-03-05,jobs_archive_2016-03-06,jobs_archive_2016-03-07,jobs_archive_2016-03-08,jobs_archive_2016-03-09,jobs_archive_2016-03-10,jobs_archive_2016-03-11,jobs_archive_2016-03-12,jobs_archive_2016-03-13,jobs_archive_2016-03-14,jobs_archive_2016-03-15,jobs_archive_2016-03-16,jobs_archive_2016-03-17,jobs_archive_2016-03-18,jobs_archive_2016-03-19,jobs_archive_2016-03-20,jobs_archive_2016-03-21,jobs_archive_2016-03-22,jobs_archive_2016-03-23,jobs_archive_2016-03-24,jobs_archive_2016-03-25,jobs_archive_2016-03-26,jobs_archive_2016-03-27,jobs_archive_2016-03-28,jobs_archive_2016-03-29,jobs_archive_2016-03-30,jobs_archive_2016-03-31\n"
     ]
    }
   ],
   "source": [
    "# use e.g. last_days=7 or pattern='2016-02' (no wildcard !)\n",
    "NDAYS=''  #NDAYS=150\n",
    "PATTERN = '2016-03' #PATTERN=''\n",
    "ind = time_filter(indices, last_days=NDAYS, pattern=PATTERN)\n",
    "ind = ','.join(ind)\n",
    "print(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try either simple query\n",
    "query = \"jobstatus:failed AND processingtype:gangarobot-pft\"\n",
    "\n",
    "#or add it to body\n",
    "body = {\n",
    "    \"size\": 2,\n",
    "    \"_source\": [\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"], #returns only certain fields\n",
    "    \"query\": { \n",
    "        \"bool\" : {\n",
    "            \"filter\" : [\n",
    "                { \"match\" : { \"processingtype\":\"gangarobot-pft\" } },\n",
    "                { \"match\" : { \"jobstatus\":\"failed\" } },\n",
    "              ],\n",
    "           #\"must\" :                 \n",
    "           #     {\"match\": {\"processingtype\":\"gangarobot-pft\"}},\n",
    "           # \"should\" :\n",
    "           #     {\"match\": {\"jobstatus\":\"failed\"}}\n",
    "     \n",
    "        }\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pandaid 2797638432\n",
      "modificationtime 2016-03-17T01:14:21\n",
      "site UNIBE-LHEP\n",
      "\n",
      "\n",
      "pandaid 2797630345\n",
      "modificationtime 2016-03-17T01:16:08\n",
      "site UNIBE-LHEP\n"
     ]
    }
   ],
   "source": [
    "#test query with search -> gets only a limited number of records (size=x). Cannot be used for big searches x>10000\n",
    "res = es.search(index=ind, q=query, size = 2, request_timeout=600, \n",
    "                _source=[\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"])\n",
    "#res = es.search(index=ind, body=body, request_timeout=600)\n",
    "\n",
    "jobs = res['hits']['hits']\n",
    "\n",
    "#print(json.dumps(jobs))\n",
    "#print a few information\n",
    "for j in jobs:\n",
    "    print_info(j)\n",
    "    \n",
    "#save to file\n",
    "with open('data_few.txt', 'w') as outfile:  \n",
    "    json.dump(jobs, outfile)\n",
    "outfile.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits: 43260\n",
      "data_2016-03.txt\n",
      "processing hit 10000...\n",
      "processing hit 20000...\n",
      "processing hit 30000...\n",
      "processing hit 40000...\n",
      "saved 43260 results\n",
      "check: reading in 43260 hits\n",
      "\n",
      "\n",
      "pandaid 2804382616\n",
      "modificationtime 2016-03-22T01:05:26\n",
      "site INFN-GENOVA\n",
      "piloterrorcode 1099\n",
      "None\n",
      "\n",
      "\n",
      "pandaid 2804382616\n",
      "modificationtime 2016-03-22T01:05:26\n",
      "site INFN-GENOVA\n",
      "piloterrorcode 1099\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#count hits\n",
    "count =(es.count(index=ind, q=query, request_timeout=600))\n",
    "print('hits: '+str(count['count']))\n",
    "\n",
    "#use scroll to get all hits (allows unlimted result queries)\n",
    "scroll = scan(es, index=ind, q=query, scroll='5m', timeout=\"5m\", size=100, _source=[\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"])\n",
    "\n",
    "#create filename\n",
    "if (NDAYS==''):\n",
    "    FILENAME = 'data_'+PATTERN+'.txt'\n",
    "else:\n",
    "    FILENAME = 'data_last'+LASTDAYS+'.txt'\n",
    "\n",
    "print(FILENAME)\n",
    "outfile = open(FILENAME, 'w') \n",
    "\n",
    "#write results to file\n",
    "i = 0   \n",
    "jobs = []\n",
    "for result in scroll:\n",
    "    #print(result['_source']['pandaid'])\n",
    "    #print_info(result)\n",
    "    jobs.append(result)\n",
    "    #if i<1: print_info(result)\n",
    "    i = i+1\n",
    "    if not i%10000:  print('processing hit '+str(i)+'...')\n",
    "\n",
    "json.dump(jobs, outfile)         \n",
    "outfile.close()\n",
    "print('saved '+str(i)+' results') \n",
    "\n",
    "#check written results\n",
    "infile = open(FILENAME, 'r')\n",
    "savedjobs = json.load(infile)\n",
    "print('check: reading in '+str(len(savedjobs))+' hits')\n",
    "infile.close()\n",
    "\n",
    "print_info(savedjobs[0])\n",
    "print_info(jobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing hit 10000...\n",
      "processing hit 20000...\n",
      "processing hit 30000...\n",
      "processing hit 40000...\n",
      "processing hit 50000...\n",
      "processing hit 60000...\n",
      "processing hit 70000...\n",
      "processing hit 80000...\n",
      "processing hit 90000...\n",
      "processing hit 100000...\n",
      "processing hit 110000...\n",
      "processing hit 120000...\n",
      "processing hit 130000...\n",
      "processing hit 140000...\n",
      "processing hit 150000...\n",
      "processing hit 160000...\n",
      "processing hit 170000...\n",
      "processing hit 180000...\n",
      "processing hit 190000...\n",
      "processing hit 200000...\n",
      "processing hit 210000...\n",
      "processing hit 220000...\n",
      "processing hit 230000...\n",
      "processing hit 240000...\n",
      "processing hit 250000...\n",
      "processing hit 260000...\n",
      "processing hit 270000...\n",
      "processing hit 280000...\n",
      "processing hit 290000...\n",
      "processing hit 300000...\n",
      "processing hit 310000...\n",
      "processing hit 320000...\n",
      "processing hit 330000...\n",
      "processing hit 340000...\n",
      "processing hit 350000...\n",
      "processing hit 360000...\n",
      "processing hit 370000...\n",
      "processing hit 380000...\n",
      "processing hit 390000...\n",
      "processing hit 400000...\n",
      "processing hit 410000...\n",
      "processing hit 420000...\n",
      "processing hit 430000...\n",
      "processing hit 440000...\n",
      "processing hit 450000...\n",
      "processing hit 460000...\n",
      "processing hit 470000...\n",
      "processing hit 480000...\n",
      "processing hit 490000...\n",
      "processing hit 500000...\n",
      "processing hit 510000...\n",
      "processing hit 520000...\n",
      "processing hit 530000...\n",
      "processing hit 540000...\n",
      "processing hit 550000...\n",
      "processing hit 560000...\n",
      "processing hit 570000...\n",
      "processing hit 580000...\n",
      "processing hit 590000...\n",
      "processing hit 600000...\n",
      "processing hit 610000...\n",
      "processing hit 620000...\n",
      "processing hit 630000...\n",
      "processing hit 640000...\n",
      "processing hit 650000...\n",
      "processing hit 660000...\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for j in jobs:\n",
    "    debug(jobs[i])\n",
    "    i = i+1\n",
    "    if not i%10000:  print('processing hit '+str(i)+'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggregations': {'models': {'sum_other_doc_count': 0, 'doc_count_error_upper_bound': 0, 'buckets': [{'key': 'failed', 'doc_count': 141998}]}}, 'took': 14, 'hits': {'total': 141998, 'max_score': 0.0, 'hits': [{'_id': '3124983243', '_type': 'jobs_data', '_source': {'taskbuffererrorcode': 0, 'jobdispatchererrorcode': 0, 'ddmerrordiag': None, 'computingsite': 'ATLAS_OPP_OSG-MIT_CMS', 'brokerageerrorcode': 0, 'exeerrorcode': 0, 'modificationtime': '2016-12-14T02:46:42', 'brokerageerrordiag': None, 'superrorcode': 0, 'pandaid': 3124983243, 'superrordiag': None, 'jobdispatchererrordiag': None, 'piloterrordiag': 'Job killed by signal 15: Signal handler has set job result to FAILED, ec = 1201', 'ddmerrorcode': 0, 'piloterrorcode': 1201, 'exeerrordiag': None, 'taskbuffererrordiag': None}, '_score': 0.0, '_index': 'jobs_archive_2016-12-14'}]}, '_shards': {'total': 155, 'failed': 0, 'successful': 155}, 'timed_out': False}\n",
      "check: reading in 1 hits\n",
      "{'_id': '3124983243', '_type': 'jobs_data', '_source': {'taskbuffererrorcode': 0, 'jobdispatchererrorcode': 0, 'ddmerrordiag': None, 'computingsite': 'ATLAS_OPP_OSG-MIT_CMS', 'brokerageerrorcode': 0, 'exeerrorcode': 0, 'modificationtime': '2016-12-14T02:46:42', 'brokerageerrordiag': None, 'superrorcode': 0, 'pandaid': 3124983243, 'superrordiag': None, 'jobdispatchererrordiag': None, 'piloterrordiag': 'Job killed by signal 15: Signal handler has set job result to FAILED, ec = 1201', 'ddmerrorcode': 0, 'piloterrorcode': 1201, 'exeerrordiag': None, 'taskbuffererrordiag': None}, '_score': 0.0, '_index': 'jobs_archive_2016-12-14'}\n"
     ]
    }
   ],
   "source": [
    "#Example of more refined queries\n",
    "#better to use filters if the score is not needed (faster)\n",
    "s = {\n",
    "    \"size\": 1,\n",
    "    \"_source\": [\"computingsite\", \"pandaid\", \"modificationtime\", \"*errorcode\", \"*errordiag\"], #returns only certain fields\n",
    "    \"query\": { \n",
    "        \"bool\" : {\n",
    "            \"filter\" : [\n",
    "                { \"match\" : { \"processingtype\":\"gangarobot-pft\" } },\n",
    "                { \"match\" : { \"jobstatus\":\"failed\" } },\n",
    "              ],\n",
    "           #\"must\" :                 \n",
    "           #     {\"match\": {\"processingtype\":\"gangarobot-pft\"}},\n",
    "           # \"should\" :\n",
    "           #     {\"match\": {\"jobstatus\":\"failed\"}}\n",
    "     \n",
    "        }\n",
    "    },\n",
    "    \"aggs\": {  #build aggregation\n",
    "        \"models\": \n",
    "            {\"terms\": { \"field\": \"jobstatus\" } }\n",
    "    }    \n",
    "}\n",
    "\n",
    "res = es.search(index=ind, body=s, request_timeout=12000)\n",
    "\n",
    "print(res) \n",
    "\n",
    "jobs = res['hits']['hits']\n",
    "print('check: reading in '+str(len(jobs))+' hits')\n",
    "#print_info(jobs[0])\n",
    "print(jobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
