{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a scan() method from elasticsearch-py in v5.x.  It does not use 'scan' search type, which is removed since v2.1.  This can be used as a example implementation of scrolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copied from elasticsearch-py\n",
    "#  https://github.com/elastic/elasticsearch-py/blob/master/elasticsearch/helpers/__init__.py\n",
    "#\n",
    "def scan(client, query=None, scroll='5m', raise_on_error=True,\n",
    "         preserve_order=False, size=1000, request_timeout=None, clear_scroll=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Simple abstraction on top of the\n",
    "    :meth:`~elasticsearch.Elasticsearch.scroll` api - a simple iterator that\n",
    "    yields all hits as returned by underlining scroll requests.\n",
    "    By default scan does not return results in any pre-determined order. To\n",
    "    have a standard order in the returned documents (either by score or\n",
    "    explicit sort definition) when scrolling, use ``preserve_order=True``. This\n",
    "    may be an expensive operation and will negate the performance benefits of\n",
    "    using ``scan``.\n",
    "    :arg client: instance of :class:`~elasticsearch.Elasticsearch` to use\n",
    "    :arg query: body for the :meth:`~elasticsearch.Elasticsearch.search` api\n",
    "    :arg scroll: Specify how long a consistent view of the index should be\n",
    "        maintained for scrolled search\n",
    "    :arg raise_on_error: raises an exception (``ScanError``) if an error is\n",
    "        encountered (some shards fail to execute). By default we raise.\n",
    "    :arg preserve_order: don't set the ``search_type`` to ``scan`` - this will\n",
    "        cause the scroll to paginate with preserving the order. Note that this\n",
    "        can be an extremely expensive operation and can easily lead to\n",
    "        unpredictable results, use with caution.\n",
    "    :arg size: size (per shard) of the batch send at each iteration.\n",
    "    :arg request_timeout: explicit timeout for each call to ``scan``\n",
    "    :arg clear_scroll: explicitly calls delete on the scroll id via the clear\n",
    "        scroll API at the end of the method on completion or error, defaults\n",
    "        to true.\n",
    "    Any additional keyword arguments will be passed to the initial\n",
    "    :meth:`~elasticsearch.Elasticsearch.search` call::\n",
    "        scan(es,\n",
    "            query={\"query\": {\"match\": {\"title\": \"python\"}}},\n",
    "            index=\"orders-*\",\n",
    "            doc_type=\"books\"\n",
    "        )\n",
    "    \"\"\"\n",
    "    if not preserve_order:\n",
    "        query = query.copy() if query else {}\n",
    "        query[\"sort\"] = \"_doc\"\n",
    "    # initial search\n",
    "    resp = client.search(body=query, scroll=scroll, size=size,\n",
    "                         request_timeout=request_timeout, **kwargs)\n",
    "\n",
    "    scroll_id = resp.get('_scroll_id')\n",
    "    if scroll_id is None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        first_run = True\n",
    "        while True:\n",
    "            # if we didn't set search_type to scan initial search contains data\n",
    "            if first_run:\n",
    "                first_run = False\n",
    "            else:\n",
    "                resp = client.scroll(scroll_id, scroll=scroll, request_timeout=request_timeout)\n",
    "\n",
    "            for hit in resp['hits']['hits']:\n",
    "                yield hit\n",
    "\n",
    "            # check if we have any errrors\n",
    "            if resp[\"_shards\"][\"failed\"]:\n",
    "                logger.warning(\n",
    "                    'Scroll request has failed on %d shards out of %d.',\n",
    "                    resp['_shards']['failed'], resp['_shards']['total']\n",
    "                )\n",
    "                if raise_on_error:\n",
    "                    raise ScanError(\n",
    "                        scroll_id,\n",
    "                        'Scroll request has failed on %d shards out of %d.' %\n",
    "                            (resp['_shards']['failed'], resp['_shards']['total'])\n",
    "                    )\n",
    "\n",
    "            scroll_id = resp.get('_scroll_id')\n",
    "            # end of scroll\n",
    "            if scroll_id is None or not resp['hits']['hits']:\n",
    "                break\n",
    "    finally:\n",
    "        if scroll_id and clear_scroll:\n",
    "            client.clear_scroll(body={'scroll_id': [scroll_id]}, ignore=(404, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'cl-analytics.mwt2.org', 'port':9200}],\n",
    "                   send_get_body_as = 'POST'     # to be passed to Transport class\n",
    "                   )\n",
    "triumf = [\"ANALY_TRIUMF\"]\n",
    "source = ['pandaid','wall_time','cpuconsumptiontime']\n",
    "q = {\n",
    "      \"_source\": source,\n",
    "      \"query\": {\n",
    "        \"constant_score\": {\n",
    "          \"filter\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\"range\": {\"endtime\": {\"gte\":\"now-1d/d\", \"lte\":\"now\"}}},\n",
    "                {\"terms\": {\"computingsite\": triumf}},\n",
    "                {\"terms\": {\"jobstatus\": [\"finished\", \"failed\"]}}\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "index = 'jobs_archive_2016-12*'\n",
    "\n",
    "try:\n",
    "    sc = helpers.scan(es, query=q, index=index)\n",
    "    for s in sc:\n",
    "        print s['_source']\n",
    "except:\n",
    "    sc = scan(es, query=q, index=index)\n",
    "    for s in sc:\n",
    "        print s['_source']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
